{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **저시력자를 위한 원화 화폐 분류**\n","---\n","- 본 과제는 UltraLytics YOLO v5 모델 사용을 권장합니다.\n","    - 본 파일의 목차는 UltraLytics YOLO v5에 맞게 작성되어 있습니다.\n","    - 다른 모델을 찾아서 사용하셔도 좋습니다.\n","    - 산출물이 잘 나오면 됩니다 : )\n","---"],"metadata":{"id":"XT7PRhnMf-kI"}},{"cell_type":"markdown","source":["## 0.미션\n","---\n","- **과제 수행 목표**\n","    - 본 과제는 Object Detection 문제입니다.\n","    - Object Detection 문제로 접근하기 위해 **데이터셋 전처리**를 하셔야 합니다.\n","    - 데이터셋 : money_dataset.zip\n","        1. 데이터셋은 압축 파일로 제공됩니다.\n","        2. 압축 파일 안에는 화폐마다 폴더가 개별적으로 존재합니다.\n","        3. 폴더 안에는 화폐 이미지와 화폐 정보가 담긴 json 파일이 있습니다.\n","    - 여러분이 직접 촬영한 화폐 사진들을 탐지 과정에서 이용 해보세요.\n","    - 이미지에 화폐 하나만 나오게 촬영하는 것은 지양해주세요.\n","    - 다양한 방법으로 화폐를 촬영하고 결과를 확인해보세요.\n","        - ex 1) 화폐의 모든 종류를 한 이미지에 나오게 촬영\n","        - ex 2) 여러 화폐를 겹치게 하여 촬영\n","---\n","- **Key Point**\n","    1. 모델에 맞는 폴더 구조 확인\n","    2. 이미지 축소 비율에 맞춰 좌표값 변경\n","        - 좌표를 이미지 리사이즈한 비율로 변경\n","    3. 모델에 맞는 정보 추출/형식 변경\n","        - json 파일에서 정보 추출 및 모델 형식에 맞게 변경\n","    4. 화폐당 하나의 클래스로 변경\n","        - 총 8개 클래스\n","    5. 모델 선택 필요\n","---"],"metadata":{"id":"47D2vGDYdCOz"}},{"cell_type":"markdown","source":["## 1.환경설정"],"metadata":{"id":"aZon1K-Ag9be"}},{"cell_type":"markdown","source":["### (1) 구글 드라이브 연동\n","---\n","- 아래의 코드 셀을 반드시 실행시켜야 합니다.\n","---"],"metadata":{"id":"CMgnHN9ZBF05"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"xCplyiojBFwh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679640126416,"user_tz":-540,"elapsed":27685,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"1b958753-d782-4be1-c168-b40c1f0a48a1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"markdown","source":["### (2) 데이터셋 불러오기\n","---\n","- **세부요구사항**\n","    - 데이터셋 파일의 압축을 해제하세요.\n","---\n","- 예제 코드에서는 zipfile 모듈을 이용하였습니다.\n","    - [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"],"metadata":{"id":"J8vjv0acBAV4"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"bkSa5ejf8LMe","executionInfo":{"status":"ok","timestamp":1679625498778,"user_tz":-540,"elapsed":306,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[],"source":["import zipfile"]},{"cell_type":"code","source":["# 데이터셋 압축 파일 경로 : 유저별로 상이할 수 있음\n","money_data = zipfile.ZipFile( '/content/drive/MyDrive/money_dataset.zip' )"],"metadata":{"id":"N4cdpkRv86QQ","executionInfo":{"status":"ok","timestamp":1679624981823,"user_tz":-540,"elapsed":679,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 압축 해제\n","money_data.extractall('/content/drive/MyDrive/Dataset/')"],"metadata":{"id":"TDAyDRLT9hZS","executionInfo":{"status":"error","timestamp":1679625047582,"user_tz":-540,"elapsed":4790,"user":{"displayName":"현태","userId":"11869159444039358312"}},"colab":{"base_uri":"https://localhost:8080/","height":337},"outputId":"d44d5a5f-af50-4741-dce6-9c21e3b7a0ce"},"execution_count":4,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-43c17ad5ae7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 데이터셋 압축 해제\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmoney_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Dataset/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1693\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["!mkdir /content/drive/MyDrive/Dataset/recall"],"metadata":{"id":"mfh-0TKSRgRF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 압축 해제\n","money_data.extractall('/content/drive/MyDrive/Dataset/recall')"],"metadata":{"id":"aR7NBIIyRbyO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.데이터 전처리"],"metadata":{"id":"QyEd-WNIhoSc"}},{"cell_type":"markdown","source":["### (1) 폴더 구조 생성 및 파일 이동\n","---\n","- **세부요구사항**\n","    -  모델에서 요구하는 폴더 구조를 만들어야 합니다.\n","        - Hint : Image와 Label을 구분하는 폴더를 만들어 주세요\n","---\n","- 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n","    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"],"metadata":{"id":"P81d6utx-3LY"}},{"cell_type":"code","source":["# 1.폴더 구조 만들기\n","!mkdir /content/drive/MyDrive/Dataset/images;\n","!mkdir /content/drive/MyDrive/Dataset/images/train; mkdir /content/drive/MyDrive/Dataset/images/val\n","\n","!mkdir /content/drive/MyDrive/Dataset/labels !mkdir /content/drive/MyDrive/Dataset/labels/train_json; mkdir /content/drive/MyDrive/Dataset/labels/val_json;\n"],"metadata":{"id":"YBqCJU5z_UI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob, shutil"],"metadata":{"id":"UuchlNA_DftJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Dataset metadata 입력\n","won_list = ['10', '50', '100', '500', '1000', '5000', '10000', '50000']\n","data_path = '/content/drive/MyDrive/Dataset/'"],"metadata":{"id":"Q3lnYcLS_UOy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","for won in won_list:\n","    print('class: ', won)\n","    print(len(glob.glob(f'/content/drive/MyDrive/Dataset/{won}/*')))\n","    print(len(glob.glob(f'/content/drive/MyDrive/Dataset/{won}/*jpg')))\n","    print(len(glob.glob(f'/content/drive/MyDrive/Dataset/{won}/*json')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"at6afXWwq6id","executionInfo":{"status":"ok","timestamp":1679561987852,"user_tz":-540,"elapsed":484,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"6b72454e-d2e1-4dfc-944b-d779c016826f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["class:  10\n","0\n","0\n","0\n","class:  50\n","0\n","0\n","0\n","class:  100\n","0\n","0\n","0\n","class:  500\n","0\n","0\n","0\n","class:  1000\n","0\n","0\n","0\n","class:  5000\n","0\n","0\n","0\n","class:  10000\n","0\n","0\n","0\n","class:  50000\n","0\n","0\n","0\n"]}]},{"cell_type":"markdown","source":["---\n","- 데이터를 Training set | Validation set으로 분할하세요.\n","    - 예시 : Training과 Validation은 8:2로 분리\n","- Hint : 이미지 데이터는 /images에, JSON 데이터는 /labels에 넣어주세요\n","    - 예시 : /dataset/images/train, /dataset/labels/train\n","    - 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n","    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","\n","    ※ 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","    \n","---"],"metadata":{"id":"ihJgeqXJG1Ml"}},{"cell_type":"code","source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","# 3. 데이터를 Training set | Validation set으로 분할하세요.\n","import random, glob, shutil\n","\n","images_train_path = '/content/drive/MyDrive/Dataset/images/train/'\n","images_valid_path = '/content/drive/MyDrive/Dataset/images/val/'\n","\n","labels_train_path = '/content/drive/MyDrive/Dataset/labels/train_json/'\n","labels_valid_path = '/content/drive/MyDrive/Dataset/labels/val_json/'\n","\n","for lst in won_list :\n","    path = '/content/drive/MyDrive/Dataset/' + lst + '/'\n","    train_data = glob.glob(path + '*.jpg')\n","    labels_data = glob.glob(path + '*.json')\n","    \n","    valid_jpg = random.sample(train_data, k = round(len(train_data)*0.2))\n","\n","    valid_json = valid_jpg.copy()\n","    for idx, x in enumerate(valid_jpg) :\n","        valid_json[idx] = x[:-3] + 'json'\n","\n","    \n","    for file in valid_jpg :\n","        shutil.move(file, images_valid_path)\n","\n","    for file in valid_json :\n","        shutil.move(file, labels_valid_path)\n","    \n","    train_data = glob.glob(path + '*.jpg')\n","    labels_data = glob.glob(path + '*.json')\n","\n","    for file in train_data :\n","        shutil.move(file, images_train_path)\n","\n","    for file in labels_data :\n","        shutil.move(file, labels_train_path)"],"metadata":{"id":"1qfGCSqy_kL0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","print('images - train 개수 : ', len(os.listdir('/content/drive/MyDrive/Dataset/images/train/')))\n","print('images - val 개수 : ', len(os.listdir('/content/drive/MyDrive/Dataset/images/val/')))\n","print('labels - train 개수 : ', len(os.listdir('/content/drive/MyDrive/Dataset/labels/train_json/')))\n","print('labels - val 개수 : ', len(os.listdir('/content/drive/MyDrive/Dataset/labels/val_json/')))"],"metadata":{"id":"GA7T3IPUS_iD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679572522852,"user_tz":-540,"elapsed":414,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"20195b1d-1ce8-462c-b685-7ea24255dbf0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["images - train 개수 :  4175\n","images - val 개수 :  1043\n","labels - train 개수 :  4175\n","labels - val 개수 :  1043\n"]}]},{"cell_type":"code","source":["print(sorted(os.listdir('/content/drive/MyDrive/Dataset/images/train/'))[:5])\n","print(sorted(os.listdir('/content/drive/MyDrive/Dataset/labels/train_json/'))[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qGyHAA7ZITw","executionInfo":{"status":"ok","timestamp":1679572580218,"user_tz":-540,"elapsed":1021,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"12014e1a-2443-4570-f73d-0f39ebaf7721"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['10000_B_DESK_0_1.jpg', '10000_B_DESK_0_10.jpg', '10000_B_DESK_0_100.jpg', '10000_B_DESK_0_101.jpg', '10000_B_DESK_0_102.jpg']\n","['10000_B_DESK_0_1.json', '10000_B_DESK_0_10.json', '10000_B_DESK_0_100.json', '10000_B_DESK_0_101.json', '10000_B_DESK_0_102.json']\n"]}]},{"cell_type":"markdown","source":["### (2) json에서 정보 추출\n","---\n","- **세부요구사항**\n","    - json 파일에서 필요한 정보를 추출하세요:\n","        - 위치 정보 : x1, x2, y1, y2\n","        - 박스 정보 : shape_type\n","        - 클래스 정보 : labels\n","    - 화폐당 하나의 클래스로 변경하세요.\n","        - json 파일에는 화폐 클래스가 앞뒷면으로 구분되어 있습니다.\n","        - 화폐의 앞뒷면 구분을 없애주세요.\n","            - 예시 : 'ten_front', 'ten_back' -> 'ten'\n","    - 화폐의 위치 정보를 YOLO 모델 형식에 맞게 변경 해주세요.\n","        - 사용되는 이미지는 원본에서 1/4로 축소되어 있습니다.\n","        - json 파일의 정보는 원본 기준 데이터이므로 위치 정보 추출을 할 때 x값과 y값을 1/4로 줄여주세요.\n","    - 이렇게 변경된 정보를 YOLO label 형식에 맞게 txt파일로 저장 해 주세요.\n","        - Hint : YOLO Labeling Format [label, x-center, y-center, width-norm, height-norm]\n","---"],"metadata":{"id":"II_hsJ6bKYGn"}},{"cell_type":"code","source":["import os, json"],"metadata":{"id":"MgUoCewjM-Jf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir '/content/drive/MyDrive/Dataset/labels/train'\n","!mkdir '/content/drive/MyDrive/Dataset/labels/val'\n","\n"],"metadata":{"id":"dMAibgLN4dzK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["won_dict = {'Ten':'0', 'Fifty':'1', 'Hundred':'2', 'Five_Hundred':'3', 'Thousand':'4', 'Five_Thousand':'5', 'Ten_Thousand':'6', 'Fifty_Thousand':'7'}"],"metadata":{"id":"Q08VmvYgla28"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["json_path = '/content/drive/MyDrive/Dataset/labels/'\n","temp_list = ['train_json', 'val_json']"],"metadata":{"id":"gBD1Zv9BKaxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def to_txt(file_, train_or_val) :\n","    file_path = json_path + train_or_val + '/' + file_\n","    \n","    with open(file_path,encoding='UTF-8') as json_file:\n","        data = json.load(json_file)\n","    \n","    if train_or_val == 'train_json' :\n","        save_path = '/content/drive/MyDrive/Dataset/labels/train/' + file_\n","    else :\n","        save_path = '/content/drive/MyDrive/Dataset/labels/val/' + file_\n","    with open(save_path[:-5]+'.txt', 'w') as f :\n","        if 'back' in data['shapes'][0]['label'] : \n","            label = data['shapes'][0]['label'].replace('_back', '')\n","        elif 'front' in data['shapes'][0]['label'] : \n","            label = data['shapes'][0]['label'].replace('_front', '')        \n","        else : label = data['shapes'][0]['label']\n","        label = won_dict[str(label)]\n","        x_center = ((data['shapes'][0]['points'][0][0] + data['shapes'][0]['points'][1][0])/2)/data['imageWidth']\n","        y_center = ((data['shapes'][0]['points'][0][1] + data['shapes'][0]['points'][1][1])/2)/data['imageHeight']\n","        width_norm = (data['shapes'][0]['points'][1][0] - data['shapes'][0]['points'][0][0])/data['imageWidth']\n","        height_norm = (data['shapes'][0]['points'][1][1] - data['shapes'][0]['points'][0][1])/data['imageHeight']\n","        f.write(f'{label} {x_center} {y_center} {width_norm} {height_norm}')\n","        f.close()"],"metadata":{"id":"bZ3oQfd_eTgt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Yt7yhvSFZTOZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"09XBF9fdZSTr"}},{"cell_type":"code","source":["x = 'Ten_front'"],"metadata":{"id":"ihIANw59At3B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label = 'Fifty'"],"metadata":{"id":"TMwVztcVAvHr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["won_dict['Ten']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"jVcTRGgAOVZ2","executionInfo":{"status":"ok","timestamp":1679571117642,"user_tz":-540,"elapsed":366,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"cec35ce9-32ad-4ed8-a2f1-447e7684e0bf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'10'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["########################\n","# 이 셀부터 코드 작성하세요\n","# Json 파일에서 필요한 정보만 골라 txt로 바꾸는 작업임을 기억하세요!\n","########################\n","lst = []\n","for train_or_val in temp_list :\n","    for file_ in os.listdir('/content/drive/MyDrive/Dataset/labels/' + train_or_val) :\n","        # try:\n","        to_txt(file_, train_or_val)\n","        # except :\n","            # lst.append([file_, train_or_val])"],"metadata":{"id":"4C1hJa-FBFqg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lst"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_JqJCzufbir","executionInfo":{"status":"ok","timestamp":1679572831500,"user_tz":-540,"elapsed":316,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"de232856-d072-49dc-95ea-b7f9335c2380"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["print('label_txt train 개수 : ', len(os.listdir('/content/drive/MyDrive/Dataset/labels/train')))\n","print('label_txt val 개수 : ', len(os.listdir('/content/drive/MyDrive/Dataset/labels/val')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wuGNkJSpR_1U","executionInfo":{"status":"ok","timestamp":1679574448619,"user_tz":-540,"elapsed":392,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"c4913655-cae3-4961-b72e-916ebf011a4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["label_txt train 개수 :  4175\n","label_txt val 개수 :  1043\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"Q81edc7N0Ije"}},{"cell_type":"markdown","metadata":{"id":"tOQeEhApesWR"},"source":["### (3) 데이터셋 정보가 담긴 파일 생성\n","---\n","- **세부요구사항**\n","    - 파일 안에 있어야 할 정보는 아래와 같습니다.\n","        - 학습할 클래스 이름 정보\n","        - 학습할 클래스 수 정보\n","        - Training, Validation 데이터셋 위치 정보\n","---\n","- 가장 대중적으로 이용하는 라이브러리는 yaml 입니다.\n","    - [yaml document](https://pyyaml.org/wiki/PyYAMLDocumentation)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pu1iQfQolBhJ"},"outputs":[],"source":["import yaml"]},{"cell_type":"code","source":["won_dict = {0:'10', 1:'50', 2:'100', 3:'500', 4:'1000', 5:'5000', 6:'10000', 7:'50000'}"],"metadata":{"id":"t1_uOeXcSvv3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["str_data = \"\"\"\n","path: /content/drive/MyDrive/Dataset  # 데이터셋 경로\n","train: images/train  # Training 데이터셋 위치 정보\n","val: images/val  # Validation 데이터셋 위치 정보\n","\n","# Classes\n","nc: 8  # 학습할 클래스 수\n","names: ['10원','50원','100원','500원','1000원','5000원','10000원','50000원'] # 학습할 클래스 이름 정보\n","            \"\"\"\n","\n","with open('/content/drive/MyDrive/Dataset/money.yaml', 'w') as f :\n","    f.write(str_data)\n","\n","\n","\n","\n","\n","    "],"metadata":{"id":"L5JwVZjob06F"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvMQcHirmSnD"},"outputs":[],"source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","with open('/content/drive/MyDrive/Dataset/money.yaml', 'w') as f :\n","    f.write(str_data)\n","    "]},{"cell_type":"markdown","source":["## 3.모델링"],"metadata":{"id":"3btFvySXi2dt"}},{"cell_type":"markdown","metadata":{"id":"0pQ2gRbTYgLL"},"source":["### (1) 모델 라이브러리 설치\n","---"]},{"cell_type":"code","source":["!pip install jedi"],"metadata":{"id":"73a1l-ZQuHyF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679632775817,"user_tz":-540,"elapsed":5125,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"bbe2c326-b907-478e-b4fa-abc561509353"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting jedi\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi) (0.8.3)\n","Installing collected packages: jedi\n","Successfully installed jedi-0.18.2\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5"],"metadata":{"id":"Biyr9AHkMyNf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679632779240,"user_tz":-540,"elapsed":1714,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"0dea0a43-ef25-43f0-a25e-ef4974beddb0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 15338, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 15338 (delta 0), reused 2 (delta 0), pack-reused 15335\u001b[K\n","Receiving objects: 100% (15338/15338), 14.21 MiB | 29.58 MiB/s, done.\n","Resolving deltas: 100% (10523/10523), done.\n"]}]},{"cell_type":"code","source":["## yolov5 폴더 requirements.txt 수정 필요\n","## setuptools<=64.0.2\n","\n","temp_str = 'setuptools<=64.0.2\\n'\n","\n","f = open('/content/yolov5/requirements.txt', 'r')\n","f_str = f.readlines()\n","f.close()\n","\n","f2 = open('/content/yolov5/requirements.txt', 'w')\n","\n","for idx, val in enumerate(f_str) :\n","    if 'setuptools' in val :\n","        idx_v = idx\n","        f_str.remove(val)\n","        f_str.insert(idx_v, temp_str)\n","\n","for val in f_str :\n","    f2.write(val)\n","\n","f2.close() "],"metadata":{"id":"W3JjyVOpg26s","executionInfo":{"status":"ok","timestamp":1679632783623,"user_tz":-540,"elapsed":342,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"6xD6tBTdMyNg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679632801348,"user_tz":-540,"elapsed":3995,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"eab5ba0f-434e-422e-fec6-08c3cf412849"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (3.1.31)\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (5.9.4)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n","Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 15)) (1.13.1+cu116)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 16)) (0.14.1+cu116)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (2.11.2)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 26)) (1.4.4)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 27)) (0.12.2)\n","Requirement already satisfied: setuptools<=64.0.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 41)) (64.0.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.10)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (23.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.4.4)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (5.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (4.39.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.15)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.5.0)\n","Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.19.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.16.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.2.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.4.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.51.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.40.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.6)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 26)) (2022.7.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (5.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.16.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.3.1)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.15.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 21)) (6.1.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.1.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.2.2)\n"]}],"source":["!cd yolov5; pip install -r requirements.txt"]},{"cell_type":"markdown","source":["### (2) 가중치 파일 다운로드\n","---\n","- **세부요구사항**\n","    - 모델 개발자가 제공하는 사전 학습 가중치 파일을 다운로드 하세요.\n","        - 해당 과정이 불필요하다면 넘어가셔도 됩니다!\n","---"],"metadata":{"id":"_mHMAspjR6Xp"}},{"cell_type":"code","source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","!wget -O /content/drive/MyDrive/Dataset/yolov5s.pt https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt"],"metadata":{"id":"sSVIqkMLDIOd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679632807697,"user_tz":-540,"elapsed":1873,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"9e19da8c-dfe9-4897-8f57-4217beaa48c9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-24 04:40:06--  https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt\n","Resolving github.com (github.com)... 140.82.113.3\n","Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/381bd8a8-8910-4e9e-b0dd-2752951ef78c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230324T044006Z&X-Amz-Expires=300&X-Amz-Signature=c1fe2dd352b29e7cce2c41399873c9629c42a63a6f8f65211cbec690b5943da9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-03-24 04:40:06--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/381bd8a8-8910-4e9e-b0dd-2752951ef78c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230324T044006Z&X-Amz-Expires=300&X-Amz-Signature=c1fe2dd352b29e7cce2c41399873c9629c42a63a6f8f65211cbec690b5943da9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 14808437 (14M) [application/octet-stream]\n","Saving to: ‘/content/drive/MyDrive/Dataset/yolov5s.pt’\n","\n","/content/drive/MyDr 100%[===================>]  14.12M  54.2MB/s    in 0.3s    \n","\n","2023-03-24 04:40:06 (54.2 MB/s) - ‘/content/drive/MyDrive/Dataset/yolov5s.pt’ saved [14808437/14808437]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"W8-5lC4mfbwT"},"source":["### (3) 학습 : train.py\n","---\n","- **세부요구사항**\n","    - UltraLytics YOLO v5에는 아래의 데이터가 필요합니다.\n","        - 데이터셋 정보가 담긴 yaml 파일\n","        - 사용하려는 모델 구조에 대한 yaml 파일\n","        - 사용하려는 모델의 가중치 파일\n","---"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"4AYFDMaVfmTK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679627948977,"user_tz":-540,"elapsed":2323106,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"3c519bda-a320-479f-dbbc-e5cc8363277c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/Dataset/yolov5s.pt, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/drive/MyDrive/Dataset/money.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1000, batch_size=16, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/drive/MyDrive/Dataset, name=train_money, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=5, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-128-gb96f35c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/Dataset', view at http://localhost:6006/\n","2023-03-24 02:40:29.700617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-24 02:40:29.861344: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-03-24 02:40:30.696325: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-03-24 02:40:30.696453: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-03-24 02:40:30.696473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Overriding model.yaml nc=80 with nc=8\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     35061  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","YOLOv5s summary: 214 layers, 7041205 parameters, 7041205 gradients, 16.0 GFLOPs\n","\n","Transferred 342/349 items from /content/drive/MyDrive/Dataset/yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Dataset/labels/train.cache... 4175 images, 0 backgrounds, 0 corrupt: 100% 4175/4175 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Dataset/labels/val.cache... 1043 images, 0 backgrounds, 0 corrupt: 100% 1043/1043 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.25 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to /content/drive/MyDrive/Dataset/train_money/labels.jpg... \n","Image sizes 320 train, 320 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/Dataset/train_money\u001b[0m\n","Starting training for 1000 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      0/999     0.904G     0.1225    0.01329    0.06574         37        320:   0% 0/261 [00:29<?, ?it/s]Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","      0/999     0.946G    0.06382    0.01852    0.05374         31        320: 100% 261/261 [04:42<00:00,  1.08s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.39it/s]\n","                   all       1043       1043       0.27      0.709       0.35      0.233\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      1/999      1.34G    0.04076    0.01228    0.03976         26        320: 100% 261/261 [00:30<00:00,  8.55it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.34it/s]\n","                   all       1043       1043      0.406      0.743      0.658      0.375\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      2/999      1.34G    0.03804   0.009599    0.02569         37        320: 100% 261/261 [00:30<00:00,  8.68it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.35it/s]\n","                   all       1043       1043       0.49      0.836      0.684      0.437\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      3/999      1.34G    0.03125   0.008184    0.02119         27        320: 100% 261/261 [00:30<00:00,  8.68it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.30it/s]\n","                   all       1043       1043      0.662      0.962      0.768      0.587\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      4/999      1.34G    0.02616   0.007192    0.01869         29        320: 100% 261/261 [00:30<00:00,  8.56it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.41it/s]\n","                   all       1043       1043      0.633      0.853      0.741       0.58\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      5/999      1.34G    0.02374   0.006922    0.01792         29        320: 100% 261/261 [00:30<00:00,  8.64it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.36it/s]\n","                   all       1043       1043      0.657      0.874      0.795      0.649\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      6/999      1.34G    0.02219   0.006467    0.01725         38        320: 100% 261/261 [00:30<00:00,  8.64it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.46it/s]\n","                   all       1043       1043       0.72      0.862      0.816      0.613\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      7/999      1.34G    0.02114   0.006303    0.01593         36        320: 100% 261/261 [00:30<00:00,  8.67it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.41it/s]\n","                   all       1043       1043      0.761      0.907      0.845       0.71\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      8/999      1.34G    0.02014   0.006043    0.01536         30        320: 100% 261/261 [00:30<00:00,  8.57it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.37it/s]\n","                   all       1043       1043      0.751      0.859      0.865      0.739\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      9/999      1.34G    0.01917   0.005913    0.01434         34        320: 100% 261/261 [00:30<00:00,  8.56it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.46it/s]\n","                   all       1043       1043      0.773       0.84      0.858      0.721\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     10/999      1.34G     0.0188   0.005831    0.01351         31        320: 100% 261/261 [00:30<00:00,  8.50it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.59it/s]\n","                   all       1043       1043       0.84      0.851      0.885      0.761\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     11/999      1.34G    0.01783   0.005771    0.01331         36        320: 100% 261/261 [00:30<00:00,  8.57it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.38it/s]\n","                   all       1043       1043      0.853      0.876      0.911      0.805\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     12/999      1.34G    0.01741   0.005637    0.01336         34        320: 100% 261/261 [00:30<00:00,  8.66it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.50it/s]\n","                   all       1043       1043      0.875      0.856      0.913      0.801\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     13/999      1.34G    0.01711   0.005545    0.01223         25        320: 100% 261/261 [00:30<00:00,  8.66it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.38it/s]\n","                   all       1043       1043      0.891       0.87      0.929      0.817\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     14/999      1.34G    0.01634   0.005404    0.01164         36        320: 100% 261/261 [00:30<00:00,  8.63it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.51it/s]\n","                   all       1043       1043      0.913      0.896      0.941      0.843\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     15/999      1.34G    0.01599   0.005305    0.01176         25        320: 100% 261/261 [00:30<00:00,  8.62it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.36it/s]\n","                   all       1043       1043      0.895      0.863      0.924      0.829\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     16/999      1.34G    0.01587   0.005263    0.01096         25        320: 100% 261/261 [00:30<00:00,  8.69it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.44it/s]\n","                   all       1043       1043      0.873      0.913      0.934      0.834\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     17/999      1.34G    0.01537   0.005148     0.0108         35        320: 100% 261/261 [00:30<00:00,  8.57it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.51it/s]\n","                   all       1043       1043      0.877      0.881      0.922      0.833\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     18/999      1.34G    0.01548   0.005224    0.01008         29        320: 100% 261/261 [00:30<00:00,  8.58it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.41it/s]\n","                   all       1043       1043      0.928      0.945      0.973      0.877\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     19/999      1.34G    0.01561   0.005191     0.0102         34        320: 100% 261/261 [00:30<00:00,  8.60it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.45it/s]\n","                   all       1043       1043      0.927      0.925      0.959      0.861\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     20/999      1.34G    0.01476   0.005051    0.01015         35        320: 100% 261/261 [00:30<00:00,  8.65it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.45it/s]\n","                   all       1043       1043      0.939      0.936      0.972      0.876\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     21/999      1.34G    0.01473   0.005049   0.009412         30        320: 100% 261/261 [00:30<00:00,  8.55it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.48it/s]\n","                   all       1043       1043       0.95      0.954      0.982      0.886\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     22/999      1.34G    0.01452   0.004958   0.008859         28        320: 100% 261/261 [00:30<00:00,  8.60it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.38it/s]\n","                   all       1043       1043      0.925      0.936      0.967      0.886\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     23/999      1.34G    0.01432   0.004978   0.008788         33        320: 100% 261/261 [00:30<00:00,  8.63it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.45it/s]\n","                   all       1043       1043      0.919      0.933      0.969      0.896\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     24/999      1.34G    0.01426    0.00498   0.009246         30        320: 100% 261/261 [00:30<00:00,  8.62it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.41it/s]\n","                   all       1043       1043      0.927      0.962       0.98      0.901\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     25/999      1.34G    0.01361   0.004809   0.008374         36        320: 100% 261/261 [00:30<00:00,  8.61it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.30it/s]\n","                   all       1043       1043      0.957      0.923      0.973      0.892\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     26/999      1.34G    0.01383   0.004763   0.007941         24        320: 100% 261/261 [00:30<00:00,  8.67it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.41it/s]\n","                   all       1043       1043      0.929      0.945      0.972      0.905\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     27/999      1.34G    0.01393    0.00488   0.008096         35        320: 100% 261/261 [00:30<00:00,  8.61it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.36it/s]\n","                   all       1043       1043      0.975       0.97       0.99      0.924\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     28/999      1.34G    0.01326   0.004702   0.007403         33        320: 100% 261/261 [00:30<00:00,  8.65it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.48it/s]\n","                   all       1043       1043      0.975      0.934      0.982      0.904\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     29/999      1.34G    0.01316   0.004702    0.00784         32        320: 100% 261/261 [00:29<00:00,  8.70it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.41it/s]\n","                   all       1043       1043      0.947       0.95      0.978      0.903\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     30/999      1.34G    0.01298    0.00461   0.007572         24        320: 100% 261/261 [00:30<00:00,  8.63it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.41it/s]\n","                   all       1043       1043      0.952       0.95      0.982      0.924\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     31/999      1.34G    0.01311   0.004676    0.00802         33        320: 100% 261/261 [00:30<00:00,  8.55it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.55it/s]\n","                   all       1043       1043      0.968      0.949      0.986      0.927\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     32/999      1.34G    0.01294   0.004611   0.007529         34        320: 100% 261/261 [00:30<00:00,  8.61it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.43it/s]\n","                   all       1043       1043       0.96      0.951      0.985       0.92\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     33/999      1.34G    0.01301   0.004673   0.007029         25        320: 100% 261/261 [00:30<00:00,  8.63it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.32it/s]\n","                   all       1043       1043      0.972      0.973       0.99      0.924\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     34/999      1.34G    0.01261   0.004537   0.007513         33        320: 100% 261/261 [00:29<00:00,  8.71it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.21it/s]\n","                   all       1043       1043      0.984       0.98      0.991      0.929\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     35/999      1.34G    0.01261    0.00464   0.007194         29        320: 100% 261/261 [00:30<00:00,  8.64it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.40it/s]\n","                   all       1043       1043      0.972      0.984      0.992      0.933\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     36/999      1.34G    0.01241   0.004478   0.006658         34        320: 100% 261/261 [00:30<00:00,  8.66it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.40it/s]\n","                   all       1043       1043      0.979      0.964      0.989      0.933\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     37/999      1.34G    0.01274   0.004593   0.007326         34        320: 100% 261/261 [00:30<00:00,  8.68it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.39it/s]\n","                   all       1043       1043      0.958      0.972      0.987      0.933\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     38/999      1.34G    0.01231   0.004527    0.00691         31        320: 100% 261/261 [00:30<00:00,  8.59it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.45it/s]\n","                   all       1043       1043       0.97      0.976      0.989      0.938\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     39/999      1.34G    0.01225   0.004403   0.006339         33        320: 100% 261/261 [00:30<00:00,  8.65it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.26it/s]\n","                   all       1043       1043      0.966      0.987      0.992      0.942\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     40/999      1.34G    0.01224   0.004448   0.006553         37        320: 100% 261/261 [00:30<00:00,  8.65it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.41it/s]\n","                   all       1043       1043      0.982      0.977      0.992      0.935\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     41/999      1.34G    0.01187   0.004336   0.006725         27        320: 100% 261/261 [00:30<00:00,  8.70it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.29it/s]\n","                   all       1043       1043       0.97      0.978      0.991      0.946\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     42/999      1.34G    0.01174   0.004374   0.006002         38        320: 100% 261/261 [00:30<00:00,  8.65it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.43it/s]\n","                   all       1043       1043      0.977      0.943      0.989      0.937\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     43/999      1.34G    0.01197    0.00441   0.005855         27        320: 100% 261/261 [00:30<00:00,  8.63it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.38it/s]\n","                   all       1043       1043      0.988      0.977      0.992      0.938\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     44/999      1.34G    0.01165    0.00427   0.005907         36        320: 100% 261/261 [00:30<00:00,  8.62it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.46it/s]\n","                   all       1043       1043      0.986      0.977      0.991      0.949\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     45/999      1.34G    0.01199   0.004362   0.006131         32        320: 100% 261/261 [00:30<00:00,  8.65it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.31it/s]\n","                   all       1043       1043      0.988      0.982      0.989      0.943\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     46/999      1.34G    0.01164   0.004306    0.00585         32        320: 100% 261/261 [00:30<00:00,  8.64it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.29it/s]\n","                   all       1043       1043      0.991      0.978      0.992       0.95\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     47/999      1.34G    0.01154   0.004384   0.006091         28        320: 100% 261/261 [00:30<00:00,  8.65it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.39it/s]\n","                   all       1043       1043      0.981      0.988      0.994      0.946\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     48/999      1.34G     0.0117   0.004269   0.005543         33        320: 100% 261/261 [00:30<00:00,  8.63it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.36it/s]\n","                   all       1043       1043      0.986      0.976      0.992      0.945\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     49/999      1.34G    0.01156   0.004312   0.005477         25        320: 100% 261/261 [00:30<00:00,  8.62it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.49it/s]\n","                   all       1043       1043      0.982      0.985      0.994      0.957\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     50/999      1.34G    0.01157   0.004206   0.005902         29        320: 100% 261/261 [00:30<00:00,  8.66it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.31it/s]\n","                   all       1043       1043      0.983      0.988      0.993      0.949\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     51/999      1.34G    0.01171   0.004286   0.005781         32        320: 100% 261/261 [00:30<00:00,  8.56it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.55it/s]\n","                   all       1043       1043      0.981       0.97      0.993       0.95\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     52/999      1.34G    0.01167   0.004322   0.005788         31        320: 100% 261/261 [00:30<00:00,  8.66it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.36it/s]\n","                   all       1043       1043      0.991      0.978      0.993      0.955\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     53/999      1.34G    0.01135   0.004223   0.005399         34        320: 100% 261/261 [00:30<00:00,  8.65it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.38it/s]\n","                   all       1043       1043      0.992      0.984      0.995      0.955\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     54/999      1.34G    0.01091   0.004132   0.005317         27        320: 100% 261/261 [00:30<00:00,  8.62it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  5.42it/s]\n","                   all       1043       1043       0.99      0.984      0.991      0.951\n","Stopping training early as no improvement observed in last 5 epochs. Best results observed at epoch 49, best model saved as best.pt.\n","To update EarlyStopping(patience=5) pass a new patience value, i.e. `python train.py --patience 300` or use `--patience 0` to disable EarlyStopping.\n","\n","55 epochs completed in 0.634 hours.\n","Optimizer stripped from /content/drive/MyDrive/Dataset/train_money/weights/last.pt, 14.3MB\n","Optimizer stripped from /content/drive/MyDrive/Dataset/train_money/weights/best.pt, 14.3MB\n","\n","Validating /content/drive/MyDrive/Dataset/train_money/weights/best.pt...\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:07<00:00,  4.33it/s]\n","                   all       1043       1043      0.982      0.985      0.994      0.957\n","                   10원       1043         87      0.945          1      0.994       0.94\n","                   50원       1043         88      0.954      0.989      0.993      0.962\n","                  100원       1043         88          1      0.914      0.988      0.925\n","                  500원       1043         88      0.967      0.977      0.993      0.946\n","                 1000원       1043        172      0.998          1      0.995      0.965\n","                 5000원       1043        173      0.998          1      0.995      0.972\n","                10000원       1043        173      0.998          1      0.995      0.965\n","                50000원       1043        174      0.998          1      0.995      0.982\n","Results saved to \u001b[1m/content/drive/MyDrive/Dataset/train_money\u001b[0m\n"]}],"source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","!cd yolov5; python train.py \\\n","    --data '/content/drive/MyDrive/Dataset/money.yaml' \\\n","    --cfg '/content/yolov5/models/yolov5s.yaml' \\\n","    --weights '/content/drive/MyDrive/Dataset/yolov5s.pt' \\\n","    --epochs 1000 \\\n","    --patience 5 \\\n","    --img 320 \\\n","    --project '/content/drive/MyDrive/Dataset' \\\n","    --name 'train_money' \\\n","    --exist-ok\n","    # --device cpu"]},{"cell_type":"code","source":[],"metadata":{"id":"J3Rmay_sqSc3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u2YESAa5fc4M"},"source":["\n","\n","```\n","# 코드로 형식 지정됨\n","\n","```\n","# 코드로 형식 지정됨\n","```\n","\n","\n","```\n","\n","## 4.탐지 : detect.py\n","---\n","- **세부요구사항**\n","    - 학습 과정에서 생성된 가중치 파일을 이용하세요.\n","    - IoU threshold를 0.25 이하로 설정하세요.\n","    - confidence threshold를 0.75 이상으로 설정하세요.\n","---\n","- 여러분이 **직접 촬영한 화폐 사진과 동영상**을 탐지 과정에 이용하여 결과를 확인하세요.\n","    - 조건\n","        1. 화폐의 수를 늘려가며 촬영 해보세요.\n","            - ex) 50원 하나, 50원 둘, 50원 셋, ...\n","        2. 화폐의 종류를 늘려가며 촬영 해보세요.\n","            - ex) 50원 하나와 100원 하나, 50원 하나와 100원 하나와 1000원 하나, ...\n","        3. 사진은 최소 30장 이상, 동영상은 최소 하나 이상 촬영하여 사용 해보세요.\n","---"]},{"cell_type":"code","source":["import zipfile\n","money_picture = zipfile.ZipFile( '/content/drive/MyDrive/money_picture 2.zip')\n","money_picture.extractall('/content/drive/MyDrive/Dataset/')\n","money_video = zipfile.ZipFile( '/content/drive/MyDrive/money_video.zip')\n","money_video.extractall('/content/drive/MyDrive/Dataset/')"],"metadata":{"id":"LnQHuJv8qTZg","executionInfo":{"status":"ok","timestamp":1679633838139,"user_tz":-540,"elapsed":1996,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","!cd yolov5; python detect.py \\\n","    --weights '/content/drive/MyDrive/Dataset/train_money/weights/best.pt' \\\n","    --source '/content/drive/MyDrive/Dataset/money_picture' \\\n","    --project '/content/drive/MyDrive/Dataset/' \\\n","    --name 'images' \\\n","    --img 320 \\\n","    --conf-thres 0.75 \\\n","    --iou-thres 0.25 \\\n","    --line-thickness 2 \\\n","    --exist-ok \n","    # --device CPU"],"metadata":{"id":"9rK0ClfTcjEZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679633979433,"user_tz":-540,"elapsed":14106,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"0795bc0b-b91c-4891-8c16-90e10598fd84"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/Dataset/train_money/weights/best.pt'], source=/content/drive/MyDrive/Dataset/money_picture, data=data/coco128.yaml, imgsz=[320, 320], conf_thres=0.75, iou_thres=0.25, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/drive/MyDrive/Dataset/, name=images, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-128-gb96f35c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/98 /content/drive/MyDrive/Dataset/money_picture/1000.jpeg: 192x320 1 1000원, 12.0ms\n","image 2/98 /content/drive/MyDrive/Dataset/money_picture/10000_1.jpg: 320x256 4 10000원s, 12.4ms\n","image 3/98 /content/drive/MyDrive/Dataset/money_picture/10000_1.png: 224x320 (no detections), 12.0ms\n","image 4/98 /content/drive/MyDrive/Dataset/money_picture/10000_10.jpg: 256x320 1 10000원, 11.7ms\n","image 5/98 /content/drive/MyDrive/Dataset/money_picture/10000_2.jpg: 320x320 1 50원, 1 10000원, 9.8ms\n","image 6/98 /content/drive/MyDrive/Dataset/money_picture/10000_2.png: 256x320 1 10000원, 8.7ms\n","image 7/98 /content/drive/MyDrive/Dataset/money_picture/10000_3.jpg: 320x320 (no detections), 8.9ms\n","image 8/98 /content/drive/MyDrive/Dataset/money_picture/10000_3.png: 224x320 1 10000원, 8.3ms\n","image 9/98 /content/drive/MyDrive/Dataset/money_picture/10000_4.jpg: 256x320 1 10000원, 8.5ms\n","image 10/98 /content/drive/MyDrive/Dataset/money_picture/10000_4.png: 320x224 1 10000원, 12.1ms\n","image 11/98 /content/drive/MyDrive/Dataset/money_picture/10000_5.jpg: 320x256 (no detections), 8.4ms\n","image 12/98 /content/drive/MyDrive/Dataset/money_picture/10000_6.jpg: 256x320 1 10000원, 8.9ms\n","image 13/98 /content/drive/MyDrive/Dataset/money_picture/10000_7.jpg: 320x256 (no detections), 8.4ms\n","image 14/98 /content/drive/MyDrive/Dataset/money_picture/10000_8.jpg: 320x160 (no detections), 12.7ms\n","image 15/98 /content/drive/MyDrive/Dataset/money_picture/10000_9.jpg: 320x320 1 10000원, 8.7ms\n","image 16/98 /content/drive/MyDrive/Dataset/money_picture/1000_1.jpg: 256x320 1 1000원, 8.4ms\n","image 17/98 /content/drive/MyDrive/Dataset/money_picture/1000_10.jpg: 320x320 1 1000원, 11.1ms\n","image 18/98 /content/drive/MyDrive/Dataset/money_picture/1000_2.jpeg: 256x320 (no detections), 8.5ms\n","image 19/98 /content/drive/MyDrive/Dataset/money_picture/1000_2.jpg: 320x256 1 1000원, 8.7ms\n","image 20/98 /content/drive/MyDrive/Dataset/money_picture/1000_3.jpeg: 288x320 1 1000원, 12.7ms\n","image 21/98 /content/drive/MyDrive/Dataset/money_picture/1000_3.jpg: 320x256 1 1000원, 8.4ms\n","image 22/98 /content/drive/MyDrive/Dataset/money_picture/1000_4.jpg: 256x320 (no detections), 9.6ms\n","image 23/98 /content/drive/MyDrive/Dataset/money_picture/1000_5.jpg: 256x320 1 1000원, 8.2ms\n","image 24/98 /content/drive/MyDrive/Dataset/money_picture/1000_6.jpg: 192x320 1 1000원, 10.6ms\n","image 25/98 /content/drive/MyDrive/Dataset/money_picture/1000_7.jpg: 320x256 (no detections), 8.6ms\n","image 26/98 /content/drive/MyDrive/Dataset/money_picture/1000_8.jpg: 320x256 1 1000원, 7.9ms\n","image 27/98 /content/drive/MyDrive/Dataset/money_picture/1000_9.jpg: 256x320 (no detections), 8.6ms\n","image 28/98 /content/drive/MyDrive/Dataset/money_picture/100_1.jpeg: 320x320 1 50원, 5 100원s, 8.7ms\n","image 29/98 /content/drive/MyDrive/Dataset/money_picture/100_1.jpg: 320x320 (no detections), 8.3ms\n","image 30/98 /content/drive/MyDrive/Dataset/money_picture/100_10.jpg: 224x320 2 100원s, 8.4ms\n","image 31/98 /content/drive/MyDrive/Dataset/money_picture/100_2.jpg: 224x320 1 100원, 8.0ms\n","image 32/98 /content/drive/MyDrive/Dataset/money_picture/100_2.png: 320x320 1 100원, 8.9ms\n","image 33/98 /content/drive/MyDrive/Dataset/money_picture/100_3.jpg: 320x256 1 50원, 3 100원s, 8.7ms\n","image 34/98 /content/drive/MyDrive/Dataset/money_picture/100_3.png: 192x320 1 100원, 9.1ms\n","image 35/98 /content/drive/MyDrive/Dataset/money_picture/100_4.jpg: 320x256 1 50원, 8.6ms\n","image 36/98 /content/drive/MyDrive/Dataset/money_picture/100_5.jpg: 320x320 2 50원s, 4 500원s, 8.9ms\n","image 37/98 /content/drive/MyDrive/Dataset/money_picture/100_500_1.png: 320x320 5 500원s, 8.2ms\n","image 38/98 /content/drive/MyDrive/Dataset/money_picture/100_6.jpg: 192x320 1 100원, 9.7ms\n","image 39/98 /content/drive/MyDrive/Dataset/money_picture/100_7.jpg: 320x320 1 500원, 11.5ms\n","image 40/98 /content/drive/MyDrive/Dataset/money_picture/100_8.jpg: 256x320 2 50원s, 2 500원s, 9.1ms\n","image 41/98 /content/drive/MyDrive/Dataset/money_picture/100_9.jpg: 224x320 1 100원, 8.5ms\n","image 42/98 /content/drive/MyDrive/Dataset/money_picture/10_1.jpg: 256x320 1 50원, 8.2ms\n","image 43/98 /content/drive/MyDrive/Dataset/money_picture/10_1.png: 224x320 5 10원s, 8.4ms\n","image 44/98 /content/drive/MyDrive/Dataset/money_picture/10_10.jpg: 320x192 1 50원, 12.4ms\n","image 45/98 /content/drive/MyDrive/Dataset/money_picture/10_2.jpg: 288x320 (no detections), 11.2ms\n","image 46/98 /content/drive/MyDrive/Dataset/money_picture/10_2.png: 128x320 2 10원s, 12.1ms\n","image 47/98 /content/drive/MyDrive/Dataset/money_picture/10_3.jpg: 320x256 1 50원, 1 500원, 8.2ms\n","image 48/98 /content/drive/MyDrive/Dataset/money_picture/10_3.png: 224x320 5 10원s, 11.1ms\n","image 49/98 /content/drive/MyDrive/Dataset/money_picture/10_4.jpg: 320x160 1 100원, 10.9ms\n","image 50/98 /content/drive/MyDrive/Dataset/money_picture/10_5.jpg: 224x320 1 50원, 8.6ms\n","image 51/98 /content/drive/MyDrive/Dataset/money_picture/10_6.jpg: 320x256 (no detections), 8.3ms\n","image 52/98 /content/drive/MyDrive/Dataset/money_picture/10_7.jpg: 320x256 1 500원, 9.5ms\n","image 53/98 /content/drive/MyDrive/Dataset/money_picture/10_8.jpg: 320x192 1 100원, 8.9ms\n","image 54/98 /content/drive/MyDrive/Dataset/money_picture/10_9.jpg: 256x320 (no detections), 8.3ms\n","image 55/98 /content/drive/MyDrive/Dataset/money_picture/50000_1.jpg: 192x320 1 50000원, 9.2ms\n","image 56/98 /content/drive/MyDrive/Dataset/money_picture/50000_1.png: 320x320 (no detections), 11.4ms\n","image 57/98 /content/drive/MyDrive/Dataset/money_picture/50000_10.jpg: 160x320 1 50000원, 12.8ms\n","image 58/98 /content/drive/MyDrive/Dataset/money_picture/50000_2.jpg: 256x320 1 50000원, 8.2ms\n","image 59/98 /content/drive/MyDrive/Dataset/money_picture/50000_2.png: 256x320 (no detections), 7.6ms\n","image 60/98 /content/drive/MyDrive/Dataset/money_picture/50000_3.jpg: 256x320 1 50000원, 7.9ms\n","image 61/98 /content/drive/MyDrive/Dataset/money_picture/50000_3.png: 256x320 1 50000원, 8.3ms\n","image 62/98 /content/drive/MyDrive/Dataset/money_picture/50000_4.jpg: 320x256 1 50000원, 9.9ms\n","image 63/98 /content/drive/MyDrive/Dataset/money_picture/50000_5.jpg: 192x320 1 50000원, 10.2ms\n","image 64/98 /content/drive/MyDrive/Dataset/money_picture/50000_6.jpg: 256x320 1 50000원, 12.6ms\n","image 65/98 /content/drive/MyDrive/Dataset/money_picture/50000_7.jpg: 256x320 (no detections), 7.8ms\n","image 66/98 /content/drive/MyDrive/Dataset/money_picture/50000_8.jpg: 320x320 (no detections), 8.4ms\n","image 67/98 /content/drive/MyDrive/Dataset/money_picture/50000_9.jpg: 320x320 (no detections), 8.5ms\n","image 68/98 /content/drive/MyDrive/Dataset/money_picture/5000_1.jpg: 256x320 1 5000원, 8.0ms\n","image 69/98 /content/drive/MyDrive/Dataset/money_picture/5000_10.jpg: 224x320 (no detections), 8.0ms\n","image 70/98 /content/drive/MyDrive/Dataset/money_picture/5000_2.jpg: 192x320 1 5000원, 9.2ms\n","image 71/98 /content/drive/MyDrive/Dataset/money_picture/5000_2.png: 224x320 1 5000원, 8.4ms\n","image 72/98 /content/drive/MyDrive/Dataset/money_picture/5000_3.jpg: 256x320 1 5000원, 8.9ms\n","image 73/98 /content/drive/MyDrive/Dataset/money_picture/5000_3.png: 256x320 1 5000원, 7.9ms\n","image 74/98 /content/drive/MyDrive/Dataset/money_picture/5000_4.jpg: 256x320 1 5000원, 8.3ms\n","image 75/98 /content/drive/MyDrive/Dataset/money_picture/5000_4.png: 256x320 5 5000원s, 7.8ms\n","image 76/98 /content/drive/MyDrive/Dataset/money_picture/5000_5.jpg: 256x320 1 5000원, 8.0ms\n","image 77/98 /content/drive/MyDrive/Dataset/money_picture/5000_6.jpg: 256x320 1 5000원, 8.0ms\n","image 78/98 /content/drive/MyDrive/Dataset/money_picture/5000_7.jpg: 320x256 (no detections), 8.2ms\n","image 79/98 /content/drive/MyDrive/Dataset/money_picture/5000_8.jpg: 320x256 (no detections), 7.8ms\n","image 80/98 /content/drive/MyDrive/Dataset/money_picture/5000_9.jpg: 320x224 (no detections), 9.0ms\n","image 81/98 /content/drive/MyDrive/Dataset/money_picture/500_1.png: 256x320 1 50원, 10.6ms\n","image 82/98 /content/drive/MyDrive/Dataset/money_picture/500_2.png: 320x288 1 50원, 13.0ms\n","image 83/98 /content/drive/MyDrive/Dataset/money_picture/500_3.png: 320x320 1 50원, 9.1ms\n","image 84/98 /content/drive/MyDrive/Dataset/money_picture/500_4.png: 320x320 6 500원s, 9.1ms\n","image 85/98 /content/drive/MyDrive/Dataset/money_picture/50_1.png: 192x320 2 50원s, 8.7ms\n","image 86/98 /content/drive/MyDrive/Dataset/money_picture/50_2.png: 224x320 1 50원, 8.7ms\n","image 87/98 /content/drive/MyDrive/Dataset/money_picture/IMG_2466.JPG: 320x256 (no detections), 15.1ms\n","image 88/98 /content/drive/MyDrive/Dataset/money_picture/mixed_1.png: 256x320 2 50원s, 12.1ms\n","image 89/98 /content/drive/MyDrive/Dataset/money_picture/mixed_10.png: 256x320 1 10000원, 11.2ms\n","image 90/98 /content/drive/MyDrive/Dataset/money_picture/mixed_11.png: 288x320 1 1000원, 1 50000원, 11.6ms\n","image 91/98 /content/drive/MyDrive/Dataset/money_picture/mixed_2.png: 224x320 2 10원s, 1 50원, 1 100원, 10.9ms\n","image 92/98 /content/drive/MyDrive/Dataset/money_picture/mixed_3.png: 256x320 1 50원, 1 100원, 14.2ms\n","image 93/98 /content/drive/MyDrive/Dataset/money_picture/mixed_4.png: 320x320 5 50원s, 2 500원s, 11.7ms\n","image 94/98 /content/drive/MyDrive/Dataset/money_picture/mixed_5.png: 320x320 5 50원s, 2 500원s, 12.2ms\n","image 95/98 /content/drive/MyDrive/Dataset/money_picture/mixed_6.jpeg: 256x320 3 10원s, 10.6ms\n","image 96/98 /content/drive/MyDrive/Dataset/money_picture/mixed_7.png: 224x320 (no detections), 10.7ms\n","image 97/98 /content/drive/MyDrive/Dataset/money_picture/mixed_8.png: 224x320 (no detections), 12.7ms\n","image 98/98 /content/drive/MyDrive/Dataset/money_picture/mixed_9.png: 320x256 1 5000원, 12.7ms\n","Speed: 0.3ms pre-process, 9.7ms inference, 0.9ms NMS per image at shape (1, 3, 320, 320)\n","Results saved to \u001b[1m/content/drive/MyDrive/Dataset/images\u001b[0m\n"]}]},{"cell_type":"code","source":["from IPython.display import Image\n","from google.colab import files"],"metadata":{"id":"3vv6ZQdXgdEr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!zip -r /content/detected_images.zip /content/yolov5/detected/images"],"metadata":{"id":"nODb9tYGgfa9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files.download(filename='/content/detected_images.zip')"],"metadata":{"id":"bdq7W8rtggqb"},"execution_count":null,"outputs":[]}]}