{"cells":[{"cell_type":"markdown","metadata":{"id":"JLojLUpcGNbk"},"source":["# **차량 공유업체의 차량 파손 여부 분류하기**"]},{"cell_type":"markdown","source":["## 0.미션\n","\n","* 1) 미션1 : Data Preprocessing\n","    - **과제 수행 목표**\n","        - 본인의 구글 드라이브에 모델링 수행을 위해 적절한 폴더 및 파일로 **일관성 있게 정리**해야 합니다.\n","        - 제공된 데이터 : Car_Images.zip\n","            * Car_Images : 차량의 정상/파손 이미지 무작위 수집"],"metadata":{"id":"BbrllJY8JdkF"}},{"cell_type":"markdown","source":["* 2) 미션2 : CNN 모델링\n","    - **과제 수행 목표**\n","        - Tensorflow Keras를 이용하여 모델을 3개 이상 생성하세요.\n","            - 모델 구조와 파라미터는 자유롭게 구성하세요.\n","            - 단, 세부 목차에서 명시한 부분은 지켜주세요."],"metadata":{"id":"Hgdg96jE-mmd"}},{"cell_type":"markdown","source":["* 3) 미션3 : Data Argumentation & Transfer Learning\n","    - **과제 수행 목표**\n","        - 성능 개선을 위해 다음의 두가지를 시도하세요.\n","            * Data Augmentation을 적용하세요.(Image Generator)\n","            * Transfer Learning(VGG16)\n"],"metadata":{"id":"VRrUY4ud_rJV"}},{"cell_type":"markdown","metadata":{"id":"7MdjZtxfGNKz"},"source":["## 1.환경설정 "]},{"cell_type":"markdown","metadata":{"id":"6QgFWzN9xhlr"},"source":["### (1) 데이터셋 폴더 생성\n","- **세부요구사항**\n","    - C드라이브에 Datasets라는 폴더를 만드세요.\n","        - 구글드라이브를 사용하는경우 드라이브 첫 화면에 Datasets 라는 폴더를 만드세요. ('/content/drive/MyDrive/Datasets/')\n","    - 해당 폴더 안에 Car_Images.zip 파일을 넣으세요."]},{"cell_type":"markdown","source":["* 구글 Colab을 이용하는 경우"],"metadata":{"id":"Elg8NL8vwUs5"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"kWUbDvBzwiTq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6f5de17-8c54-40e2-a658-b078bde071c4","executionInfo":{"status":"ok","timestamp":1679460114594,"user_tz":-540,"elapsed":21141,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"0sVNbCKnLUGc"},"source":["### (2) 데이터셋 불러오기 \n","- **세부요구사항**\n","    - Car_Images.zip 파일을 C:/Datasets/ 경로에 압축 해제합니다.\n","    - zipfile 모듈을 이용하거나 다른 방식을 사용해도 됩니다.\n","        - 참고 자료 : [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n","    - 폴더구조(로컬)\n","        * C:/Datasets/ : 압축파일\n","        * C:/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n","    - 폴더구조(구글드라이브브)\n","        * /content/drive/MyDrive/Datasets/ : 압축파일\n","        * /content/drive/MyDrive/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n","    - 압축을 해제하면 다음과 같은 두 하위 폴더가 생성됩니다.\n","        * normal, abnormal : 각 폴더에는 이미지들이 있습니다.\n","        * 이후 단계에서 해당 경로로 부터 validation, test 셋을 추출하게 됩니다.\n","        "]},{"cell_type":"code","execution_count":2,"metadata":{"id":"K2-8EaA9x4Xm","executionInfo":{"status":"ok","timestamp":1679460120385,"user_tz":-540,"elapsed":353,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[],"source":["import zipfile"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"hMkstFLKx4Xm","executionInfo":{"status":"ok","timestamp":1679460150936,"user_tz":-540,"elapsed":2,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[],"source":["# 압축파일 경로\n","# 구글 드라이브인 경우 경로에 맞게 지정하세요.\n","# dataset_path  = '/content/drive/MyDrive/Datasets/'\n","dataset_path = '/content/drive/MyDrive/Datasets/'\n","\n","file_path = dataset_path + 'Car_Images.zip'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgT_RB14Lwza"},"outputs":[],"source":["# 압축 해제\n","\n","data = zipfile.ZipFile(file_path)\n","data.extractall('/content/drive/MyDrive/my_data/Car_Images_train/')"]},{"cell_type":"markdown","metadata":{"id":"8hgC0axQyMhI"},"source":["### (3) 이미지 저장을 위한 폴더 생성\n","- **세부요구사항**\n","    - train, validation, test 을 위해 각각 하위 폴더 normal과 abnormal를 준비합니다.\n","        - train\n","            * 정상 이미지 저장소 : C:/Datasets/Car_Images_train/normal/ \n","                * 구글드라이브 :   /content/drive/MyDrive/Datasets/Car_Images_train/normal/\n","            * 파손 이미지 저장소 : C:/Datasets/Car_Images_train/abnormal/\n","                * 구글드라이브 : /content/drive/MyDrive/Datasets/Car_Images_train/abnormal/\n","        - val, test 역시 동일한 구조로 생성합니다.\n","    - 직접 탐색기에서 폴더를 생성할 수도 있고, os 모듈을 이용하여 코드로 작성할 수도 있습니다.\n","        - 참고 자료 : [os document](https://docs.python.org/3/library/os.html)"]},{"cell_type":"code","source":["# 각각 경로 지정\n","tr_n_path = '/content/drive/MyDrive/my_data/Car_Images_train/normal/'\n","tr_ab_path = '/content/drive/MyDrive/my_data/Car_Images_train/abnormal/'\n","\n","val_path_n = '/content/drive/MyDrive/my_data/Car_Images_val/normal/'\n","val_path_an = '/content/drive/MyDrive/my_data/Car_Images_val/abnormal/'\n","\n","test_path_n = '/content/drive/MyDrive/my_data/Car_Images_test/normal/'\n","test_path_an = '/content/drive/MyDrive/my_data/Car_Images_test/abnormal/'"],"metadata":{"id":"bTHrIUUlwdA3","executionInfo":{"status":"ok","timestamp":1679460155109,"user_tz":-540,"elapsed":821,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rc8GnuauOzLf"},"outputs":[],"source":["# train 폴더는 압축을 해제하면서 이미 생성 되어 있습니다.\n","\n","# test 폴더 만들기 os.mkdir()\n","\n","# validation 폴더 만들기\n","\n","import os\n","\n","pass_list = [val_path_n, val_path_an, test_path_n, test_path_an]\n","\n","for path in pass_list:\n","    os.makedirs(path, exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"FYZKJrP0GtPh"},"source":["## 2.데이터 전처리"]},{"cell_type":"markdown","metadata":{"id":"j-ilpDQfInAE"},"source":["### (1) 데이터 분할 : Training set | Validation set | Test set 생성\n","- **세부요구사항**\n","    - Training set, Validation set, Test set을 만듭니다.\n","        * size\n","            * test : 전체에서 20%를 추출합니다.\n","            * validation : test를 떼어낸 나머지에서 다시 20%를 추출합니다.\n","        * 데이터는 랜덤하게 추출해야 합니다.\n","            - random, shutil 모듈을 이용하여 랜덤하게 추출할 수 있습니다.\n","                - [random document](https://docs.python.org/3/library/random.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","            * 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"]},{"cell_type":"markdown","source":["#### 1) test, validation 크기를 지정"],"metadata":{"id":"mFMSDA26RS-E"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"JhQ_Gu_KNR2g","executionInfo":{"status":"ok","timestamp":1679460161352,"user_tz":-540,"elapsed":1002,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[],"source":["import random, shutil"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PdU7X9e70dBu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"21258f5f-a2c5-4d3e-fd89-db8989d05215"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(302, 303)"]},"metadata":{},"execution_count":8}],"source":["# 전체 이미지 갯수를 확인합니다.\n","len(os.listdir(tr_n_path)) , len(os.listdir(tr_ab_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oa2mxylBDVM5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c9d04aa1-7c35-4318-e7bc-4a6b7a630cc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["[60, 61]\n","[48, 48]\n"]}],"source":["# test 사이즈 : 전체 이미지의 20%\n","te_data_num = [round(len(os.listdir(tr_n_path))*0.2), round(len(os.listdir(tr_ab_path))*0.2)]\n","print(te_data_num)\n","\n","# validation 사이즈 : test를 제외한 나머지 중에서 20%\n","val_data_num = [ round((len(os.listdir(tr_n_path))-te_data_num[0])*0.2) , round((len(os.listdir(tr_n_path))-te_data_num[1])*0.2) ]\n","print(val_data_num)\n","\n","# train 사이즈\n","train_data_num = [len(os.listdir(tr_n_path)) - te_data_num[0] - val_data_num[0],\n","                  len(os.listdir(tr_ab_path))- te_data_num[1] - val_data_num[1]]"]},{"cell_type":"markdown","source":["#### 2) test 셋 추출"],"metadata":{"id":"RmRhrViWRXgL"}},{"cell_type":"code","source":["import shutil"],"metadata":{"id":"Ct5AVFvZ9buG","executionInfo":{"status":"ok","timestamp":1679460165494,"user_tz":-540,"elapsed":429,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["print(len(os.listdir(tr_n_path)), len(os.listdir(tr_ab_path)))\n","print(len(os.listdir(test_path_n)), len(os.listdir(test_path_an)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jplkfq5gAS8K","outputId":"e7e9c56a-c32f-4241-cd60-41fc8961f1cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["302 303\n","0 0\n"]}]},{"cell_type":"code","source":["files = os.listdir(tr_n_path)\n","random.seed(2023)\n","random.shuffle(files)\n","print(files[0])\n","\n","# new_path = test_path_n\n","print('test_n 옮김: ', te_data_num[0])\n","\n","for file in files[:te_data_num[0]]:\n","    shutil.move(tr_n_path + file,test_path_n + file )\n","    # print('{} has been mobed to new folder!'.format(file))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lv1Rvs7T7-9p","outputId":"a124f5dc-2781-489e-ac4c-60d4472e3296"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DALLíñE 2023-03-11 14.32.58 - part of a car.png\n","test_n 옮김:  60\n"]}]},{"cell_type":"code","source":["files = os.listdir(tr_ab_path)\n","random.seed(2023)\n","random.shuffle(files)\n","print(files[0])\n","\n","print('test_ab 옮김: ', te_data_num[1])\n","\n","for file in files[:te_data_num[1]]:\n","    shutil.move(tr_ab_path + file,test_path_an + file )\n","    # print('{} has been mobed to new folder!'.format(file))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VdfHGEqe9P02","outputId":"3d8153dd-5396-49a4-b437-a72a7f086ff6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DALLíñE 2023-03-11 15.08.05 - dents of a car.png\n","test_ab 옮김:  61\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AImO1ujiI2IY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d377039-1af8-48f8-d386-171c3595230d"},"outputs":[{"output_type":"stream","name":"stdout","text":["242 242\n","60 61\n"]}],"source":["# 추출 후 이미지 갯수 확인\n","\n","print(len(os.listdir(tr_n_path)), len(os.listdir(tr_ab_path)))\n","print(len(os.listdir(test_path_n)), len(os.listdir(test_path_an)))"]},{"cell_type":"markdown","source":["#### 3) validation 셋 추출"],"metadata":{"id":"2V4mh3hxRpR2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXYmEdCjAEDu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8573c54b-feca-4864-8363-8df48a248611"},"outputs":[{"output_type":"stream","name":"stdout","text":["DALLíñE 2023-03-10 23.55.59 - a part of car without blemish.png\n","test_n 옮김:  48\n"]}],"source":["files = os.listdir(tr_n_path)\n","random.seed(2023)\n","random.shuffle(files)\n","print(files[0])\n","\n","print('val_n 옮김: ', val_data_num[0])\n","\n","for file in files[:val_data_num[0]]:\n","    shutil.move(tr_n_path + file,val_path_n + file )\n","    # print('{} has been mobed to new folder!'.format(file))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIT85iSdM4U-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"efbdc719-3e9c-4df9-fe1d-e0ceefcc8a57"},"outputs":[{"output_type":"stream","name":"stdout","text":["DALLíñE 2023-03-11 01.30.43 - a little bit scratched car.png\n","test_n 옮김:  48\n"]}],"source":["files = os.listdir(tr_ab_path)\n","random.seed(2023)\n","random.shuffle(files)\n","print(files[0])\n","\n","# new_path = test_path_n\n","print('val_n 옮김: ', val_data_num[1])\n","\n","for file in files[:val_data_num[1]]:\n","    shutil.move(tr_ab_path + file,val_path_an + file )\n","    # print('{} has been mobed to new folder!'.format(file))"]},{"cell_type":"code","source":["# 추출 후 이미지 갯수 확인\n","\n","print(len(os.listdir(tr_n_path)), len(os.listdir(tr_ab_path)))\n","print(len(os.listdir(val_path_n)), len(os.listdir(val_path_an)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDEAJYZe-A91","outputId":"4505a0de-2cfa-486d-89af-8a4206b93558"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["194 194\n","48 48\n"]}]},{"cell_type":"markdown","metadata":{"id":"haSO004sgyyu"},"source":["### (2) 데이터 복사 및 이동\n","- **세부요구사항**\n","    - 분할된 데이터를 복사 이동합니다.\n","        - 새로운 폴더에 저장하는 데이터로 \"3.모델링I\"에서 사용합니다.\n","        - 기존 폴더는 \"4.모델링II > (1) Data Augmentation\"에서 사용합니다.\n","    - Training set | Validation set | Test set의 데이터를 **새로운 폴더**에 복사하세요.\n","        - 새로운 폴더 명\n","            * copy_images/trainset\n","            * copy_images/validset\n","            * copy_images/testset\n","        - 새로운 폴더에는 normal, abnormal 파일 모두를 복사합니다. \n","            * 파일을 구분하기 위해 abnormal 파일들은 파일명 앞에 접두사 'ab_'를 붙입시다.\n","        - os, shutil 모듈을 활용하세요."]},{"cell_type":"markdown","source":["#### 1) abnormal 파일 복사"],"metadata":{"id":"3UbNfTY4kOSZ"}},{"cell_type":"markdown","source":["* 복사하기 : shutil.copytree()"],"metadata":{"id":"zhkKqLfTkjGI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTMVxJJJya98","colab":{"base_uri":"https://localhost:8080/"},"outputId":"78ce05ee-6e25-4e66-cedf-b874d2c88cf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["194\n","61\n","48\n"]}],"source":["copy_path = '/content/drive/MyDrive/my_data/copy_images/'\n","\n","shutil.copytree(tr_ab_path, copy_path+'trainset')\n","shutil.copytree(test_path_an, copy_path+'testset')\n","shutil.copytree(val_path_an, copy_path+'validset')\n","\n","\n","print(len(os.listdir(copy_path+'trainset')))\n","print(len(os.listdir(copy_path+'validset')))\n","print(len(os.listdir(copy_path+'testset')))"]},{"cell_type":"markdown","source":["* abnormal 이미지 이름의 접두어 \"ab_\" 붙이기 : os.rename"],"metadata":{"id":"mU0T-ypHkV6D"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cv6gafRyz6ul","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0299f73d-15b4-4a19-837e-a58ad5948fd7"},"outputs":[{"output_type":"stream","name":"stdout","text":["ab_DALLíñE 2023-03-10 18.51.24 - scratched car.png\n","ab_DALLíñE 2023-03-10 18.51.26 - scratched car.png\n","ab_DALLíñE 2023-03-10 18.51.32 - scratched car.png\n"]}],"source":["def changeName(path, cName):\n","    for filename in os.listdir(path):\n","        # print(path+filename, '=>', path+str(cName)+filename)\n","        os.rename(path+filename, path+str(cName)+filename)\n"," \n","changeName(copy_path+'trainset/','ab_')\n","changeName(copy_path+'validset/','ab_')\n","changeName(copy_path+'testset/','ab_')\n","\n","print(os.listdir(copy_path+'trainset')[0])\n","print(os.listdir(copy_path+'validset')[0])\n","print(os.listdir(copy_path+'testset')[0])"]},{"cell_type":"markdown","source":["#### 2) normal 파일 복사"],"metadata":{"id":"Nk6xITmTksyK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vw3DmdTS17RM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"decbd791-fb9f-4971-8132-e307ac21b7f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["388\n","121\n","96\n","DALLíñE 2023-03-11 17.09.48 - a part of a car.png\n","DALLíñE 2023-03-11 14.45.14 - photo of part of a car.png\n","DALLíñE 2023-03-11 14.41.37 - photo of part of a car.png\n"]}],"source":["def copy_file(path, status):\n","    copy_path = '/content/drive/MyDrive/my_data/copy_images/'\n","    files = os.listdir(path)\n","\n","    for file in files:\n","        shutil.copy(path + file, copy_path + status + file )\n","\n","copy_file(tr_n_path, 'trainset/')\n","copy_file(test_path_n, 'testset/')\n","copy_file(val_path_n, 'validset/')\n","\n","print(len(os.listdir(copy_path+'trainset')))\n","print(len(os.listdir(copy_path+'validset')))\n","print(len(os.listdir(copy_path+'testset')))\n","\n","print(os.listdir(copy_path+'trainset')[-1])\n","print(os.listdir(copy_path+'validset')[-1])\n","print(os.listdir(copy_path+'testset')[-1])"]},{"cell_type":"markdown","source":["* 데이터 갯수 조회"],"metadata":{"id":"xzEXHZrqkz88"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ugNprP9d-Gti","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f4da06c8-2bda-4ae2-f1c1-4a3050bc62c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["388\n","121\n","96\n"]}],"source":["print(len(os.listdir(dataset_path+'copy_images/trainset/')))\n","print(len(os.listdir(dataset_path+'copy_images/validset/')))\n","print(len(os.listdir(dataset_path+'copy_images/testset/')))"]},{"cell_type":"markdown","metadata":{"id":"VfYDW1Pj7ZdU"},"source":["## 3.모델링 I\n","* **세부요구사항**\n","    * 모델링을 위한 데이터 구조 만들기\n","        * x : 이미지를 array로 변환합니다.\n","        * y : 이미지 갯수만큼 normal - 0, abnormal - 1 로 array를 만듭니다.\n","    * 모델을 최소 3개 이상 만들고 성능을 비교합니다.\n","        * 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n","        * 전처리 과정에서 생성한 Validation set을 적절하게 사용하세요.\n","        * Early Stopping을 반드시 사용하세요.\n","            * 최적의 가중치를 모델에 적용하세요."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Rg553KIvxE6W","executionInfo":{"status":"ok","timestamp":1679460496147,"user_tz":-540,"elapsed":407,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VT6Ylw-mmHV8","outputId":"56e0c7af-ec25-436a-b802-d6edbc8a9c4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"wIfqg6e0xE6A"},"source":["### (1) X : image to array\n","- **세부요구사항**\n","    * 모델링을 위해서는 np.array 형태로 데이터셋을 만들어야 합니다.\n","    * Training set / Validation set / Test set의 X는 이미지 형태로 되어있습니다. \n","    * 이미지 파일을 불러와 train, valid, test 각각 array 형태로 변환해 봅시다.\n","        * 각 폴더로 부터 이미지 목록을 만들고\n","        * 이미지 한장씩 적절한 크기로 로딩하여 (keras.utils.load_img)\n","            * 이미지가 너무 크면 학습시간이 많이 걸리고, 메모리 부족현상이 발생될 수 있습니다.\n","            * 이미지 크기를 280 * 280 * 3 이내의 크기를 설정하여 로딩하시오.\n","            * array로 변환 (keras.utils.img_to_array, np.expand_dims)\n","        * 데이터셋에 추가합니다.(데이터셋도 array)"]},{"cell_type":"markdown","source":["#### 1) 이미지 목록 만들기\n","* train, validation, test 폴더로 부터 이미지 목록을 생성합니다."],"metadata":{"id":"FovkIeSDT367"}},{"cell_type":"code","source":["import os"],"metadata":{"id":"jAG6UGu3mkJE","executionInfo":{"status":"ok","timestamp":1679460212685,"user_tz":-540,"elapsed":534,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# 압축파일 경로\n","# 구글 드라이브인 경우 경로에 맞게 지정하세요.\n","dataset_path  = '/content/drive/MyDrive/my_data/'\n","# dataset_path = 'C:/Datasets/'"],"metadata":{"id":"xLZLaCZqmjjc","executionInfo":{"status":"ok","timestamp":1679460256640,"user_tz":-540,"elapsed":515,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X022f0QMxE6W","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"58bb9a07-1b83-4d25-ab77-9229851a498a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'DALLíñE 2023-03-10 18.50.11 - photo of a part of car.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}],"source":["# 이미지 목록 저장\n","img_train_list = os.listdir(dataset_path+'copy_images/trainset/')\n","img_valid_list = os.listdir(dataset_path+'copy_images/validset/')\n","img_test_list = os.listdir(dataset_path+'copy_images/testset/')\n","\n","(os.listdir(tr_n_path)[0])"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"rgvW_LQfxE6X","executionInfo":{"status":"ok","timestamp":1679460217842,"user_tz":-540,"elapsed":474,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[],"source":["# 메모리, 처리시간을 위해서 이미지 크기 조정\n","img_size = 280 ## 사이즈 조정 가능\n","# img_size = 224"]},{"cell_type":"markdown","source":["#### 2) 이미지들을 배열 데이터셋으로 만들기"],"metadata":{"id":"LSt88mjPV33u"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rhEdBiKfxE6Y"},"outputs":[],"source":["from keras.utils import load_img, img_to_array\n","\n","\n","def to_array(img_path):\n","    x = []\n","    files = os.listdir(img_path)\n","    for file in files:\n","        img = load_img(img_path + file, target_size=(img_size, img_size))\n","        # print(type(img))\n","        img_tensor = img_to_array(img)\n","        # print(type(img_tensor))\n","        # print(img)\n","        x.append(img_tensor)\n","\n","    x_np = np.array(x)\n","    \n","    return x_np\n"]},{"cell_type":"code","source":["train_x = to_array(dataset_path+'copy_images/trainset/')\n","print(train_x.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2O_Ctv1dmzX","outputId":"81609c20-d18c-45eb-c8a3-542fd0489833"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(388, 280, 280, 3)\n"]}]},{"cell_type":"code","source":["val_x = to_array(dataset_path+'copy_images/validset/')\n","print(val_x.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mBo8sh_1iPd4","outputId":"642680fe-c418-4e9c-8a9e-ac45eba8b2d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(96, 280, 280, 3)\n"]}]},{"cell_type":"code","source":["test_x = to_array(dataset_path+'copy_images/testset/')\n","print(test_x.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBBXTqTFiah9","outputId":"9fa92531-2a15-42ed-ed7a-074a92e71b67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(121, 280, 280, 3)\n"]}]},{"cell_type":"markdown","metadata":{"id":"doUM37LxxE6Z"},"source":["### (2) y : 클래스 만들기\n","- **세부요구사항**\n","    - Training set / Validation set / Test set의 y를 생성합니다.\n","        - 각각 normal, abnormal 데이터의 갯수를 다시 확인하고\n","        - normal을 0, abnormal을 1로 지정합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nl1Uv9UxE6b","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa13616e-0ec4-4d6b-ff08-9b91b003f91d"},"outputs":[{"output_type":"stream","name":"stdout","text":["388\n","194\n","---\n","96\n","48\n","---\n","121\n","61\n"]}],"source":["# 데이터 갯수 확인\n","print( len(img_train_list) )\n","print( len([val for val in img_train_list if val.startswith('ab_')]) )\n","print('---')\n","print( len(img_valid_list) )\n","print( len([val for val in img_valid_list if val.startswith('ab_')]) )\n","print('---')\n","print( len(img_test_list) )\n","print( len([val for val in img_test_list if val.startswith('ab_')]) )"]},{"cell_type":"markdown","source":["* y_train, y_valid, y_test 만들기\n","    * normal, abnormal 데이터의 갯수를 다시 확인하고 normal을 0, abnormal을 1로 지정합니다."],"metadata":{"id":"HIfaCLlNn04C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVrPQdhTxE6b"},"outputs":[],"source":["def get_y(dlist):\n","    y = []\n","    for val in dlist:\n","        if val.startswith('ab_'):\n","            y.append(1)\n","        else:\n","            y.append(0)\n","    y_np = np.array(y)\n","\n","    return y_np"]},{"cell_type":"code","source":["train_y = get_y(img_train_list)\n","train_y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBZySXb0uEoX","outputId":"d41f4ba8-1977-4b9c-f8f4-aa546cd9876f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(388,)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["val_y = get_y(img_valid_list)\n","val_y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JbWVuvzuuM5B","outputId":"e2a2f035-b2ba-464f-917f-bbc951e18529"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(96,)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["test_y = get_y(img_test_list)\n","test_y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bSd5sTN8uVDn","outputId":"0392aa1f-02f9-46ff-fa79-587ca727fc66"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(121,)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["print(f'max: {train_x.max()}, min: {train_x.min()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BAEuq-li1Iwi","outputId":"295239b5-4426-4ac9-d888-28d8ca5d4c36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["max: 255.0, min: 0.0\n"]}]},{"cell_type":"code","source":["# train_x.shape, train_y.shape, test_x.shape, test_y.shape\n","mean_x = train_x.mean()\n","std_x = train_x.std()\n","\n","mean_x, std_x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DBtddcJ2qiy","outputId":"95d659a0-2f37-4b48-b333-9951c10feef3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(127.13476, 65.64915)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["max_x = train_x.max()\n","min_x = train_x.min()"],"metadata":{"id":"-wE81Pqn8wro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x_s = (train_x - mean_x) / std_x\n","val_x_s = (val_x - mean_x) / std_x\n","test_x_s = (test_x - mean_x) / std_x"],"metadata":{"id":"AueTu3W31O9b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_x_minmax = (test_x - min_x) / (max_x - min_x)"],"metadata":{"id":"j6X5uZfN8rnB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'max: {test_x_minmax.max()}, min: {test_x_minmax.min()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RFoBOykf883K","outputId":"804d7e76-1d14-4556-8b22-25a9ba98b543"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["max: 1.0, min: 0.0\n"]}]},{"cell_type":"code","source":["train_x_s.mean(), train_x_s.std()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GV4nFLcs28An","outputId":"056adb7c-ef58-47a5-d0e1-0d1c3266d2dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(-1.8170322e-06, 0.9999961)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"Z586wXFu7ZgT"},"source":["### (3) 모델1\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 validation_data로 validation set을 사용하시오.\n","    - 반드시 Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"markdown","source":["#### 1) 구조 설계"],"metadata":{"id":"NIvIO6RKa0mp"}},{"cell_type":"code","source":["print(train_x_s.shape, val_x_s.shape, test_x_s.shape)\n","print(train_y.shape, val_y.shape, test_y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mT3-vQMyvA_X","outputId":"40132019-c8e2-4210-bd67-dcfeeacbf65f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(388, 224, 224, 3) (96, 224, 224, 3) (121, 224, 224, 3)\n","(388,) (96,) (121,)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TtIIz6XJQ5E","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd8b0f79-c991-4607-ff12-51aeeed4f325"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 280, 280, 64)      1792      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 280, 280, 64)      36928     \n","                                                                 \n"," batch_normalization (BatchN  (None, 280, 280, 64)     256       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 140, 140, 64)     0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 140, 140, 64)      0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 140, 140, 32)      18464     \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 140, 140, 32)     128       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 140, 140, 64)      18496     \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 140, 140, 64)     256       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 70, 70, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 70, 70, 64)        0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 70, 70, 128)       73856     \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 70, 70, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," dropout_2 (Dropout)         (None, 70, 70, 128)       0         \n","                                                                 \n"," flatten (Flatten)           (None, 627200)            0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 627201    \n","                                                                 \n","=================================================================\n","Total params: 777,889\n","Trainable params: 777,313\n","Non-trainable params: 576\n","_________________________________________________________________\n"]}],"source":["# 1. session_clear\n","keras.backend.clear_session()\n","\n","# 2. sequential model 선언\n","model = keras.models.Sequential()\n","\n","# 3. layer 하나씩 쌓기\n","# input layer\n","model.add(keras.layers.Input(shape=(280, 280, 3)))\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=64,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","model.add(keras.layers.Conv2D(filters=64,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","# BatchNormalization\n","model.add( keras.layers.BatchNormalization())\n","# Max Pooling\n","model.add( keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","model.add( keras.layers.Dropout(0.25))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=32,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","# BatchNormalization\n","model.add( keras.layers.BatchNormalization())\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=64,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","# BatchNormalization\n","model.add( keras.layers.BatchNormalization())\n","\n","# Max Pooling\n","model.add( keras.layers.MaxPool2D(pool_size=(2,2)))\n","model.add( keras.layers.Dropout(0.25))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","# BatchNormalization\n","model.add( keras.layers.BatchNormalization())\n","# Max Pooling\n","model.add( keras.layers.Dropout(0.25))\n","\n","# Flatten\n","model.add( keras.layers.Flatten())\n","model.add( keras.layers.global())\n","\n","# Dense\n","model.add( keras.layers.Dense(1, activation='sigmoid'))\n","\n","# 4. compile\n","model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n","\n","# 5. summary\n","model.summary()"]},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"DHM91_bha3Kc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OHnFVZuKa42f"},"outputs":[],"source":["es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   patience = 5,\n","                   verbose = 1,\n","                   restore_best_weights = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BnrTSupKa42f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7231edef-02d9-4d50-d588-54960233395d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","13/13 [==============================] - 17s 793ms/step - loss: 4.7079 - accuracy: 0.6959 - val_loss: 69.6654 - val_accuracy: 0.4711\n","Epoch 2/1000\n","13/13 [==============================] - 6s 485ms/step - loss: 2.2324 - accuracy: 0.8531 - val_loss: 13.9962 - val_accuracy: 0.4298\n","Epoch 3/1000\n","13/13 [==============================] - 7s 511ms/step - loss: 2.4022 - accuracy: 0.8840 - val_loss: 21.0141 - val_accuracy: 0.4463\n","Epoch 4/1000\n","13/13 [==============================] - 6s 481ms/step - loss: 1.9093 - accuracy: 0.8943 - val_loss: 87.1005 - val_accuracy: 0.4959\n","Epoch 5/1000\n","13/13 [==============================] - 6s 484ms/step - loss: 1.2487 - accuracy: 0.9227 - val_loss: 15.4594 - val_accuracy: 0.6446\n","Epoch 6/1000\n","13/13 [==============================] - 6s 483ms/step - loss: 0.9553 - accuracy: 0.9330 - val_loss: 50.4482 - val_accuracy: 0.4793\n","Epoch 7/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.7190 - accuracy: 0.9562Restoring model weights from the end of the best epoch: 2.\n","13/13 [==============================] - 6s 491ms/step - loss: 0.7190 - accuracy: 0.9562 - val_loss: 21.6940 - val_accuracy: 0.5124\n","Epoch 7: early stopping\n"]}],"source":["hist = model.fit(train_x, train_y, validation_data=(val_x, val_y),\n","                 batch_size=32, epochs=1000, callbacks=[es], verbose=1)"]},{"cell_type":"markdown","source":["#### 3) test set으로 예측하고 평가하기\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"zage6-Z0a6DX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xkFFlFdbBZb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"37f93e3a-aa4d-4cf7-a3ac-127b1bc4ea47"},"outputs":[{"output_type":"stream","name":"stdout","text":["3/3 [==============================] - 0s 101ms/step\n"]}],"source":["y_pred = model.predict(test_x)"]},{"cell_type":"code","source":["print(test_y[:10])\n","print(y_pred[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JNxCoeG_EH0_","outputId":"61ecca3d-1ebf-48a5-bbc1-97b1658058de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 1 1 1 1 1 1 1 1]\n","[[3.8222346e-23]\n"," [3.3873271e-19]\n"," [5.2595750e-21]\n"," [1.4843350e-21]\n"," [3.8292855e-11]\n"," [1.1446760e-05]\n"," [1.0392097e-21]\n"," [9.5180787e-11]\n"," [1.0000000e+00]\n"," [2.4906730e-02]]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-EQFVkCbBZc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5d0e8722-73be-47a6-89ab-cb004bd6f856"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 7s 7s/step - loss: 13.8990 - accuracy: 0.4896\n"]}],"source":["performance_test = model.evaluate(test_x, test_y, batch_size=100)"]},{"cell_type":"code","source":["print('Test Loss : {:.6f},  Test Accuracy : {:.3f}%'.format(performance_test[0], performance_test[1]*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hkHiOaziFHzu","outputId":"9100b451-0e7e-4fcf-8b7d-d957a28970fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss : 13.899045,  Test Accuracy : 48.958%\n"]}]},{"cell_type":"code","source":["preds_1d = y_pred.flatten() # 차원 펴주기\n","pred_class = np.where(preds_1d > 0.5, 1 , 0) #0.5보다크면 2, 작으면 1"],"metadata":{"id":"ZxnW8_wiHEOW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_class"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-vNk8sNHkUb","outputId":"e31daaaf-898d-44c4-a875-33c1495000d9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n","       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","       0, 0, 0, 0, 0, 0, 0, 1])"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["test_y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVOT86g_H-QL","outputId":"3577ee6f-1e9c-4755-d2f5-72fcf99065d2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0])"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","\n","print(confusion_matrix(test_y, pred_class))\n","print(classification_report(test_y, pred_class))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xjv7b1MIF7CB","outputId":"0d8afb34-b2ad-4bb9-933e-a799bf9d7774"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[43  5]\n"," [44  4]]\n","              precision    recall  f1-score   support\n","\n","           0       0.49      0.90      0.64        48\n","           1       0.44      0.08      0.14        48\n","\n","    accuracy                           0.49        96\n","   macro avg       0.47      0.49      0.39        96\n","weighted avg       0.47      0.49      0.39        96\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"qRoacK2mcLPb"},"source":["### (4) 모델2\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 validation_data로 validation set을 사용하시오.\n","    - 반드시 Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"markdown","source":["#### 1) 구조 설계"],"metadata":{"id":"5WTwG8NFoLBQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHu5gey1oLBR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"57a5779f-12bb-41af-d2f1-43ffd24a9d1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(388, 280, 280, 3) (121, 280, 280, 3) (96, 280, 280, 3)\n","(388,) (121,) (96,)\n"]}],"source":["print(train_x_s.shape, val_x_s.shape, test_x_s.shape)\n","print(train_y.shape, val_y.shape, test_y.shape)"]},{"cell_type":"code","source":["# 1. session_clear\n","keras.backend.clear_session()\n","\n","# 2. sequential model 선언\n","model = keras.models.Sequential()\n","\n","# 3. layer 하나씩 쌓기\n","# input layer\n","model.add(keras.layers.Input(shape=(280, 280, 3)))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","# BatchNormalization\n","model.add( keras.layers.BatchNormalization())\n","# Max Pooling\n","model.add( keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","model.add( keras.layers.Dropout(0.05))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=256,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","# BatchNormalization\n","model.add( keras.layers.BatchNormalization())\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=256,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","# BatchNormalization\n","model.add( keras.layers.BatchNormalization())\n","\n","# Max Pooling\n","model.add( keras.layers.MaxPool2D(pool_size=(2,2)))\n","model.add( keras.layers.Dropout(0.1))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=64,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","# BatchNormalization\n","model.add( keras.layers.BatchNormalization())\n","# Max Pooling\n","model.add( keras.layers.Dropout(0.25))\n","\n","# Flatten\n","model.add( keras.layers.Flatten())\n","# model.add( keras.layers.global())\n","\n","# Dense\n","model.add( keras.layers.Dense(1, activation='sigmoid'))\n","\n","# 4. compile\n","model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n","\n","# 5. summary\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-TYB_KJIr6Y","outputId":"a82ae1cc-936d-4dc1-a820-9ec98a0386c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 280, 280, 128)     3584      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 280, 280, 128)     147584    \n","                                                                 \n"," batch_normalization (BatchN  (None, 280, 280, 128)    512       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 140, 140, 128)    0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 140, 140, 128)     0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 140, 140, 256)     295168    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 140, 140, 256)    1024      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 140, 140, 256)     590080    \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 140, 140, 256)    1024      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 70, 70, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 70, 70, 256)       0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 70, 70, 64)        147520    \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 70, 70, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," dropout_2 (Dropout)         (None, 70, 70, 64)        0         \n","                                                                 \n"," flatten (Flatten)           (None, 313600)            0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 313601    \n","                                                                 \n","=================================================================\n","Total params: 1,500,353\n","Trainable params: 1,498,945\n","Non-trainable params: 1,408\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"DqTzgRTroLBR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lcVDXnpQoLBR"},"outputs":[],"source":["es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   patience = 7,\n","                   verbose = 1,\n","                   restore_best_weights = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UAhXnGmXoLBS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"988a5605-1be1-4c0c-c934-7ad02a7b68d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","13/13 [==============================] - 40s 2s/step - loss: 5.1244 - accuracy: 0.7036 - val_loss: 473.6449 - val_accuracy: 0.4628\n","Epoch 2/1000\n","13/13 [==============================] - 21s 2s/step - loss: 4.6812 - accuracy: 0.7938 - val_loss: 412.6552 - val_accuracy: 0.5124\n","Epoch 3/1000\n","13/13 [==============================] - 21s 2s/step - loss: 2.1985 - accuracy: 0.8557 - val_loss: 403.9130 - val_accuracy: 0.4628\n","Epoch 4/1000\n","13/13 [==============================] - 22s 2s/step - loss: 1.4649 - accuracy: 0.8969 - val_loss: 86.0789 - val_accuracy: 0.4545\n","Epoch 5/1000\n","13/13 [==============================] - 21s 2s/step - loss: 1.3364 - accuracy: 0.8969 - val_loss: 205.4527 - val_accuracy: 0.4298\n","Epoch 6/1000\n","13/13 [==============================] - 21s 2s/step - loss: 1.0804 - accuracy: 0.9381 - val_loss: 119.9389 - val_accuracy: 0.4463\n","Epoch 7/1000\n","13/13 [==============================] - 22s 2s/step - loss: 1.3591 - accuracy: 0.9046 - val_loss: 262.2880 - val_accuracy: 0.4876\n","Epoch 8/1000\n","13/13 [==============================] - 22s 2s/step - loss: 1.4525 - accuracy: 0.9227 - val_loss: 46.3564 - val_accuracy: 0.5455\n","Epoch 9/1000\n","13/13 [==============================] - 22s 2s/step - loss: 0.8756 - accuracy: 0.9330 - val_loss: 17.3214 - val_accuracy: 0.7355\n","Epoch 10/1000\n","13/13 [==============================] - 21s 2s/step - loss: 0.5050 - accuracy: 0.9691 - val_loss: 62.8831 - val_accuracy: 0.4959\n","Epoch 11/1000\n","13/13 [==============================] - 21s 2s/step - loss: 0.4118 - accuracy: 0.9510 - val_loss: 13.2341 - val_accuracy: 0.7025\n","Epoch 12/1000\n","13/13 [==============================] - 21s 2s/step - loss: 0.4426 - accuracy: 0.9691 - val_loss: 11.7714 - val_accuracy: 0.7190\n","Epoch 13/1000\n","13/13 [==============================] - 22s 2s/step - loss: 0.1508 - accuracy: 0.9820 - val_loss: 13.0067 - val_accuracy: 0.7355\n","Epoch 14/1000\n","13/13 [==============================] - 22s 2s/step - loss: 0.1500 - accuracy: 0.9923 - val_loss: 8.8316 - val_accuracy: 0.7934\n","Epoch 15/1000\n","13/13 [==============================] - 22s 2s/step - loss: 0.0307 - accuracy: 0.9871 - val_loss: 7.3633 - val_accuracy: 0.7851\n","Epoch 16/1000\n","13/13 [==============================] - 22s 2s/step - loss: 0.0585 - accuracy: 0.9948 - val_loss: 6.0210 - val_accuracy: 0.7851\n","Epoch 17/1000\n","13/13 [==============================] - 22s 2s/step - loss: 0.0206 - accuracy: 0.9948 - val_loss: 5.6258 - val_accuracy: 0.8512\n","Epoch 18/1000\n","13/13 [==============================] - 21s 2s/step - loss: 0.1455 - accuracy: 0.9871 - val_loss: 7.7931 - val_accuracy: 0.7934\n","Epoch 19/1000\n","13/13 [==============================] - 22s 2s/step - loss: 0.0893 - accuracy: 0.9923 - val_loss: 10.0871 - val_accuracy: 0.7686\n","Epoch 20/1000\n","13/13 [==============================] - 21s 2s/step - loss: 0.1468 - accuracy: 0.9845 - val_loss: 7.7310 - val_accuracy: 0.8017\n","Epoch 21/1000\n","13/13 [==============================] - 22s 2s/step - loss: 1.3374e-06 - accuracy: 1.0000 - val_loss: 8.2629 - val_accuracy: 0.7934\n","Epoch 22/1000\n","13/13 [==============================] - 21s 2s/step - loss: 0.0026 - accuracy: 0.9974 - val_loss: 7.6313 - val_accuracy: 0.8264\n","Epoch 23/1000\n","13/13 [==============================] - 22s 2s/step - loss: 4.7692e-06 - accuracy: 1.0000 - val_loss: 7.2329 - val_accuracy: 0.8099\n","Epoch 24/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 17.\n","13/13 [==============================] - 22s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.2914 - val_accuracy: 0.8017\n","Epoch 24: early stopping\n"]}],"source":["hist = model.fit(train_x, train_y, validation_data=(val_x, val_y),\n","                 batch_size=32, epochs=1000, callbacks=[es], verbose=1)"]},{"cell_type":"markdown","source":["#### 3) test set으로 예측하고 평가하기\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"qxZ0U7K1oLBS"}},{"cell_type":"code","source":["test_y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rltZ4roNDP9","outputId":"6708cfb4-9451-4aa6-ccf4-b2b619419c9f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(96,)"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ShruikbsoLBS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b594f360-5a4f-447f-8f91-86ea361ab7da"},"outputs":[{"output_type":"stream","name":"stdout","text":["3/3 [==============================] - 1s 286ms/step\n"]}],"source":["y_pred = model.predict(test_x)"]},{"cell_type":"code","source":["performance_score = model.evaluate(test_x, test_y, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ooFfvJVMvGC","outputId":"23346e08-2873-4bed-d0d2-b0640eb1db13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3/3 [==============================] - 1s 274ms/step - loss: 4.2703 - accuracy: 0.8438\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8MC8l07oLBS"},"outputs":[],"source":["preds_1d = y_pred.flatten() # 차원 펴주기\n","pred_class = np.where(preds_1d > 0.5, 1 , 0) #0.5보다크면 2, 작으면 1"]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report"],"metadata":{"id":"3CcwOIWXN9yo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(confusion_matrix(test_y, pred_class))\n","print(classification_report(test_y, pred_class))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gt6VUrjpOJgG","outputId":"dd4f4834-381c-4dce-ec8e-f5bcd0163e06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[36 12]\n"," [ 3 45]]\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.75      0.83        48\n","           1       0.79      0.94      0.86        48\n","\n","    accuracy                           0.84        96\n","   macro avg       0.86      0.84      0.84        96\n","weighted avg       0.86      0.84      0.84        96\n","\n"]}]},{"cell_type":"code","source":["\n","# 1. session_clear\n","keras.backend.clear_session()\n","\n","# 2. sequential model 선언\n","model = keras.models.Sequential()\n","\n","# 3. layer 하나씩 쌓기\n","# input layer\n","model.add(keras.layers.Input(shape=(280, 280, 3)))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","model.add( keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","# Flatten\n","model.add( keras.layers.Flatten())\n","# model.add( keras.layers.global())\n","\n","# Dense\n","model.add( keras.layers.Dense(128))\n","model.add( keras.layers.Dense(128))\n","model.add( keras.layers.Dense(1, activation='sigmoid'))\n","\n","# 4. compile\n","model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n","\n","# 5. summary\n","model.summary()"],"metadata":{"id":"G7FVsFiCFSGa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dc676406-159b-42b6-e505-40e066182846"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 280, 280, 128)     3584      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 280, 280, 128)     147584    \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 280, 280, 128)     147584    \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 280, 280, 128)     147584    \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 280, 280, 128)     147584    \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 280, 280, 128)     147584    \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 280, 280, 128)     147584    \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 280, 280, 128)     147584    \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 140, 140, 128)    0         \n"," )                                                               \n","                                                                 \n"," flatten (Flatten)           (None, 2508800)           0         \n","                                                                 \n"," dense (Dense)               (None, 128)               321126528 \n","                                                                 \n"," dense_1 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 322,179,841\n","Trainable params: 322,179,841\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["y_pred = model.predict(test_x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKuLA6sGqmZC","outputId":"9da41002-14bd-4cff-c886-7cfcd70f11bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3/3 [==============================] - 3s 819ms/step\n"]}]},{"cell_type":"code","source":["performance_score = model.evaluate(test_x, test_y, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VTCjJsijq5Bx","outputId":"61ccd4dc-92e8-4357-dba4-11aa5331af66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3/3 [==============================] - 3s 837ms/step - loss: 1.9228 - accuracy: 0.5104\n"]}]},{"cell_type":"code","source":["preds_1d = y_pred.flatten() # 차원 펴주기\n","pred_class = np.where(preds_1d > 0.5, 1 , 0) #0.5보다크면 2, 작으면 1"],"metadata":{"id":"H886jxnoq7Wa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","print(confusion_matrix(test_y, pred_class))\n","print(classification_report(test_y, pred_class))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmEeOQxVq9nh","outputId":"29fcdb9b-76c6-4492-c720-06801271b65d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1 47]\n"," [ 0 48]]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.02      0.04        48\n","           1       0.51      1.00      0.67        48\n","\n","    accuracy                           0.51        96\n","   macro avg       0.75      0.51      0.36        96\n","weighted avg       0.75      0.51      0.36        96\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"MRqzBw8eccwj"},"source":["### (5) 모델3\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 validation_data로 validation set을 사용하시오.\n","    - 반드시 Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"markdown","source":["#### 1) 구조 설계"],"metadata":{"id":"LtNd8u5RoNJo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KM-Npn6WoNJo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"797dfe60-848e-4af6-8170-86fc8308d785"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 280, 280, 64)      1792      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 280, 280, 64)      36928     \n","                                                                 \n"," batch_normalization (BatchN  (None, 280, 280, 64)     256       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 140, 140, 64)     0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 140, 140, 128)     73856     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 140, 140, 128)     147584    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 140, 140, 128)    512       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 70, 70, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 70, 70, 256)       295168    \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 70, 70, 256)       590080    \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 70, 70, 256)       590080    \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 35, 35, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 35, 35, 512)       1180160   \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 35, 35, 512)       2359808   \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 35, 35, 512)       2359808   \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 17, 17, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 17, 17, 512)       2359808   \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 17, 17, 512)       2359808   \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 17, 17, 512)       2359808   \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 8, 8, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 14,715,969\n","Trainable params: 14,715,585\n","Non-trainable params: 384\n","_________________________________________________________________\n"]}],"source":["# VGGNet\n","\n","# 1. session_clear\n","keras.backend.clear_session()\n","\n","# 2. sequential model 선언\n","model = keras.models.Sequential()\n","\n","# 3. layer 하나씩 쌓기\n","# input layer\n","model.add(keras.layers.Input(shape=(280, 280, 3)))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=64, \n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","model.add(keras.layers.Conv2D(filters=64,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","# BatchNormalization\n","model.add( keras.layers.BatchNormalization())\n","# Max Pooling\n","model.add( keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","# Convolution filter\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","model.add(keras.layers.Conv2D(filters=128,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","# BatchNormalization\n","model.add( keras.layers.BatchNormalization())\n","# MaxPool\n","model.add( keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","model.add(keras.layers.Conv2D(filters=256,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","model.add(keras.layers.Conv2D(filters=256,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","model.add(keras.layers.Conv2D(filters=256,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","# MaxPool\n","model.add( keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","model.add(keras.layers.Conv2D(filters=512,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","model.add(keras.layers.Conv2D(filters=512,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","model.add(keras.layers.Conv2D(filters=512,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","# MaxPool\n","model.add( keras.layers.MaxPool2D(pool_size=(2,2)))\n","# 여기서 사이즈기 35*35 가 되는데 다음 maxpooling 시 어떻게 처리되는 거지?\n","\n","model.add(keras.layers.Conv2D(filters=512,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","model.add(keras.layers.Conv2D(filters=512,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","model.add(keras.layers.Conv2D(filters=512,\n","                              kernel_size=(3, 3),\n","                              padding='same',\n","                              strides=(1,1),\n","                              activation='relu'))\n","\n","model.add( keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","# Flatten\n","# model.add( keras.layers.Flatten())\n","# model.add( keras.layers.global())\n","model.add(tf.keras.layers.GlobalAveragePooling2D())\n","\n","# Dense\n","# model.add( keras.layers.Dense(4096))\n","# model.add( keras.layers.Dense(4096))\n","model.add( keras.layers.Dense(1, activation='sigmoid'))\n","\n","# 4. compile\n","model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n","\n","# 5. summary\n","model.summary()"]},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"4zgVkXLHoNJo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTlUNbkhoNJo"},"outputs":[],"source":["es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   patience = 8,\n","                   verbose = 1,\n","                   restore_best_weights = True)"]},{"cell_type":"code","source":["es2 = EarlyStopping(monitor = 'val_accuracy',\n","                   min_delta = 0,\n","                   patience = 8,\n","                   verbose = 1,\n","                   restore_best_weights = True)"],"metadata":{"id":"cZ0306IcIQi7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4GYo0dboNJo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf37b14b-25b2-4d53-e1a0-1a337a5b0f9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","13/13 [==============================] - 9s 692ms/step - loss: 0.6205 - accuracy: 0.6521 - val_loss: 0.7415 - val_accuracy: 0.6146\n","Epoch 2/1000\n","13/13 [==============================] - 9s 687ms/step - loss: 0.4400 - accuracy: 0.8222 - val_loss: 0.4111 - val_accuracy: 0.8125\n","Epoch 3/1000\n","13/13 [==============================] - 10s 746ms/step - loss: 0.3924 - accuracy: 0.8093 - val_loss: 0.4234 - val_accuracy: 0.8646\n","Epoch 4/1000\n","13/13 [==============================] - 9s 686ms/step - loss: 0.3144 - accuracy: 0.8711 - val_loss: 0.3275 - val_accuracy: 0.8646\n","Epoch 5/1000\n","13/13 [==============================] - 9s 681ms/step - loss: 0.3437 - accuracy: 0.8351 - val_loss: 0.2632 - val_accuracy: 0.8958\n","Epoch 6/1000\n","13/13 [==============================] - 9s 672ms/step - loss: 0.3148 - accuracy: 0.8686 - val_loss: 0.4276 - val_accuracy: 0.8229\n","Epoch 7/1000\n","13/13 [==============================] - 9s 671ms/step - loss: 0.3101 - accuracy: 0.8763 - val_loss: 0.4005 - val_accuracy: 0.8542\n","Epoch 8/1000\n","13/13 [==============================] - 9s 672ms/step - loss: 0.2840 - accuracy: 0.8711 - val_loss: 0.3338 - val_accuracy: 0.9062\n","Epoch 9/1000\n","13/13 [==============================] - 9s 674ms/step - loss: 0.2558 - accuracy: 0.8918 - val_loss: 0.3412 - val_accuracy: 0.9271\n","Epoch 10/1000\n","13/13 [==============================] - 9s 677ms/step - loss: 0.2450 - accuracy: 0.8969 - val_loss: 0.3999 - val_accuracy: 0.8958\n","Epoch 11/1000\n","13/13 [==============================] - 9s 677ms/step - loss: 0.2205 - accuracy: 0.9046 - val_loss: 0.4174 - val_accuracy: 0.8750\n","Epoch 12/1000\n","13/13 [==============================] - 9s 679ms/step - loss: 0.2970 - accuracy: 0.8660 - val_loss: 0.6704 - val_accuracy: 0.5833\n","Epoch 13/1000\n","13/13 [==============================] - 9s 675ms/step - loss: 0.2781 - accuracy: 0.9046 - val_loss: 0.6558 - val_accuracy: 0.6250\n","Epoch 14/1000\n","13/13 [==============================] - 9s 675ms/step - loss: 0.3284 - accuracy: 0.8531 - val_loss: 0.4643 - val_accuracy: 0.8333\n","Epoch 15/1000\n","13/13 [==============================] - 9s 678ms/step - loss: 0.2813 - accuracy: 0.8711 - val_loss: 0.3742 - val_accuracy: 0.8750\n","Epoch 16/1000\n","13/13 [==============================] - 9s 678ms/step - loss: 0.2454 - accuracy: 0.8943 - val_loss: 0.3840 - val_accuracy: 0.8333\n","Epoch 17/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.8943Restoring model weights from the end of the best epoch: 9.\n","13/13 [==============================] - 9s 681ms/step - loss: 0.3021 - accuracy: 0.8943 - val_loss: 0.3529 - val_accuracy: 0.8854\n","Epoch 17: early stopping\n"]}],"source":["hist = model.fit(train_x, train_y, validation_data=(val_x, val_y),\n","                 batch_size=32, epochs=1000, callbacks=[es2], verbose=1)"]},{"cell_type":"markdown","source":["#### 3) test set으로 예측하고 평가하기\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"uZV9zbsroNJo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sc9UmjZ0oNJo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"521c9121-0144-44ba-8c4e-054b47dc3350"},"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 214ms/step\n"]}],"source":["y_pred = model.predict(test_x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aP-p0_y9oNJo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a5ef7a7-0c6a-42e1-fa06-8d5346c90b1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 196ms/step - loss: 0.4025 - accuracy: 0.8430\n"]}],"source":["performance_test = model.evaluate(test_x, test_y, batch_size=32)"]},{"cell_type":"code","source":["print('Test Loss : {:.6f},  Test Accuracy : {:.3f}%'.format(performance_test[0], performance_test[1]*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hBpSJncvla_","outputId":"b59fb97a-252e-450f-cccc-61ce7b54b71f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss : 0.402522,  Test Accuracy : 84.298%\n"]}]},{"cell_type":"code","source":["preds_1d = y_pred.flatten() # 차원 펴주기\n","pred_class = np.where(preds_1d > 0.5, 1 , 0) #0.5보다크면 2, 작으면 1"],"metadata":{"id":"rhEZGdZClwFV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","\n","print(confusion_matrix(test_y, pred_class))\n","print(classification_report(test_y, pred_class))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dXklGxXLlxZO","outputId":"a4dd75d9-ff76-4a39-cf95-289dac337ba3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[54  6]\n"," [13 48]]\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.90      0.85        60\n","           1       0.89      0.79      0.83        61\n","\n","    accuracy                           0.84       121\n","   macro avg       0.85      0.84      0.84       121\n","weighted avg       0.85      0.84      0.84       121\n","\n"]}]},{"cell_type":"markdown","source":["scaling data"],"metadata":{"id":"uKh6BuE61uTS"}},{"cell_type":"code","source":["# scaling data\n","hist = model.fit(train_x_s, train_y, validation_data=(val_x_s, val_y),\n","                 batch_size=32, epochs=1000, callbacks=[es], verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KCdv0xR6uXMP","outputId":"86cbd041-441b-4446-fd7e-063106c34df5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","13/13 [==============================] - 16s 651ms/step - loss: 0.7108 - accuracy: 0.5954 - val_loss: 0.7204 - val_accuracy: 0.5104\n","Epoch 2/1000\n","13/13 [==============================] - 5s 421ms/step - loss: 0.4841 - accuracy: 0.7938 - val_loss: 2.7834 - val_accuracy: 0.5000\n","Epoch 3/1000\n","13/13 [==============================] - 5s 419ms/step - loss: 0.4296 - accuracy: 0.8299 - val_loss: 3.0467 - val_accuracy: 0.5000\n","Epoch 4/1000\n","13/13 [==============================] - 6s 440ms/step - loss: 0.4137 - accuracy: 0.8222 - val_loss: 2.4939 - val_accuracy: 0.5000\n","Epoch 5/1000\n","13/13 [==============================] - 5s 413ms/step - loss: 0.4722 - accuracy: 0.8067 - val_loss: 4.5454 - val_accuracy: 0.5000\n","Epoch 6/1000\n","13/13 [==============================] - 6s 434ms/step - loss: 0.5047 - accuracy: 0.7861 - val_loss: 3.5066 - val_accuracy: 0.5000\n","Epoch 7/1000\n","13/13 [==============================] - 6s 433ms/step - loss: 0.3683 - accuracy: 0.8479 - val_loss: 2.2549 - val_accuracy: 0.5000\n","Epoch 8/1000\n","13/13 [==============================] - 6s 430ms/step - loss: 0.3186 - accuracy: 0.8814 - val_loss: 2.4677 - val_accuracy: 0.5000\n","Epoch 9/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.8763Restoring model weights from the end of the best epoch: 1.\n","13/13 [==============================] - 6s 438ms/step - loss: 0.3345 - accuracy: 0.8763 - val_loss: 4.8660 - val_accuracy: 0.5000\n","Epoch 9: early stopping\n"]}]},{"cell_type":"code","source":["# scaling data\n","y_pred_s = model.predict(test_x_s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PsilHcoSwujt","outputId":"72662b07-efa4-479f-faac-0bb9635dda18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 3s 908ms/step\n"]}]},{"cell_type":"code","source":["# scaling data\n","performance_test_s = model.evaluate(test_x_s, test_y, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iRnhVdNPw4ee","outputId":"36360803-0229-4fad-97c5-04da5a3a2ec5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 128ms/step - loss: 0.7084 - accuracy: 0.5207\n"]}]},{"cell_type":"code","source":["# scaling data\n","print('Test Loss : {:.6f},  Test Accuracy : {:.3f}%'.format(performance_test_s[0], performance_test_s[1]*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dF9Q0lpPw_de","outputId":"232621cc-0d14-4449-a9a9-6e70e2d8370a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss : 0.708392,  Test Accuracy : 52.066%\n"]}]},{"cell_type":"code","source":["# scaling\n","preds_1d_s = y_pred_s.flatten() # 차원 펴주기\n","pred_class_s = np.where(preds_1d_s > 0.5, 1 , 0) #0.5보다크면 2, 작으면 1"],"metadata":{"id":"2VJqrgsjpz0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# scaling\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","print(confusion_matrix(test_y, pred_class_s))\n","print(classification_report(test_y, pred_class_s))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lHMGmN7zxO7D","outputId":"dcc9bbfd-3470-48d8-e67c-dd2340826ec9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[44  4]\n"," [ 9 39]]\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.92      0.87        48\n","           1       0.91      0.81      0.86        48\n","\n","    accuracy                           0.86        96\n","   macro avg       0.87      0.86      0.86        96\n","weighted avg       0.87      0.86      0.86        96\n","\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import datasets, layers, models, losses, Model"],"metadata":{"id":"F1Wq9pQ-LlB4","executionInfo":{"status":"ok","timestamp":1679460541497,"user_tz":-540,"elapsed":2,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# googLeNet\n","\n","def inception(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool):\n","    path1 = layers.Conv2D(filters_1x1, (1, 1), padding='same',    activation='relu')(x)\n","    path2 = layers.Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n","    path2 = layers.Conv2D(filters_3x3, (1, 1), padding='same', activation='relu')(path2)\n","    path3 = layers.Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n","    path3 = layers.Conv2D(filters_5x5, (1, 1), padding='same', activation='relu')(path3)\n","    path4 = layers.MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n","    path4 = layers.Conv2D(filters_pool, (1, 1), padding='same', activation='relu')(path4)\n","    \n","    return tf.concat([path1, path2, path3, path4], axis=3)"],"metadata":{"id":"R0E5eGnJKjeA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inp = layers.Input(shape=(280, 280, 3))\n","input_tensor = layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=train_x.shape[1:])(inp)\n","x = layers.Conv2D(64, 7, strides=2, padding='same', activation='relu')(input_tensor)\n","x = layers.MaxPooling2D(3, strides=2)(x)\n","x = layers.Conv2D(64, 1, strides=1, padding='same', activation='relu')(x)\n","x = layers.Conv2D(192, 3, strides=1, padding='same', activation='relu')(x)\n","x = layers.MaxPooling2D(3, strides=2)(x)\n","x = inception(x, filters_1x1=64, filters_3x3_reduce=96, filters_3x3=128, filters_5x5_reduce=16, filters_5x5=32, filters_pool=32)\n","x = inception(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=192, filters_5x5_reduce=32, filters_5x5=96, filters_pool=64)\n","x = layers.MaxPooling2D(3, strides=2)(x)\n","x = inception(x, filters_1x1=192, filters_3x3_reduce=96, filters_3x3=208, filters_5x5_reduce=16, filters_5x5=48, filters_pool=64)\n","aux1 = layers.AveragePooling2D((5, 5), strides=3)(x)\n","aux1 =layers.Conv2D(128, 1, padding='same', activation='relu')(aux1)\n","aux1 = layers.Flatten()(aux1)\n","aux1 = layers.Dense(1024, activation='relu')(aux1)\n","aux1 = layers.Dropout(0.7)(aux1)\n","aux1 = layers.Dense(1, activation='sigmoid')(aux1)\n","x = inception(x, filters_1x1=160, filters_3x3_reduce=112, filters_3x3=224, filters_5x5_reduce=24, filters_5x5=64, filters_pool=64)\n","x = inception(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=256, filters_5x5_reduce=24, filters_5x5=64, filters_pool=64)\n","x = inception(x, filters_1x1=112, filters_3x3_reduce=144, filters_3x3=288, filters_5x5_reduce=32, filters_5x5=64, filters_pool=64)\n","aux2 = layers.AveragePooling2D((5, 5), strides=3)(x)\n","aux2 =layers.Conv2D(128, 1, padding='same', activation='relu')(aux2)\n","aux2 = layers.Flatten()(aux2)\n","aux2 = layers.Dense(1024, activation='relu')(aux2)\n","aux2 = layers.Dropout(0.7)(aux2) \n","aux2 = layers.Dense(1, activation='sigmoid')(aux2)\n","x = inception(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool=128)\n","x = layers.MaxPooling2D(3, strides=2)(x)\n","x = inception(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool=128)\n","x = inception(x, filters_1x1=384, filters_3x3_reduce=192, filters_3x3=384, filters_5x5_reduce=48, filters_5x5=128, filters_pool=128)\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dropout(0.4)(x)\n","out = layers.Dense(1, activation='sigmoid')(x)"],"metadata":{"id":"PdbhlGYKLQxp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_googLeNet = Model(inputs = inp, outputs = [out, aux1, aux2])"],"metadata":{"id":"CcA5MU8KLdah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n","\n","model_googLeNet.compile(optimizer='adam', \n","              loss=['binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy'],\n","              loss_weights=[1, 0.3, 0.3],\n","              metrics=['accuracy'])\n","\n","model_googLeNet.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RLXqM2V1L-gc","outputId":"a87ed683-52b8-4e24-bcb6-1581f274108e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 280, 280, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," resizing (Resizing)            (None, 224, 224, 3)  0           ['input_1[0][0]']                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 112, 112, 64  9472        ['resizing[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 55, 55, 64)   0           ['conv2d[0][0]']                 \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 55, 55, 64)   4160        ['max_pooling2d[0][0]']          \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 55, 55, 192)  110784      ['conv2d_1[0][0]']               \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 27, 27, 192)  0          ['conv2d_2[0][0]']               \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 27, 27, 96)   18528       ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 27, 27, 16)   3088        ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, 27, 27, 192)  0          ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 27, 27, 64)   12352       ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 27, 27, 128)  12416       ['conv2d_4[0][0]']               \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 27, 27, 32)   544         ['conv2d_6[0][0]']               \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 27, 27, 32)   6176        ['max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," tf.concat (TFOpLambda)         (None, 27, 27, 256)  0           ['conv2d_3[0][0]',               \n","                                                                  'conv2d_5[0][0]',               \n","                                                                  'conv2d_7[0][0]',               \n","                                                                  'conv2d_8[0][0]']               \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 27, 27, 128)  32896       ['tf.concat[0][0]']              \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 27, 27, 32)   8224        ['tf.concat[0][0]']              \n","                                                                                                  \n"," max_pooling2d_3 (MaxPooling2D)  (None, 27, 27, 256)  0          ['tf.concat[0][0]']              \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 27, 27, 128)  32896       ['tf.concat[0][0]']              \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 27, 27, 192)  24768       ['conv2d_10[0][0]']              \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 27, 27, 96)   3168        ['conv2d_12[0][0]']              \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 27, 27, 64)   16448       ['max_pooling2d_3[0][0]']        \n","                                                                                                  \n"," tf.concat_1 (TFOpLambda)       (None, 27, 27, 480)  0           ['conv2d_9[0][0]',               \n","                                                                  'conv2d_11[0][0]',              \n","                                                                  'conv2d_13[0][0]',              \n","                                                                  'conv2d_14[0][0]']              \n","                                                                                                  \n"," max_pooling2d_4 (MaxPooling2D)  (None, 13, 13, 480)  0          ['tf.concat_1[0][0]']            \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 13, 13, 96)   46176       ['max_pooling2d_4[0][0]']        \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 13, 13, 16)   7696        ['max_pooling2d_4[0][0]']        \n","                                                                                                  \n"," max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 480)  0          ['max_pooling2d_4[0][0]']        \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 13, 13, 192)  92352       ['max_pooling2d_4[0][0]']        \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 13, 13, 208)  20176       ['conv2d_16[0][0]']              \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 13, 13, 48)   816         ['conv2d_18[0][0]']              \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 13, 13, 64)   30784       ['max_pooling2d_5[0][0]']        \n","                                                                                                  \n"," tf.concat_2 (TFOpLambda)       (None, 13, 13, 512)  0           ['conv2d_15[0][0]',              \n","                                                                  'conv2d_17[0][0]',              \n","                                                                  'conv2d_19[0][0]',              \n","                                                                  'conv2d_20[0][0]']              \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 13, 13, 112)  57456       ['tf.concat_2[0][0]']            \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 13, 13, 24)   12312       ['tf.concat_2[0][0]']            \n","                                                                                                  \n"," max_pooling2d_6 (MaxPooling2D)  (None, 13, 13, 512)  0          ['tf.concat_2[0][0]']            \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 13, 13, 160)  82080       ['tf.concat_2[0][0]']            \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 13, 13, 224)  25312       ['conv2d_23[0][0]']              \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 13, 13, 64)   1600        ['conv2d_25[0][0]']              \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 13, 13, 64)   32832       ['max_pooling2d_6[0][0]']        \n","                                                                                                  \n"," tf.concat_3 (TFOpLambda)       (None, 13, 13, 512)  0           ['conv2d_22[0][0]',              \n","                                                                  'conv2d_24[0][0]',              \n","                                                                  'conv2d_26[0][0]',              \n","                                                                  'conv2d_27[0][0]']              \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 13, 13, 128)  65664       ['tf.concat_3[0][0]']            \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 13, 13, 24)   12312       ['tf.concat_3[0][0]']            \n","                                                                                                  \n"," max_pooling2d_7 (MaxPooling2D)  (None, 13, 13, 512)  0          ['tf.concat_3[0][0]']            \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 13, 13, 128)  65664       ['tf.concat_3[0][0]']            \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 13, 13, 256)  33024       ['conv2d_29[0][0]']              \n","                                                                                                  \n"," conv2d_32 (Conv2D)             (None, 13, 13, 64)   1600        ['conv2d_31[0][0]']              \n","                                                                                                  \n"," conv2d_33 (Conv2D)             (None, 13, 13, 64)   32832       ['max_pooling2d_7[0][0]']        \n","                                                                                                  \n"," tf.concat_4 (TFOpLambda)       (None, 13, 13, 512)  0           ['conv2d_28[0][0]',              \n","                                                                  'conv2d_30[0][0]',              \n","                                                                  'conv2d_32[0][0]',              \n","                                                                  'conv2d_33[0][0]']              \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 13, 13, 144)  73872       ['tf.concat_4[0][0]']            \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 13, 13, 32)   16416       ['tf.concat_4[0][0]']            \n","                                                                                                  \n"," max_pooling2d_8 (MaxPooling2D)  (None, 13, 13, 512)  0          ['tf.concat_4[0][0]']            \n","                                                                                                  \n"," conv2d_34 (Conv2D)             (None, 13, 13, 112)  57456       ['tf.concat_4[0][0]']            \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 13, 13, 288)  41760       ['conv2d_35[0][0]']              \n","                                                                                                  \n"," conv2d_38 (Conv2D)             (None, 13, 13, 64)   2112        ['conv2d_37[0][0]']              \n","                                                                                                  \n"," conv2d_39 (Conv2D)             (None, 13, 13, 64)   32832       ['max_pooling2d_8[0][0]']        \n","                                                                                                  \n"," tf.concat_5 (TFOpLambda)       (None, 13, 13, 528)  0           ['conv2d_34[0][0]',              \n","                                                                  'conv2d_36[0][0]',              \n","                                                                  'conv2d_38[0][0]',              \n","                                                                  'conv2d_39[0][0]']              \n","                                                                                                  \n"," conv2d_42 (Conv2D)             (None, 13, 13, 160)  84640       ['tf.concat_5[0][0]']            \n","                                                                                                  \n"," conv2d_44 (Conv2D)             (None, 13, 13, 32)   16928       ['tf.concat_5[0][0]']            \n","                                                                                                  \n"," max_pooling2d_9 (MaxPooling2D)  (None, 13, 13, 528)  0          ['tf.concat_5[0][0]']            \n","                                                                                                  \n"," conv2d_41 (Conv2D)             (None, 13, 13, 256)  135424      ['tf.concat_5[0][0]']            \n","                                                                                                  \n"," conv2d_43 (Conv2D)             (None, 13, 13, 320)  51520       ['conv2d_42[0][0]']              \n","                                                                                                  \n"," conv2d_45 (Conv2D)             (None, 13, 13, 128)  4224        ['conv2d_44[0][0]']              \n","                                                                                                  \n"," conv2d_46 (Conv2D)             (None, 13, 13, 128)  67712       ['max_pooling2d_9[0][0]']        \n","                                                                                                  \n"," tf.concat_6 (TFOpLambda)       (None, 13, 13, 832)  0           ['conv2d_41[0][0]',              \n","                                                                  'conv2d_43[0][0]',              \n","                                                                  'conv2d_45[0][0]',              \n","                                                                  'conv2d_46[0][0]']              \n","                                                                                                  \n"," max_pooling2d_10 (MaxPooling2D  (None, 6, 6, 832)   0           ['tf.concat_6[0][0]']            \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_48 (Conv2D)             (None, 6, 6, 160)    133280      ['max_pooling2d_10[0][0]']       \n","                                                                                                  \n"," conv2d_50 (Conv2D)             (None, 6, 6, 32)     26656       ['max_pooling2d_10[0][0]']       \n","                                                                                                  \n"," max_pooling2d_11 (MaxPooling2D  (None, 6, 6, 832)   0           ['max_pooling2d_10[0][0]']       \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_47 (Conv2D)             (None, 6, 6, 256)    213248      ['max_pooling2d_10[0][0]']       \n","                                                                                                  \n"," conv2d_49 (Conv2D)             (None, 6, 6, 320)    51520       ['conv2d_48[0][0]']              \n","                                                                                                  \n"," conv2d_51 (Conv2D)             (None, 6, 6, 128)    4224        ['conv2d_50[0][0]']              \n","                                                                                                  \n"," conv2d_52 (Conv2D)             (None, 6, 6, 128)    106624      ['max_pooling2d_11[0][0]']       \n","                                                                                                  \n"," tf.concat_7 (TFOpLambda)       (None, 6, 6, 832)    0           ['conv2d_47[0][0]',              \n","                                                                  'conv2d_49[0][0]',              \n","                                                                  'conv2d_51[0][0]',              \n","                                                                  'conv2d_52[0][0]']              \n","                                                                                                  \n"," conv2d_54 (Conv2D)             (None, 6, 6, 192)    159936      ['tf.concat_7[0][0]']            \n","                                                                                                  \n"," conv2d_56 (Conv2D)             (None, 6, 6, 48)     39984       ['tf.concat_7[0][0]']            \n","                                                                                                  \n"," max_pooling2d_12 (MaxPooling2D  (None, 6, 6, 832)   0           ['tf.concat_7[0][0]']            \n"," )                                                                                                \n","                                                                                                  \n"," average_pooling2d (AveragePool  (None, 3, 3, 512)   0           ['tf.concat_2[0][0]']            \n"," ing2D)                                                                                           \n","                                                                                                  \n"," average_pooling2d_1 (AveragePo  (None, 3, 3, 528)   0           ['tf.concat_5[0][0]']            \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_53 (Conv2D)             (None, 6, 6, 384)    319872      ['tf.concat_7[0][0]']            \n","                                                                                                  \n"," conv2d_55 (Conv2D)             (None, 6, 6, 384)    74112       ['conv2d_54[0][0]']              \n","                                                                                                  \n"," conv2d_57 (Conv2D)             (None, 6, 6, 128)    6272        ['conv2d_56[0][0]']              \n","                                                                                                  \n"," conv2d_58 (Conv2D)             (None, 6, 6, 128)    106624      ['max_pooling2d_12[0][0]']       \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 3, 3, 128)    65664       ['average_pooling2d[0][0]']      \n","                                                                                                  \n"," conv2d_40 (Conv2D)             (None, 3, 3, 128)    67712       ['average_pooling2d_1[0][0]']    \n","                                                                                                  \n"," tf.concat_8 (TFOpLambda)       (None, 6, 6, 1024)   0           ['conv2d_53[0][0]',              \n","                                                                  'conv2d_55[0][0]',              \n","                                                                  'conv2d_57[0][0]',              \n","                                                                  'conv2d_58[0][0]']              \n","                                                                                                  \n"," flatten (Flatten)              (None, 1152)         0           ['conv2d_21[0][0]']              \n","                                                                                                  \n"," flatten_1 (Flatten)            (None, 1152)         0           ['conv2d_40[0][0]']              \n","                                                                                                  \n"," global_average_pooling2d (Glob  (None, 1024)        0           ['tf.concat_8[0][0]']            \n"," alAveragePooling2D)                                                                              \n","                                                                                                  \n"," dense (Dense)                  (None, 1024)         1180672     ['flatten[0][0]']                \n","                                                                                                  \n"," dense_2 (Dense)                (None, 1024)         1180672     ['flatten_1[0][0]']              \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 1024)         0           ['global_average_pooling2d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 1024)         0           ['dense_2[0][0]']                \n","                                                                                                  \n"," dense_4 (Dense)                (None, 1)            1025        ['dropout_2[0][0]']              \n","                                                                                                  \n"," dense_1 (Dense)                (None, 1)            1025        ['dropout[0][0]']                \n","                                                                                                  \n"," dense_3 (Dense)                (None, 1)            1025        ['dropout_1[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 5,241,651\n","Trainable params: 5,241,651\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   patience = 8,\n","                   verbose = 1,\n","                   restore_best_weights = True)"],"metadata":{"id":"R05WHw6RMjpq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# scaling data\n","# hist = model.fit(train_x_s, train_y, validation_data=(val_x_s, val_y),\n","#                  batch_size=32, epochs=1000, callbacks=[es], verbose=1)\n","\n","history = model.fit(train_x, [train_y, train_y, train_y], validation_data=(val_x, [val_y, val_y, val_y]), batch_size=32, epochs=40, callbacks=[es], verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BDk9XyfaMfUB","outputId":"8e942e5a-f1c8-422e-e32a-0b80be2b3a12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","13/13 [==============================] - 38s 310ms/step - loss: 2.0929 - dense_4_loss: 1.0964 - dense_1_loss: 2.2977 - dense_3_loss: 1.0240 - dense_4_accuracy: 0.5000 - dense_1_accuracy: 0.4742 - dense_3_accuracy: 0.5335 - val_loss: 1.2219 - val_dense_4_loss: 0.7064 - val_dense_1_loss: 1.0059 - val_dense_3_loss: 0.7122 - val_dense_4_accuracy: 0.5000 - val_dense_1_accuracy: 0.5000 - val_dense_3_accuracy: 0.5000\n","Epoch 2/40\n","13/13 [==============================] - 1s 108ms/step - loss: 1.1354 - dense_4_loss: 0.6999 - dense_1_loss: 0.7493 - dense_3_loss: 0.7023 - dense_4_accuracy: 0.5103 - dense_1_accuracy: 0.5412 - dense_3_accuracy: 0.5052 - val_loss: 1.0785 - val_dense_4_loss: 0.6863 - val_dense_1_loss: 0.6352 - val_dense_3_loss: 0.6720 - val_dense_4_accuracy: 0.7812 - val_dense_1_accuracy: 0.5833 - val_dense_3_accuracy: 0.6146\n","Epoch 3/40\n","13/13 [==============================] - 1s 116ms/step - loss: 1.0525 - dense_4_loss: 0.6670 - dense_1_loss: 0.6412 - dense_3_loss: 0.6438 - dense_4_accuracy: 0.5979 - dense_1_accuracy: 0.6340 - dense_3_accuracy: 0.6443 - val_loss: 0.9586 - val_dense_4_loss: 0.6156 - val_dense_1_loss: 0.5325 - val_dense_3_loss: 0.6109 - val_dense_4_accuracy: 0.6979 - val_dense_1_accuracy: 0.8229 - val_dense_3_accuracy: 0.6562\n","Epoch 4/40\n","13/13 [==============================] - 2s 128ms/step - loss: 1.0735 - dense_4_loss: 0.6695 - dense_1_loss: 0.6762 - dense_3_loss: 0.6708 - dense_4_accuracy: 0.6031 - dense_1_accuracy: 0.5954 - dense_3_accuracy: 0.5979 - val_loss: 1.1758 - val_dense_4_loss: 0.7097 - val_dense_1_loss: 0.7878 - val_dense_3_loss: 0.7660 - val_dense_4_accuracy: 0.5000 - val_dense_1_accuracy: 0.5000 - val_dense_3_accuracy: 0.5000\n","Epoch 5/40\n","13/13 [==============================] - 1s 111ms/step - loss: 1.1303 - dense_4_loss: 0.7010 - dense_1_loss: 0.7196 - dense_3_loss: 0.7112 - dense_4_accuracy: 0.4871 - dense_1_accuracy: 0.5619 - dense_3_accuracy: 0.5155 - val_loss: 1.0870 - val_dense_4_loss: 0.6797 - val_dense_1_loss: 0.6958 - val_dense_3_loss: 0.6618 - val_dense_4_accuracy: 0.5417 - val_dense_1_accuracy: 0.5208 - val_dense_3_accuracy: 0.7812\n","Epoch 6/40\n","13/13 [==============================] - 1s 101ms/step - loss: 1.0535 - dense_4_loss: 0.6642 - dense_1_loss: 0.6367 - dense_3_loss: 0.6609 - dense_4_accuracy: 0.6443 - dense_1_accuracy: 0.6572 - dense_3_accuracy: 0.6211 - val_loss: 1.2709 - val_dense_4_loss: 0.8384 - val_dense_1_loss: 0.7363 - val_dense_3_loss: 0.7055 - val_dense_4_accuracy: 0.5000 - val_dense_1_accuracy: 0.5000 - val_dense_3_accuracy: 0.5000\n","Epoch 7/40\n","13/13 [==============================] - 1s 110ms/step - loss: 1.1117 - dense_4_loss: 0.7094 - dense_1_loss: 0.6728 - dense_3_loss: 0.6680 - dense_4_accuracy: 0.5876 - dense_1_accuracy: 0.5851 - dense_3_accuracy: 0.6392 - val_loss: 0.9249 - val_dense_4_loss: 0.6153 - val_dense_1_loss: 0.5013 - val_dense_3_loss: 0.5308 - val_dense_4_accuracy: 0.8229 - val_dense_1_accuracy: 0.8021 - val_dense_3_accuracy: 0.8021\n","Epoch 8/40\n","13/13 [==============================] - 1s 105ms/step - loss: 0.9656 - dense_4_loss: 0.6108 - dense_1_loss: 0.5725 - dense_3_loss: 0.6100 - dense_4_accuracy: 0.7036 - dense_1_accuracy: 0.7088 - dense_3_accuracy: 0.6959 - val_loss: 1.0116 - val_dense_4_loss: 0.6408 - val_dense_1_loss: 0.6029 - val_dense_3_loss: 0.6330 - val_dense_4_accuracy: 0.6354 - val_dense_1_accuracy: 0.6458 - val_dense_3_accuracy: 0.8021\n","Epoch 9/40\n","13/13 [==============================] - 1s 103ms/step - loss: 1.0900 - dense_4_loss: 0.6876 - dense_1_loss: 0.6646 - dense_3_loss: 0.6768 - dense_4_accuracy: 0.5284 - dense_1_accuracy: 0.6057 - dense_3_accuracy: 0.5619 - val_loss: 1.0722 - val_dense_4_loss: 0.6582 - val_dense_1_loss: 0.7225 - val_dense_3_loss: 0.6575 - val_dense_4_accuracy: 0.8125 - val_dense_1_accuracy: 0.5833 - val_dense_3_accuracy: 0.7396\n","Epoch 10/40\n","13/13 [==============================] - 1s 108ms/step - loss: 0.9998 - dense_4_loss: 0.6100 - dense_1_loss: 0.6851 - dense_3_loss: 0.6141 - dense_4_accuracy: 0.7371 - dense_1_accuracy: 0.6649 - dense_3_accuracy: 0.7268 - val_loss: 0.7546 - val_dense_4_loss: 0.4657 - val_dense_1_loss: 0.5265 - val_dense_3_loss: 0.4366 - val_dense_4_accuracy: 0.7812 - val_dense_1_accuracy: 0.8750 - val_dense_3_accuracy: 0.8438\n","Epoch 11/40\n","13/13 [==============================] - 1s 105ms/step - loss: 0.9559 - dense_4_loss: 0.5864 - dense_1_loss: 0.6242 - dense_3_loss: 0.6072 - dense_4_accuracy: 0.6985 - dense_1_accuracy: 0.6701 - dense_3_accuracy: 0.6804 - val_loss: 0.7127 - val_dense_4_loss: 0.4509 - val_dense_1_loss: 0.4155 - val_dense_3_loss: 0.4574 - val_dense_4_accuracy: 0.8125 - val_dense_1_accuracy: 0.8646 - val_dense_3_accuracy: 0.8229\n","Epoch 12/40\n","13/13 [==============================] - 1s 105ms/step - loss: 0.8511 - dense_4_loss: 0.5178 - dense_1_loss: 0.5877 - dense_3_loss: 0.5235 - dense_4_accuracy: 0.7732 - dense_1_accuracy: 0.6985 - dense_3_accuracy: 0.7474 - val_loss: 0.7640 - val_dense_4_loss: 0.4729 - val_dense_1_loss: 0.5088 - val_dense_3_loss: 0.4614 - val_dense_4_accuracy: 0.7708 - val_dense_1_accuracy: 0.8542 - val_dense_3_accuracy: 0.7917\n","Epoch 13/40\n","13/13 [==============================] - 1s 111ms/step - loss: 0.8744 - dense_4_loss: 0.5385 - dense_1_loss: 0.5883 - dense_3_loss: 0.5314 - dense_4_accuracy: 0.7758 - dense_1_accuracy: 0.7191 - dense_3_accuracy: 0.7835 - val_loss: 0.9877 - val_dense_4_loss: 0.6560 - val_dense_1_loss: 0.5169 - val_dense_3_loss: 0.5886 - val_dense_4_accuracy: 0.6771 - val_dense_1_accuracy: 0.7604 - val_dense_3_accuracy: 0.6875\n","Epoch 14/40\n","13/13 [==============================] - 1s 111ms/step - loss: 0.8487 - dense_4_loss: 0.5388 - dense_1_loss: 0.5116 - dense_3_loss: 0.5215 - dense_4_accuracy: 0.7371 - dense_1_accuracy: 0.7887 - dense_3_accuracy: 0.7577 - val_loss: 1.5144 - val_dense_4_loss: 0.8883 - val_dense_1_loss: 0.9474 - val_dense_3_loss: 1.1395 - val_dense_4_accuracy: 0.5833 - val_dense_1_accuracy: 0.5729 - val_dense_3_accuracy: 0.5729\n","Epoch 15/40\n","13/13 [==============================] - 1s 104ms/step - loss: 1.0633 - dense_4_loss: 0.6583 - dense_1_loss: 0.6730 - dense_3_loss: 0.6769 - dense_4_accuracy: 0.6598 - dense_1_accuracy: 0.5876 - dense_3_accuracy: 0.6701 - val_loss: 0.8080 - val_dense_4_loss: 0.4884 - val_dense_1_loss: 0.5650 - val_dense_3_loss: 0.5004 - val_dense_4_accuracy: 0.8333 - val_dense_1_accuracy: 0.8333 - val_dense_3_accuracy: 0.8333\n","Epoch 16/40\n","13/13 [==============================] - 1s 103ms/step - loss: 0.8471 - dense_4_loss: 0.5117 - dense_1_loss: 0.5715 - dense_3_loss: 0.5462 - dense_4_accuracy: 0.8093 - dense_1_accuracy: 0.7448 - dense_3_accuracy: 0.7887 - val_loss: 0.7446 - val_dense_4_loss: 0.4558 - val_dense_1_loss: 0.4880 - val_dense_3_loss: 0.4746 - val_dense_4_accuracy: 0.8229 - val_dense_1_accuracy: 0.8333 - val_dense_3_accuracy: 0.8125\n","Epoch 17/40\n","13/13 [==============================] - 1s 105ms/step - loss: 0.8770 - dense_4_loss: 0.5331 - dense_1_loss: 0.5958 - dense_3_loss: 0.5506 - dense_4_accuracy: 0.7629 - dense_1_accuracy: 0.6881 - dense_3_accuracy: 0.7577 - val_loss: 1.0416 - val_dense_4_loss: 0.6785 - val_dense_1_loss: 0.5625 - val_dense_3_loss: 0.6477 - val_dense_4_accuracy: 0.6562 - val_dense_1_accuracy: 0.7812 - val_dense_3_accuracy: 0.6771\n","Epoch 18/40\n","13/13 [==============================] - 1s 104ms/step - loss: 0.8258 - dense_4_loss: 0.5128 - dense_1_loss: 0.5277 - dense_3_loss: 0.5154 - dense_4_accuracy: 0.7242 - dense_1_accuracy: 0.7629 - dense_3_accuracy: 0.7680 - val_loss: 0.6932 - val_dense_4_loss: 0.4244 - val_dense_1_loss: 0.4451 - val_dense_3_loss: 0.4508 - val_dense_4_accuracy: 0.8229 - val_dense_1_accuracy: 0.8438 - val_dense_3_accuracy: 0.8021\n","Epoch 19/40\n","13/13 [==============================] - 1s 102ms/step - loss: 0.7202 - dense_4_loss: 0.4430 - dense_1_loss: 0.4767 - dense_3_loss: 0.4473 - dense_4_accuracy: 0.7990 - dense_1_accuracy: 0.7861 - dense_3_accuracy: 0.7912 - val_loss: 0.7701 - val_dense_4_loss: 0.4716 - val_dense_1_loss: 0.5121 - val_dense_3_loss: 0.4828 - val_dense_4_accuracy: 0.7812 - val_dense_1_accuracy: 0.7604 - val_dense_3_accuracy: 0.7917\n","Epoch 20/40\n","13/13 [==============================] - 1s 106ms/step - loss: 0.7078 - dense_4_loss: 0.4329 - dense_1_loss: 0.4908 - dense_3_loss: 0.4254 - dense_4_accuracy: 0.7938 - dense_1_accuracy: 0.7577 - dense_3_accuracy: 0.7964 - val_loss: 0.5660 - val_dense_4_loss: 0.3292 - val_dense_1_loss: 0.4325 - val_dense_3_loss: 0.3569 - val_dense_4_accuracy: 0.8958 - val_dense_1_accuracy: 0.8125 - val_dense_3_accuracy: 0.8646\n","Epoch 21/40\n","13/13 [==============================] - 1s 107ms/step - loss: 0.6754 - dense_4_loss: 0.4162 - dense_1_loss: 0.4466 - dense_3_loss: 0.4174 - dense_4_accuracy: 0.8273 - dense_1_accuracy: 0.8170 - dense_3_accuracy: 0.8273 - val_loss: 0.4725 - val_dense_4_loss: 0.2925 - val_dense_1_loss: 0.3057 - val_dense_3_loss: 0.2943 - val_dense_4_accuracy: 0.9062 - val_dense_1_accuracy: 0.8958 - val_dense_3_accuracy: 0.9062\n","Epoch 22/40\n","13/13 [==============================] - 1s 108ms/step - loss: 0.6758 - dense_4_loss: 0.4113 - dense_1_loss: 0.4766 - dense_3_loss: 0.4048 - dense_4_accuracy: 0.8196 - dense_1_accuracy: 0.7706 - dense_3_accuracy: 0.8093 - val_loss: 0.6362 - val_dense_4_loss: 0.4217 - val_dense_1_loss: 0.3169 - val_dense_3_loss: 0.3980 - val_dense_4_accuracy: 0.8125 - val_dense_1_accuracy: 0.8958 - val_dense_3_accuracy: 0.8333\n","Epoch 23/40\n","13/13 [==============================] - 1s 113ms/step - loss: 0.7483 - dense_4_loss: 0.4898 - dense_1_loss: 0.4227 - dense_3_loss: 0.4389 - dense_4_accuracy: 0.8093 - dense_1_accuracy: 0.8093 - dense_3_accuracy: 0.8196 - val_loss: 0.9133 - val_dense_4_loss: 0.4994 - val_dense_1_loss: 0.8597 - val_dense_3_loss: 0.5200 - val_dense_4_accuracy: 0.8021 - val_dense_1_accuracy: 0.7292 - val_dense_3_accuracy: 0.7708\n","Epoch 24/40\n","13/13 [==============================] - 1s 114ms/step - loss: 0.7300 - dense_4_loss: 0.4409 - dense_1_loss: 0.5183 - dense_3_loss: 0.4455 - dense_4_accuracy: 0.7938 - dense_1_accuracy: 0.7680 - dense_3_accuracy: 0.7938 - val_loss: 0.9748 - val_dense_4_loss: 0.6115 - val_dense_1_loss: 0.5462 - val_dense_3_loss: 0.6646 - val_dense_4_accuracy: 0.7604 - val_dense_1_accuracy: 0.7500 - val_dense_3_accuracy: 0.7604\n","Epoch 25/40\n","13/13 [==============================] - 1s 100ms/step - loss: 0.7076 - dense_4_loss: 0.4304 - dense_1_loss: 0.4942 - dense_3_loss: 0.4297 - dense_4_accuracy: 0.8144 - dense_1_accuracy: 0.7990 - dense_3_accuracy: 0.8222 - val_loss: 0.8054 - val_dense_4_loss: 0.5022 - val_dense_1_loss: 0.5118 - val_dense_3_loss: 0.4991 - val_dense_4_accuracy: 0.7500 - val_dense_1_accuracy: 0.7188 - val_dense_3_accuracy: 0.7708\n","Epoch 26/40\n","13/13 [==============================] - 1s 103ms/step - loss: 0.6927 - dense_4_loss: 0.4355 - dense_1_loss: 0.4627 - dense_3_loss: 0.3946 - dense_4_accuracy: 0.8093 - dense_1_accuracy: 0.7990 - dense_3_accuracy: 0.8376 - val_loss: 0.7627 - val_dense_4_loss: 0.4863 - val_dense_1_loss: 0.4674 - val_dense_3_loss: 0.4540 - val_dense_4_accuracy: 0.7812 - val_dense_1_accuracy: 0.7604 - val_dense_3_accuracy: 0.7917\n","Epoch 27/40\n","13/13 [==============================] - 1s 103ms/step - loss: 0.6601 - dense_4_loss: 0.4208 - dense_1_loss: 0.4025 - dense_3_loss: 0.3952 - dense_4_accuracy: 0.8041 - dense_1_accuracy: 0.8041 - dense_3_accuracy: 0.8015 - val_loss: 0.5655 - val_dense_4_loss: 0.3370 - val_dense_1_loss: 0.3709 - val_dense_3_loss: 0.3908 - val_dense_4_accuracy: 0.8542 - val_dense_1_accuracy: 0.8333 - val_dense_3_accuracy: 0.8229\n","Epoch 28/40\n","13/13 [==============================] - 1s 108ms/step - loss: 0.5380 - dense_4_loss: 0.3465 - dense_1_loss: 0.3261 - dense_3_loss: 0.3123 - dense_4_accuracy: 0.8608 - dense_1_accuracy: 0.8376 - dense_3_accuracy: 0.8608 - val_loss: 0.4244 - val_dense_4_loss: 0.2358 - val_dense_1_loss: 0.3705 - val_dense_3_loss: 0.2579 - val_dense_4_accuracy: 0.9375 - val_dense_1_accuracy: 0.8646 - val_dense_3_accuracy: 0.9271\n","Epoch 29/40\n","13/13 [==============================] - 1s 105ms/step - loss: 0.4854 - dense_4_loss: 0.2963 - dense_1_loss: 0.3308 - dense_3_loss: 0.2995 - dense_4_accuracy: 0.8505 - dense_1_accuracy: 0.8531 - dense_3_accuracy: 0.8608 - val_loss: 0.5061 - val_dense_4_loss: 0.2976 - val_dense_1_loss: 0.3809 - val_dense_3_loss: 0.3142 - val_dense_4_accuracy: 0.8854 - val_dense_1_accuracy: 0.8750 - val_dense_3_accuracy: 0.8854\n","Epoch 30/40\n","13/13 [==============================] - 1s 103ms/step - loss: 0.5301 - dense_4_loss: 0.3365 - dense_1_loss: 0.3378 - dense_3_loss: 0.3073 - dense_4_accuracy: 0.8454 - dense_1_accuracy: 0.8454 - dense_3_accuracy: 0.8634 - val_loss: 0.5808 - val_dense_4_loss: 0.3613 - val_dense_1_loss: 0.3786 - val_dense_3_loss: 0.3530 - val_dense_4_accuracy: 0.8542 - val_dense_1_accuracy: 0.8333 - val_dense_3_accuracy: 0.8854\n","Epoch 31/40\n","13/13 [==============================] - 1s 103ms/step - loss: 0.4622 - dense_4_loss: 0.2682 - dense_1_loss: 0.3625 - dense_3_loss: 0.2842 - dense_4_accuracy: 0.8918 - dense_1_accuracy: 0.8222 - dense_3_accuracy: 0.8763 - val_loss: 0.5839 - val_dense_4_loss: 0.3410 - val_dense_1_loss: 0.4732 - val_dense_3_loss: 0.3363 - val_dense_4_accuracy: 0.8750 - val_dense_1_accuracy: 0.8229 - val_dense_3_accuracy: 0.8542\n","Epoch 32/40\n","13/13 [==============================] - 1s 114ms/step - loss: 0.4207 - dense_4_loss: 0.2488 - dense_1_loss: 0.3316 - dense_3_loss: 0.2416 - dense_4_accuracy: 0.8892 - dense_1_accuracy: 0.8866 - dense_3_accuracy: 0.8892 - val_loss: 0.4163 - val_dense_4_loss: 0.2512 - val_dense_1_loss: 0.2800 - val_dense_3_loss: 0.2703 - val_dense_4_accuracy: 0.8958 - val_dense_1_accuracy: 0.9271 - val_dense_3_accuracy: 0.9167\n","Epoch 33/40\n","13/13 [==============================] - 1s 112ms/step - loss: 0.5153 - dense_4_loss: 0.3252 - dense_1_loss: 0.3273 - dense_3_loss: 0.3066 - dense_4_accuracy: 0.8582 - dense_1_accuracy: 0.8660 - dense_3_accuracy: 0.8686 - val_loss: 0.4228 - val_dense_4_loss: 0.2554 - val_dense_1_loss: 0.2829 - val_dense_3_loss: 0.2753 - val_dense_4_accuracy: 0.9167 - val_dense_1_accuracy: 0.9062 - val_dense_3_accuracy: 0.9062\n","Epoch 34/40\n","13/13 [==============================] - 1s 103ms/step - loss: 0.4638 - dense_4_loss: 0.2929 - dense_1_loss: 0.2963 - dense_3_loss: 0.2736 - dense_4_accuracy: 0.8737 - dense_1_accuracy: 0.8763 - dense_3_accuracy: 0.8789 - val_loss: 0.5935 - val_dense_4_loss: 0.3307 - val_dense_1_loss: 0.4405 - val_dense_3_loss: 0.4356 - val_dense_4_accuracy: 0.8229 - val_dense_1_accuracy: 0.8021 - val_dense_3_accuracy: 0.7917\n","Epoch 35/40\n","13/13 [==============================] - 1s 104ms/step - loss: 0.4505 - dense_4_loss: 0.2665 - dense_1_loss: 0.3101 - dense_3_loss: 0.3034 - dense_4_accuracy: 0.8892 - dense_1_accuracy: 0.8814 - dense_3_accuracy: 0.8943 - val_loss: 0.4504 - val_dense_4_loss: 0.2683 - val_dense_1_loss: 0.2982 - val_dense_3_loss: 0.3087 - val_dense_4_accuracy: 0.8958 - val_dense_1_accuracy: 0.8854 - val_dense_3_accuracy: 0.8750\n","Epoch 36/40\n","13/13 [==============================] - 1s 102ms/step - loss: 0.3437 - dense_4_loss: 0.2139 - dense_1_loss: 0.2281 - dense_3_loss: 0.2048 - dense_4_accuracy: 0.9175 - dense_1_accuracy: 0.9201 - dense_3_accuracy: 0.9304 - val_loss: 0.4411 - val_dense_4_loss: 0.2821 - val_dense_1_loss: 0.2460 - val_dense_3_loss: 0.2838 - val_dense_4_accuracy: 0.9375 - val_dense_1_accuracy: 0.9062 - val_dense_3_accuracy: 0.9167\n","Epoch 37/40\n","13/13 [==============================] - 1s 102ms/step - loss: 0.3523 - dense_4_loss: 0.2191 - dense_1_loss: 0.2272 - dense_3_loss: 0.2166 - dense_4_accuracy: 0.9175 - dense_1_accuracy: 0.9201 - dense_3_accuracy: 0.9175 - val_loss: 1.1674 - val_dense_4_loss: 0.7666 - val_dense_1_loss: 0.7020 - val_dense_3_loss: 0.6340 - val_dense_4_accuracy: 0.7917 - val_dense_1_accuracy: 0.7396 - val_dense_3_accuracy: 0.7396\n","Epoch 38/40\n","13/13 [==============================] - 1s 106ms/step - loss: 0.5638 - dense_4_loss: 0.3504 - dense_1_loss: 0.3555 - dense_3_loss: 0.3560 - dense_4_accuracy: 0.8454 - dense_1_accuracy: 0.8557 - dense_3_accuracy: 0.8557 - val_loss: 1.0779 - val_dense_4_loss: 0.7556 - val_dense_1_loss: 0.4703 - val_dense_3_loss: 0.6041 - val_dense_4_accuracy: 0.7083 - val_dense_1_accuracy: 0.7604 - val_dense_3_accuracy: 0.7188\n","Epoch 39/40\n","13/13 [==============================] - 1s 108ms/step - loss: 0.6004 - dense_4_loss: 0.3746 - dense_1_loss: 0.3902 - dense_3_loss: 0.3624 - dense_4_accuracy: 0.8325 - dense_1_accuracy: 0.8247 - dense_3_accuracy: 0.8222 - val_loss: 0.4032 - val_dense_4_loss: 0.2393 - val_dense_1_loss: 0.2741 - val_dense_3_loss: 0.2725 - val_dense_4_accuracy: 0.9167 - val_dense_1_accuracy: 0.8646 - val_dense_3_accuracy: 0.8958\n","Epoch 40/40\n","13/13 [==============================] - 1s 98ms/step - loss: 0.3973 - dense_4_loss: 0.2532 - dense_1_loss: 0.2489 - dense_3_loss: 0.2313 - dense_4_accuracy: 0.9046 - dense_1_accuracy: 0.8943 - dense_3_accuracy: 0.9021 - val_loss: 0.5373 - val_dense_4_loss: 0.3146 - val_dense_1_loss: 0.3730 - val_dense_3_loss: 0.3692 - val_dense_4_accuracy: 0.9062 - val_dense_1_accuracy: 0.8646 - val_dense_3_accuracy: 0.8854\n"]}]},{"cell_type":"code","source":["y_pred = model.predict(test_x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uiW6UMjHM0Vj","outputId":"343344a3-0b3f-410d-d5b0-31530aec745f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 2s 314ms/step\n"]}]},{"cell_type":"code","source":["performance_test = model.evaluate(test_x, test_y, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKwjxyMGNa9D","outputId":"70cd0401-99ca-4443-88a1-2a081b9372ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 56ms/step - loss: 0.5484 - dense_4_loss: 0.2989 - dense_1_loss: 0.4558 - dense_3_loss: 0.3759 - dense_4_accuracy: 0.8678 - dense_1_accuracy: 0.8264 - dense_3_accuracy: 0.8430\n"]}]},{"cell_type":"code","source":["performance_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3HCv541JN_nE","outputId":"64fb88c2-04c3-4c06-8180-740c4d52aca3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.5483642220497131,\n"," 0.2988683879375458,\n"," 0.4557562470436096,\n"," 0.3758964538574219,\n"," 0.8677685856819153,\n"," 0.8264462947845459,\n"," 0.8429751992225647]"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["print('Test Loss : {:.6f},  Test Accuracy : {:.3f}%'.format(performance_test[0], performance_test[1]*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2jx_3C6lNrEs","outputId":"2fe8ead6-8f42-4646-ee9f-f5122bb86830"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss : 0.548364,  Test Accuracy : 29.887%\n"]}]},{"cell_type":"code","source":["len(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yj7bjTtoONpC","outputId":"a29890eb-367e-4d1a-9c30-7aedc9c911e7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["preds_1d = y_pred[0].flatten() # 차원 펴주기\n","pred_class = np.where(preds_1d > 0.5, 1 , 0) #0.5보다크면 2, 작으면 1"],"metadata":{"id":"3Sm7rHdKNs7G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","\n","print(confusion_matrix(test_y, pred_class))\n","print(classification_report(test_y, pred_class))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Oe4FEgjOYQ3","outputId":"5ce9f838-a550-41c2-8b7d-82f9c65fe71d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[50 10]\n"," [ 6 55]]\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.83      0.86        60\n","           1       0.85      0.90      0.87        61\n","\n","    accuracy                           0.87       121\n","   macro avg       0.87      0.87      0.87       121\n","weighted avg       0.87      0.87      0.87       121\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"fJjzTbZoN5xB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AxUpfhJ1xXle"},"source":["## 4.모델링 II\n","* **세부요구사항**\n","    - 성능을 높이기 위해서 다음의 두가지를 시도해 봅시다.\n","        - Data Augmentation을 통해 데이터를 증가 시킵니다.\n","            - ImageDataGenerator를 사용합니다.\n","        - 사전 학습된 모델(Transfer Learning)을 가져다 사용해 봅시다.\n","            - VGG16(이미지넷)을 사용해 봅시다."]},{"cell_type":"markdown","metadata":{"id":"ouCRBdKPxCut"},"source":["### (1) Data Augmentation\n","- **세부요구사항**\n","    * 모델 학습에 이용할 이미지 데이터를 증강시키세요.\n","    * Keras의 ImageDataGenerator를 이용\n","        - [ImageDataGenerator document](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n","\n","    * image generator를 이용하여 학습\n","        * 모델 구조는 이미 생성한 1,2,3 중 하나를 선택하여 학습\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"qe6yjs8F7Zox","executionInfo":{"status":"ok","timestamp":1679460587510,"user_tz":-540,"elapsed":421,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"wYae9YFt8Q03","executionInfo":{"status":"ok","timestamp":1679460628285,"user_tz":-540,"elapsed":399,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[],"source":["img_size = 280 ## 사이즈 조정 가능\n","dataset_path = '/content/drive/MyDrive/Datasets/'\n","train_path = dataset_path+'Car_Image_train/'\n","valid_path = dataset_path+'Car_Image_val/'\n","test_path = dataset_path+'Car_Image_test/'"]},{"cell_type":"markdown","source":["#### 1) ImageGenerator 생성\n","* ImageDataGenerator 함수 사용\n","    * 주요 옵션\n","        * rotation_range: 무작위 회전을 적용할 각도 범위\n","        * zoom_range: 무작위 줌을 적용할 범위 [1-zoom_range, 1+zoom_range]\n","        * horizontal_flip: 무작위 좌우반전을 적용할지 여부\n","        * vertical_flip: 무작위 상하반전을 적용할지 여부\n","        * rescale: 텐서의 모든 값을 rescale 값으로 나누어줌 (이 경우에는 255로 나누어서 0~1사이의 값으로 변경)"],"metadata":{"id":"IP4jIyTGfXD_"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"LKPPSwYn7Zrj","executionInfo":{"status":"ok","timestamp":1679460594161,"user_tz":-540,"elapsed":3,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[],"source":["train_datagen = ImageDataGenerator(\n","    rotation_range = 20,\n","    zoom_range = 0.1,\n","    width_shift_range = 0.1,\n","    height_shift_range = 0.1,\n","    horizontal_flip = True,\n","    vertical_flip = True,\n","    rescale = 1/255.\n",")\n","\n","\n","valid_datagen = ImageDataGenerator(\n","    rescale = 1/255.\n",")\n","\n","####\n","test_datagen = ImageDataGenerator(\n","    rescale = 1/255\n",")"]},{"cell_type":"markdown","source":["#### 2) 경로로 부터 이미지 불러 올 준비\n","* .flow_from_directory 이용\n","    * 디렉토리에서 이미지를 가져와서 데이터 증강을 적용하고 batch 단위로 제공하는 generator를 생성합니다.\n","    * 이미지를 불러올 때 target_size로 크기를 맞추고, \n","    * class_mode로 이진 분류(binary)를 수행하도록 지정합니다.\n"],"metadata":{"id":"dKwSYYkufanb"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"0bwvQ4hHSCwY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b146a64-671c-4706-f932-704957c49ac7","executionInfo":{"status":"ok","timestamp":1679460635482,"user_tz":-540,"elapsed":3771,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 388 images belonging to 2 classes.\n","Found 96 images belonging to 2 classes.\n","Found 121 images belonging to 2 classes.\n"]}],"source":["train_generator = train_datagen.flow_from_directory(directory=train_path, target_size=(280, 280), class_mode='binary', batch_size=32, shuffle=True)\n","\n","valid_generator = valid_datagen.flow_from_directory(directory=valid_path, target_size=(280, 280), class_mode='binary', batch_size=32, shuffle=True)\n","\n","test_generator = test_datagen.flow_from_directory(directory=test_path, target_size=(280, 280), class_mode='binary', batch_size=32, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"g4RPCjU5f662"},"source":["#### 3) 학습\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 train_generator 이용. \n","    - validation_data = valid_generator 지정\n","    - Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"markdown","source":["* 구조 설계"],"metadata":{"id":"wVMLsXw6f663"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"_W7rqgH1f663","executionInfo":{"status":"ok","timestamp":1679460641187,"user_tz":-540,"elapsed":511,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[],"source":["from tensorflow.keras.applications import Xception\n","from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","source":["def create_model(verbose=False):\n","    input_tensor = Input(shape=(280, 280, 3))\n","    pretrained_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n","    pretrained_output = pretrained_model.output\n","\n","    # customize Classifier layer\n","    x = GlobalAveragePooling2D()(pretrained_output)\n","    x = Dense(units=2, activation='relu')(x)\n","    output = Dense(units=1, activation='sigmoid')(x)\n","\n","    model = Model(inputs=input_tensor, outputs=output)\n","    if verbose:\n","        model.summary()\n","    return model"],"metadata":{"id":"WLTOESuX1KL6","executionInfo":{"status":"ok","timestamp":1679460663022,"user_tz":-540,"elapsed":405,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# 모델 정의\n","model_Xception = create_model(verbose=False)\n","# 모델 compile\n","model_Xception.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"qLpEowp42NT3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679460671276,"user_tz":-540,"elapsed":4825,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"66754833-250a-4115-ba2a-81406e1f83d3"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83683744/83683744 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["* 학습\n","    * EarlyStopping 설정하기\n","    * 학습 데이터에 train_generator, validation_data=valid_generator 사용"],"metadata":{"id":"nw2_G7zdf663"}},{"cell_type":"code","execution_count":22,"metadata":{"id":"6m5mRE9Nf663","executionInfo":{"status":"ok","timestamp":1679460681773,"user_tz":-540,"elapsed":356,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[],"source":["# es\n","es = EarlyStopping(monitor='val_loss',\n","                   min_delta=0,\n","                   patience=5,\n","                   verbose=1,\n","                   restore_best_weights=True)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"yCWzBSYqf663","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d27f965-9926-4324-be00-6bd4f9666e8c","executionInfo":{"status":"ok","timestamp":1679461352082,"user_tz":-540,"elapsed":655278,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","13/13 [==============================] - 119s 6s/step - loss: 0.5873 - accuracy: 0.6907 - val_loss: 0.4619 - val_accuracy: 0.8646\n","Epoch 2/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.3630 - accuracy: 0.9485 - val_loss: 0.2246 - val_accuracy: 0.9583\n","Epoch 3/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.1936 - accuracy: 0.9665 - val_loss: 0.1208 - val_accuracy: 0.9583\n","Epoch 4/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0851 - accuracy: 0.9820 - val_loss: 0.1185 - val_accuracy: 0.9479\n","Epoch 5/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0587 - accuracy: 0.9897 - val_loss: 0.1481 - val_accuracy: 0.9271\n","Epoch 6/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0647 - accuracy: 0.9845 - val_loss: 0.0904 - val_accuracy: 0.9583\n","Epoch 7/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0482 - accuracy: 0.9923 - val_loss: 0.0858 - val_accuracy: 0.9583\n","Epoch 8/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0374 - accuracy: 0.9974 - val_loss: 0.0847 - val_accuracy: 0.9479\n","Epoch 9/500\n","13/13 [==============================] - 26s 2s/step - loss: 0.0377 - accuracy: 0.9897 - val_loss: 0.1021 - val_accuracy: 0.9479\n","Epoch 10/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0414 - accuracy: 0.9897 - val_loss: 0.0320 - val_accuracy: 0.9896\n","Epoch 11/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0493 - accuracy: 0.9923 - val_loss: 0.0285 - val_accuracy: 0.9896\n","Epoch 12/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0483 - accuracy: 0.9871 - val_loss: 0.0298 - val_accuracy: 0.9896\n","Epoch 13/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0518 - accuracy: 0.9845 - val_loss: 0.0315 - val_accuracy: 0.9896\n","Epoch 14/500\n","13/13 [==============================] - 29s 2s/step - loss: 0.0328 - accuracy: 0.9897 - val_loss: 0.0337 - val_accuracy: 0.9896\n","Epoch 15/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0315 - accuracy: 0.9948 - val_loss: 0.0235 - val_accuracy: 0.9896\n","Epoch 16/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.0305 - val_accuracy: 0.9792\n","Epoch 17/500\n","13/13 [==============================] - 26s 2s/step - loss: 0.0348 - accuracy: 0.9897 - val_loss: 0.0738 - val_accuracy: 0.9688\n","Epoch 18/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.1041 - val_accuracy: 0.9583\n","Epoch 19/500\n","13/13 [==============================] - 27s 2s/step - loss: 0.0203 - accuracy: 0.9948 - val_loss: 0.0769 - val_accuracy: 0.9583\n","Epoch 20/500\n","13/13 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9948Restoring model weights from the end of the best epoch: 15.\n","13/13 [==============================] - 27s 2s/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.0385 - val_accuracy: 0.9896\n","Epoch 20: early stopping\n"]}],"source":["# 모델 학습(fit)\n","train_hist = model_Xception.fit(train_generator, validation_data=valid_generator,\n","                                batch_size=32, epochs=500, callbacks=[es], verbose=1)"]},{"cell_type":"code","source":["# model_googLeNet\n","# 모델 학습(fit)\n","train_hist = model_googLeNet.fit(train_generator, validation_data=valid_generator,\n","                                batch_size=32, epochs=500, callbacks=[es], verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"PRkmX0-h5qBh","outputId":"4383bbc6-06d0-451a-f0ed-614e6effda2d","executionInfo":{"status":"error","timestamp":1679462312146,"user_tz":-540,"elapsed":696,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":25,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-062326e02089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model_googLeNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 모델 학습(fit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_hist = model_googLeNet.fit(train_generator, validation_data=valid_generator,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                 batch_size=32, epochs=500, callbacks=[es], verbose=1)\n","\u001b[0;31mNameError\u001b[0m: name 'model_googLeNet' is not defined"]}]},{"cell_type":"markdown","source":["#### 4) 성능 평가\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"BdKiY1uIf663"}},{"cell_type":"code","execution_count":26,"metadata":{"id":"1qjnvt0lf663","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a8379d6-e7d4-4dec-9143-05156c65fbf1","executionInfo":{"status":"ok","timestamp":1679463416876,"user_tz":-540,"elapsed":6711,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 5s 1s/step\n"]}],"source":["y_pred_Xception = model_Xception.predict(test_x)"]},{"cell_type":"code","source":["y_pred_Xception.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iuLrlmCS9UGA","outputId":"a707993a-4380-4c52-9f23-df267c6970b3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(121, 1)"]},"metadata":{},"execution_count":108}]},{"cell_type":"code","execution_count":27,"metadata":{"id":"bBl4Do0af663","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f4a7792c-a044-4bed-e6a3-3674899d0f51","executionInfo":{"status":"ok","timestamp":1679463422449,"user_tz":-540,"elapsed":5577,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 4s 1s/step - loss: 0.0298 - accuracy: 0.9835\n"]}],"source":["performance_test = model_Xception.evaluate(test_generator)"]},{"cell_type":"code","source":["y_pred = model_Xception.predict(x_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":170},"id":"XTlV5QUS0h9G","executionInfo":{"status":"error","timestamp":1679463453425,"user_tz":-540,"elapsed":535,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"06c12bda-7457-4eaf-c74a-aa57006fbba4"},"execution_count":28,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-f84334cb4d22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_Xception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"]}]},{"cell_type":"code","source":["print('Test Loss : {:.6f},  Test Accuracy : {:.3f}%'.format(performance_test[0], performance_test[1]*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S7neDQZK9wsB","outputId":"5a869485-4f6b-44ca-d96b-facc5cd43c5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss : 0.099654,  Test Accuracy : 98.347%\n"]}]},{"cell_type":"code","source":["performance_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbMLLMMj-ogt","outputId":"93b698fb-8c10-4cd4-f204-a5c2e08d48df"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[4.364559650421143, 0.11570248007774353]"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["preds_1d = y_pred_Xception.flatten() # 차원 펴주기\n","pred_class = np.where(preds_1d > 0.5, 1 , 0) #0.5보다크면 2, 작으면 1"],"metadata":{"id":"1ReO6SPU-9dX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_class"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MUZaSmx__WRo","outputId":"7eeab3d9-95fe-459e-e69d-9e76326dc40a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0])"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":[],"metadata":{"id":"J-Mt-6sI_Y9a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","\n","print(confusion_matrix(test_y, pred_class))\n","print(classification_report(test_y, pred_class))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JdQD4j0W_Brv","outputId":"fb968a3b-a51b-4e82-ef33-1642eab07a20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0 60]\n"," [47 14]]\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        60\n","           1       0.19      0.23      0.21        61\n","\n","    accuracy                           0.12       121\n","   macro avg       0.09      0.11      0.10       121\n","weighted avg       0.10      0.12      0.10       121\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8q6bs_k9_G-R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# googLeNet 결과\n","y_pred_goog = model_googLeNet.predict(test_x_minmax)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X9B9sDblDvwS","outputId":"f988cd94-77ed-4344-cd0f-820576104c24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 44ms/step\n"]}]},{"cell_type":"code","source":["y_pred_goog[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jiMO3ThqD7Nr","outputId":"add404f4-d289-4e94-851f-3c70c44df354"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(121, 1)"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["model_Xception.evaluate(test_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-EOYyhgEGDV5","outputId":"a91767ad-7b3e-4756-91db-7cd0cc89a830"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 4s 971ms/step - loss: 0.5708 - accuracy: 0.8843\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.5708385705947876, 0.8842975497245789]"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["model_googLeNet.evaluate(test_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCvs7gpQFfDZ","outputId":"a02ceb76-5be3-4fde-bf87-f186c7362d59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 22s 7s/step - loss: 0.5901 - dense_4_loss: 0.3697 - dense_1_loss: 0.3731 - dense_3_loss: 0.3618 - dense_4_accuracy: 0.8099 - dense_1_accuracy: 0.8264 - dense_3_accuracy: 0.8264\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.5901301503181458,\n"," 0.36965054273605347,\n"," 0.3731386661529541,\n"," 0.36179351806640625,\n"," 0.8099173307418823,\n"," 0.8264462947845459,\n"," 0.8264462947845459]"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["performance_test = model_googLeNet.evaluate(test_x_minmax, test_y, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HyDZ4yndD_Ne","outputId":"10c49ad6-2ef5-4492-c17f-7e206df2019a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 51ms/step - loss: 3.6194 - dense_4_loss: 2.2328 - dense_1_loss: 2.0876 - dense_3_loss: 2.5344 - dense_4_accuracy: 0.1901 - dense_1_accuracy: 0.1736 - dense_3_accuracy: 0.1736\n"]}]},{"cell_type":"code","source":["performance_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5eTZNqrCEFjj","outputId":"9500edd8-c2e1-4be1-a7a1-1eaadb465c9a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[3.6194119453430176,\n"," 2.232811212539673,\n"," 2.087596893310547,\n"," 2.534405469894409,\n"," 0.1900826394557953,\n"," 0.1735537201166153,\n"," 0.1735537201166153]"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":[],"metadata":{"id":"kG748f2tEfaz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S1iv22vSxXle"},"source":["### (2) Transfer Learning\n","- **세부요구사항**\n","    * VGG16 모델은 1000개의 클래스를 분류하는 데 사용된 ImageNet 데이터셋을 기반으로 사전 학습된 가중치를 가지고 있습니다. \n","        * 따라서 이 모델은 이미지 분류 문제에 대한 높은 성능을 보입니다.\n","        * 이 모델은 보통 전이학습(transfer learning)에서 기본적으로 사용되며, 특히 대규모 데이터셋이 없을 때는 기본 모델로 사용되어 fine-tuning을 수행합니다.\n","    * VGG16 함수로 부터 base_model 저장\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RnS12YhDxXle"},"outputs":[],"source":["from tensorflow.keras.applications import VGG16"]},{"cell_type":"markdown","source":["#### 1) VGG16 불러와서 저장하기\n","* include_top=False로 설정하여 분류기를 제외하고 미리 학습된 가중치 imagenet을 로드합니다.\n","* .trainable을 True로 설정하여 모델의 모든 레이어들이 fine-tuning에 대해 업데이트되도록 합니다.\n"],"metadata":{"id":"d3kyvCwIiAfi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFf3IxbBGe9B"},"outputs":[],"source":["base_model = VGG16(                 )\n","\n","\n"]},{"cell_type":"markdown","source":["#### 2) VGG16과 연결한 구조 설계\n","* VGG16을 불러와서 Flatten, Dense 등으로 레이어 연결하기"],"metadata":{"id":"D-JjBLZZiIxA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yg4KhHQ8xXlf"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5V5heiDxxXlf"},"source":["#### 3) 학습\n","- **세부요구사항**\n","    - 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n","    - 데이터\n","        * Image Generator를 연결하거나\n","        * 기존 train, validation 셋을 이용해도 됩니다.\n","        - Early Stopping을 반드시 사용하세요.\n","        - 최적의 가중치를 모델에 적용하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CtqQIS-HxXlg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zg0L88Gwf4l"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#### 4) 성능 평가"],"metadata":{"id":"BbhiWcS5i735"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ik4AFzCQi735"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zkkSsyMoi735"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGuQMUJNxXSy"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}