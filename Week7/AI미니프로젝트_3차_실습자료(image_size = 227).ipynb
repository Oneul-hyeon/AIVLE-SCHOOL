{"cells":[{"cell_type":"markdown","metadata":{"id":"JLojLUpcGNbk"},"source":["# **차량 공유업체의 차량 파손 여부 분류하기**"]},{"cell_type":"markdown","source":["## 0.미션\n","\n","* 1) 미션1 : Data Preprocessing\n","    - **과제 수행 목표**\n","        - 본인의 구글 드라이브에 모델링 수행을 위해 적절한 폴더 및 파일로 **일관성 있게 정리**해야 합니다.\n","        - 제공된 데이터 : Car_Images.zip\n","            * Car_Images : 차량의 정상/파손 이미지 무작위 수집"],"metadata":{"id":"BbrllJY8JdkF"}},{"cell_type":"markdown","source":["* 2) 미션2 : CNN 모델링\n","    - **과제 수행 목표**\n","        - Tensorflow Keras를 이용하여 모델을 3개 이상 생성하세요.\n","            - 모델 구조와 파라미터는 자유롭게 구성하세요.\n","            - 단, 세부 목차에서 명시한 부분은 지켜주세요."],"metadata":{"id":"Hgdg96jE-mmd"}},{"cell_type":"markdown","source":["* 3) 미션3 : Data Argumentation & Transfer Learning\n","    - **과제 수행 목표**\n","        - 성능 개선을 위해 다음의 두가지를 시도하세요.\n","            * Data Augmentation을 적용하세요.(Image Generator)\n","            * Transfer Learning(VGG16)\n"],"metadata":{"id":"VRrUY4ud_rJV"}},{"cell_type":"markdown","metadata":{"id":"7MdjZtxfGNKz"},"source":["## 1.환경설정 "]},{"cell_type":"markdown","metadata":{"id":"6QgFWzN9xhlr"},"source":["### (1) 데이터셋 폴더 생성\n","- **세부요구사항**\n","    - C드라이브에 Datasets라는 폴더를 만드세요.\n","        - 구글드라이브를 사용하는경우 드라이브 첫 화면에 Datasets 라는 폴더를 만드세요. ('/content/drive/MyDrive/Datasets/')\n","    - 해당 폴더 안에 Car_Images.zip 파일을 넣으세요."]},{"cell_type":"markdown","source":["* 구글 Colab을 이용하는 경우"],"metadata":{"id":"Elg8NL8vwUs5"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"kWUbDvBzwiTq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679445443366,"user_tz":-540,"elapsed":26784,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"3c071c72-fe34-4d39-9a69-f5994528b896"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!mkdir /content/drive/MyDrive/Datasets"],"metadata":{"id":"D3qJC5lpk8bC","executionInfo":{"status":"ok","timestamp":1679379943253,"user_tz":-540,"elapsed":10,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"76010e80-e2f3-4467-911c-7dcddde21e90","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/Datasets’: File exists\n"]}]},{"cell_type":"markdown","metadata":{"id":"0sVNbCKnLUGc"},"source":["### (2) 데이터셋 불러오기 \n","- **세부요구사항**\n","    - Car_Images.zip 파일을 C:/Datasets/ 경로에 압축 해제합니다.\n","    - zipfile 모듈을 이용하거나 다른 방식을 사용해도 됩니다.\n","        - 참고 자료 : [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n","    - 폴더구조(로컬)\n","        * C:/Datasets/ : 압축파일\n","        * C:/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n","    - 폴더구조(구글드라이브브)\n","        * /content/drive/MyDrive/Datasets/ : 압축파일\n","        * /content/drive/MyDrive/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n","    - 압축을 해제하면 다음과 같은 두 하위 폴더가 생성됩니다.\n","        * normal, abnormal : 각 폴더에는 이미지들이 있습니다.\n","        * 이후 단계에서 해당 경로로 부터 validation, test 셋을 추출하게 됩니다.\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2-8EaA9x4Xm"},"outputs":[],"source":["import zipfile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMkstFLKx4Xm"},"outputs":[],"source":["# 압축파일 경로\n","# 구글 드라이브인 경우 경로에 맞게 지정하세요.\n","# dataset_path  = '/content/drive/MyDrive/Datasets/'\n","dataset_path = '/content/drive/MyDrive/Datasets/'\n","\n","file_path = dataset_path + 'Car_Images.zip'"]},{"cell_type":"code","source":["!mkdir /content/drive/MyDrive/Datasets/Car_Image_train; "],"metadata":{"id":"7oMqiXatp8ys"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgT_RB14Lwza"},"outputs":[],"source":["# 압축 해제\n","data = zipfile.ZipFile('/content/drive/MyDrive/Car_Images.zip')\n","data.extractall('/content/drive/MyDrive/Datasets/Car_Image_train')"]},{"cell_type":"markdown","metadata":{"id":"8hgC0axQyMhI"},"source":["### (3) 이미지 저장을 위한 폴더 생성\n","- **세부요구사항**\n","    - train, validation, test 을 위해 각각 하위 폴더 normal과 abnormal를 준비합니다.\n","        - train\n","            * 정상 이미지 저장소 : C:/Datasets/Car_Images_train/normal/ \n","                * 구글드라이브 :   /content/drive/MyDrive/Datasets/Car_Images_train/normal/\n","            * 파손 이미지 저장소 : C:/Datasets/Car_Images_train/abnormal/\n","                * 구글드라이브 : /content/drive/MyDrive/Datasets/Car_Images_train/abnormal/\n","        - val, test 역시 동일한 구조로 생성합니다.\n","    - 직접 탐색기에서 폴더를 생성할 수도 있고, os 모듈을 이용하여 코드로 작성할 수도 있습니다.\n","        - 참고 자료 : [os document](https://docs.python.org/3/library/os.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rc8GnuauOzLf"},"outputs":[],"source":["# train 폴더는 압축을 해제하면서 이미 생성 되어 있습니다.\n","\n","# test 폴더 만들기 os.mkdir()\n","!mkdir /content/drive/MyDrive/Datasets/Car_Image_test; \n","!mkdir /content/drive/MyDrive/Datasets/Car_Image_test/normal\n","!mkdir /content/drive/MyDrive/Datasets/Car_Image_test/abnormal\n","\n","# validation 폴더 만들기\n","!mkdir /content/drive/MyDrive/Datasets/Car_Image_val; \n","!mkdir /content/drive/MyDrive/Datasets/Car_Image_val/normal\n","!mkdir /content/drive/MyDrive/Datasets/Car_Image_val/abnormal\n"]},{"cell_type":"code","source":["len(os.listdir('/content/drive/MyDrive/Datasets/Car_Image_test/normal/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":134},"id":"mkSa0uYAUt1N","executionInfo":{"status":"error","timestamp":1679471884358,"user_tz":-540,"elapsed":338,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"53f96eca-7619-44d7-9de7-348305d07d67"},"execution_count":147,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-147-cc9418777a91>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    len(os.listdir('/content/drive/MyDrive/Datasets/Car_Image_test/normal/')\u001b[0m\n\u001b[0m                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"]}]},{"cell_type":"markdown","metadata":{"id":"FYZKJrP0GtPh"},"source":["## 2.데이터 전처리"]},{"cell_type":"markdown","metadata":{"id":"j-ilpDQfInAE"},"source":["### (1) 데이터 분할 : Training set | Validation set | Test set 생성\n","- **세부요구사항**\n","    - Training set, Validation set, Test set을 만듭니다.\n","        * size\n","            * test : 전체에서 20%를 추출합니다.\n","            * validation : test를 떼어낸 나머지에서 다시 20%를 추출합니다.\n","        * 데이터는 랜덤하게 추출해야 합니다.\n","            - random, shutil 모듈을 이용하여 랜덤하게 추출할 수 있습니다.\n","                - [random document](https://docs.python.org/3/library/random.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","            * 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"]},{"cell_type":"markdown","source":["#### 1) test, validation 크기를 지정"],"metadata":{"id":"mFMSDA26RS-E"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JhQ_Gu_KNR2g"},"outputs":[],"source":["import random, shutil, os\n","import numpy as np"]},{"cell_type":"code","source":["tr_n_path = '/content/drive/MyDrive/Datasets/Car_Image_train/normal/'\n","tr_ab_path = '/content/drive/MyDrive/Datasets/Car_Image_train/abnormal/'"],"metadata":{"id":"1rsajRs12URF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PdU7X9e70dBu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679379962260,"user_tz":-540,"elapsed":24,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"86fe6430-d947-4cd9-b94c-4bf55ea85c9c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(302, 303)"]},"metadata":{},"execution_count":10}],"source":["# 전체 이미지 갯수를 확인합니다.\n","len(os.listdir(tr_n_path)) , len(os.listdir(tr_ab_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oa2mxylBDVM5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679379962260,"user_tz":-540,"elapsed":19,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"1811170d-0bd2-4750-e5b8-8bc91a44d2d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["[60, 61]\n","[48, 48]\n","[194, 194]\n"]}],"source":["# test 사이즈 : 전체 이미지의 20%\n","te_data_num = [round(len(os.listdir(tr_n_path))*0.2), round(len(os.listdir(tr_ab_path))*0.2)]\n","print(te_data_num)\n","\n","# validation 사이즈 : test를 제외한 나머지 중에서 20%\n","val_data_num = [ round((len(os.listdir(tr_n_path))-te_data_num[0])*0.2) , round((len(os.listdir(tr_n_path))-te_data_num[1])*0.2) ]\n","print(val_data_num)\n","\n","# train 사이즈\n","train_data_num = [len(os.listdir(tr_n_path)) - te_data_num[0] - val_data_num[0],\n","                  len(os.listdir(tr_ab_path))- te_data_num[1] - val_data_num[1]]\n","print(train_data_num)"]},{"cell_type":"code","source":["train_n_set = os.listdir(tr_n_path)\n","train_ab_set = os.listdir(tr_ab_path)"],"metadata":{"id":"VitSC3is_VGl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2) test 셋 추출"],"metadata":{"id":"RmRhrViWRXgL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TSwovHr2Fon1"},"outputs":[],"source":["random.seed(2023)\n","te_n_path = '/content/drive/MyDrive/Datasets/Car_Image_test/normal/'\n","te_ab_path = '/content/drive/MyDrive/Datasets/Car_Image_test/abnormal/'\n","\n","test_n_set = random.sample(os.listdir(tr_n_path), k = round(len(os.listdir(tr_n_path))*0.2))\n","test_ab_set = random.sample(os.listdir(tr_ab_path), k = round(len(os.listdir(tr_ab_path))*0.2))\n","for file in test_n_set :\n","    now_path = tr_n_path + file\n","    shutil.move(now_path, te_n_path)\n","\n","for file in test_ab_set :\n","    now_path = tr_ab_path + file\n","    shutil.move(now_path, te_ab_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AImO1ujiI2IY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679379962927,"user_tz":-540,"elapsed":8,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"0224accf-5a82-449e-fcd3-c5107e6e128a"},"outputs":[{"output_type":"stream","name":"stdout","text":["60 61\n","242 242\n"]}],"source":["# 추출 후 이미지 갯수 확인\n","\n","print(len(os.listdir(te_n_path)), len(os.listdir(te_ab_path)))\n","print(len(os.listdir(tr_n_path)) , len(os.listdir(tr_ab_path)))"]},{"cell_type":"markdown","source":["#### 3) validation 셋 추출"],"metadata":{"id":"2V4mh3hxRpR2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXYmEdCjAEDu"},"outputs":[],"source":["random.seed(2023)\n","val_n_path = '/content/drive/MyDrive/Datasets/Car_Image_val/normal/'\n","val_ab_path = '/content/drive/MyDrive/Datasets/Car_Image_val/abnormal/'\n","\n","val_n_set = random.sample(os.listdir(tr_n_path), k = round(len(os.listdir(tr_n_path))*0.2))\n","val_ab_set = random.sample(os.listdir(tr_ab_path), k = round(len(os.listdir(tr_ab_path))*0.2))\n","\n","for file in val_n_set :\n","    now_path = tr_n_path + file\n","    shutil.move(now_path, val_n_path)\n","\n","for file in val_ab_set :\n","    now_path = tr_ab_path + file\n","    shutil.move(now_path, val_ab_path)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIT85iSdM4U-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679379962928,"user_tz":-540,"elapsed":8,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"0100ff46-bf24-497a-e6ca-0812419e7ca0"},"outputs":[{"output_type":"stream","name":"stdout","text":["48 48\n","194 194\n"]}],"source":["# 추출 후 이미지 갯수 확인\n","len(val_n_set), len(val_ab_set)\n","\n","print(len(os.listdir(val_n_path)), len(os.listdir(val_ab_path)))\n","print(len(os.listdir(tr_n_path)) , len(os.listdir(tr_ab_path)))"]},{"cell_type":"code","source":["print(len(os.listdir(te_n_path)), len(os.listdir(te_ab_path)))\n","print(len(os.listdir(val_n_path)), len(os.listdir(val_ab_path)))\n","print(len(os.listdir(tr_n_path)) , len(os.listdir(tr_ab_path)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwI01TuQAEFD","executionInfo":{"status":"ok","timestamp":1679379962928,"user_tz":-540,"elapsed":5,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"4fa11d0d-c6c7-4cff-df43-2dfdb1e678c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["60 61\n","48 48\n","194 194\n"]}]},{"cell_type":"markdown","metadata":{"id":"haSO004sgyyu"},"source":["### (2) 데이터 복사 및 이동\n","- **세부요구사항**\n","    - 분할된 데이터를 복사 이동합니다.\n","        - 새로운 폴더에 저장하는 데이터로 \"3.모델링I\"에서 사용합니다.\n","        - 기존 폴더는 \"4.모델링II > (1) Data Augmentation\"에서 사용합니다.\n","    - Training set | Validation set | Test set의 데이터를 **새로운 폴더**에 복사하세요.\n","        - 새로운 폴더 명\n","            * copy_images/trainset\n","            * copy_images/validset\n","            * copy_images/testset\n","        - 새로운 폴더에는 normal, abnormal 파일 모두를 복사합니다. \n","            * 파일을 구분하기 위해 abnormal 파일들은 파일명 앞에 접두사 'ab_'를 붙입시다.\n","        - os, shutil 모듈을 활용하세요."]},{"cell_type":"markdown","source":["#### 1) abnormal 파일 복사"],"metadata":{"id":"3UbNfTY4kOSZ"}},{"cell_type":"markdown","source":["* 복사하기 : shutil.copytree()"],"metadata":{"id":"zhkKqLfTkjGI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTMVxJJJya98","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1679379968128,"user_tz":-540,"elapsed":5204,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"7ce531e0-8013-4ec7-b7b8-eb12ccf19b2c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Datasets/copy_images/testset/'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}],"source":["shutil.copytree('/content/drive/MyDrive/Datasets/Car_Image_train/abnormal/', dataset_path+'copy_images/trainset/')\n","shutil.copytree('/content/drive/MyDrive/Datasets/Car_Image_val/abnormal/', dataset_path+'copy_images/validset/')\n","shutil.copytree('/content/drive/MyDrive/Datasets/Car_Image_test/abnormal/', dataset_path+'copy_images/testset/')"]},{"cell_type":"markdown","source":["* abnormal 이미지 이름의 접두어 \"ab_\" 붙이기 : os.rename"],"metadata":{"id":"mU0T-ypHkV6D"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cv6gafRyz6ul","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679379968768,"user_tz":-540,"elapsed":646,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"90fc224b-3e88-400b-f847-52ccb2238e02"},"outputs":[{"output_type":"stream","name":"stdout","text":["DALLíñE 2023-03-10 18.51.26 - scratched car.png\n","DALLíñE 2023-03-10 18.51.29 - scratched car.png\n","DALLíñE 2023-03-10 18.51.32 - scratched car.png\n","DALLíñE 2023-03-10 18.53.06 - scratched car.png\n","DALLíñE 2023-03-10 18.53.08 - scratched car.png\n","DALLíñE 2023-03-10 18.53.58 - slightly damaged car.png\n","DALLíñE 2023-03-10 18.54.17 - slightly damaged car.png\n","DALLíñE 2023-03-10 18.54.19 - slightly damaged car.png\n","DALLíñE 2023-03-10 18.54.24 - slightly damaged car.png\n","DALLíñE 2023-03-10 22.04.36 - scratched car.png\n","DALLíñE 2023-03-10 22.04.39 - scratched car.png\n","DALLíñE 2023-03-10 22.04.42 - scratched car.png\n","DALLíñE 2023-03-10 22.37.56 - photo of a part of car.png\n","DALLíñE 2023-03-10 23.28.30 - photo of a part of car without blemish.png\n","DALLíñE 2023-03-10 23.34.52 - photo of a part of car without blemish.png\n","DALLíñE 2023-03-10 23.39.41 - photo of a part of car without blemish.png\n","DALLíñE 2023-03-10 23.55.00 - a part of car without blemish.png\n","DALLíñE 2023-03-10 23.55.04 - a part of car without blemish.png\n","DALLíñE 2023-03-10 23.56.50 - a part of car without blemish.png\n","DALLíñE 2023-03-10 23.57.31 - a part of car without blemish.png\n","DALLíñE 2023-03-10 23.58.03 - a part of car without blemish.png\n","DALLíñE 2023-03-10 23.58.06 - a part of car without blemish.png\n","DALLíñE 2023-03-11 00.03.13 - a part of car without blemish.png\n","DALLíñE 2023-03-11 00.12.34 - a part of car without scrach.png\n","DALLíñE 2023-03-11 00.14.25 - a part of car without scratch.png\n","DALLíñE 2023-03-11 00.14.28 - a part of car without scratch.png\n","DALLíñE 2023-03-11 00.16.36 - photo of a part of car without blemish.png\n","DALLíñE 2023-03-11 01.21.50 - scratched car.png\n","DALLíñE 2023-03-11 01.22.25 - scratched car.png\n","DALLíñE 2023-03-11 01.22.27 - scratched car.png\n","DALLíñE 2023-03-11 01.23.26 - slightly damaged car.png\n","DALLíñE 2023-03-11 01.23.29 - slightly damaged car.png\n","DALLíñE 2023-03-11 01.23.56 - slightly damaged car.png\n","DALLíñE 2023-03-11 01.23.58 - slightly damaged car.png\n","DALLíñE 2023-03-11 01.25.20 - slightly scratched car.png\n","DALLíñE 2023-03-11 01.25.26 - slightly scratched car.png\n","DALLíñE 2023-03-11 01.29.03 - scratched car.png\n","DALLíñE 2023-03-11 01.29.04 - scratched car.png\n","DALLíñE 2023-03-11 01.29.06 - scratched car.png\n","DALLíñE 2023-03-11 01.29.08 - scratched car.png\n","DALLíñE 2023-03-11 01.29.55 - a little bit scratched car.png\n","DALLíñE 2023-03-11 01.30.00 - a little bit scratched car.png\n","DALLíñE 2023-03-11 01.30.47 - a little bit scratched car.png\n","DALLíñE 2023-03-11 01.30.49 - a little bit scratched car.png\n","DALLíñE 2023-03-11 01.31.20 - slightly damaged car.png\n","DALLíñE 2023-03-11 01.31.29 - slightly damaged car.png\n","DALLíñE 2023-03-11 01.32.19 - a little bit scratched car.png\n","DALLíñE 2023-03-11 01.32.21 - a little bit scratched car.png\n","DALLíñE 2023-03-11 01.32.23 - a little bit scratched car.png\n","DALLíñE 2023-03-11 01.32.25 - a little bit scratched car.png\n","DALLíñE 2023-03-11 01.32.58 - slightly damaged car.png\n","DALLíñE 2023-03-11 01.33.00 - slightly damaged car.png\n","DALLíñE 2023-03-11 14.48.31 - dents of a car.png\n","DALLíñE 2023-03-11 14.48.33 - dents of a car.png\n","DALLíñE 2023-03-11 14.49.06 - dents of a car.png\n","DALLíñE 2023-03-11 14.49.32 - dents of a car.png\n","DALLíñE 2023-03-11 14.49.59 - dents of a car.png\n","DALLíñE 2023-03-11 14.50.01 - dents of a car.png\n","DALLíñE 2023-03-11 14.50.36 - dents of a car.png\n","DALLíñE 2023-03-11 14.50.39 - dents of a car.png\n","DALLíñE 2023-03-11 14.51.19 - dents of a car.png\n","DALLíñE 2023-03-11 14.52.54 - dents of a car.png\n","DALLíñE 2023-03-11 14.52.56 - dents of a car.png\n","DALLíñE 2023-03-11 14.53.25 - dents of a car.png\n","DALLíñE 2023-03-11 14.53.49 - dents of a car.png\n","DALLíñE 2023-03-11 14.53.52 - dents of a car.png\n","DALLíñE 2023-03-11 14.54.38 - dents of a car.png\n","DALLíñE 2023-03-11 14.54.42 - dents of a car.png\n","DALLíñE 2023-03-11 14.55.03 - dents of a car.png\n","DALLíñE 2023-03-11 14.55.32 - dents of a car.png\n","DALLíñE 2023-03-11 14.55.34 - dents of a car.png\n","DALLíñE 2023-03-11 14.56.30 - dents of a car.png\n","DALLíñE 2023-03-11 14.56.57 - dents of a car.png\n","DALLíñE 2023-03-11 14.57.01 - dents of a car.png\n","DALLíñE 2023-03-11 14.57.26 - dents of a car.png\n","DALLíñE 2023-03-11 14.57.28 - dents of a car.png\n","DALLíñE 2023-03-11 14.58.17 - dents of a car.png\n","DALLíñE 2023-03-11 14.58.40 - dents of a car.png\n","DALLíñE 2023-03-11 14.59.08 - dents of a car.png\n","DALLíñE 2023-03-11 14.59.32 - dents of a car.png\n","DALLíñE 2023-03-11 15.00.14 - dents of a car.png\n","DALLíñE 2023-03-11 15.00.21 - dents of a car.png\n","DALLíñE 2023-03-11 15.00.43 - dents of a car.png\n","DALLíñE 2023-03-11 15.01.15 - dents of a car.png\n","DALLíñE 2023-03-11 15.01.57 - dents of a car.png\n","DALLíñE 2023-03-11 15.02.00 - dents of a car.png\n","DALLíñE 2023-03-11 15.03.37 - dents of a car.png\n","DALLíñE 2023-03-11 15.04.50 - dents of a car.png\n","DALLíñE 2023-03-11 15.05.16 - dents of a car.png\n","DALLíñE 2023-03-11 15.05.23 - dents of a car.png\n","DALLíñE 2023-03-11 15.05.44 - dents of a car.png\n","DALLíñE 2023-03-11 15.05.50 - dents of a car.png\n","DALLíñE 2023-03-11 15.06.13 - dents of a car.png\n","DALLíñE 2023-03-11 15.06.15 - dents of a car.png\n","DALLíñE 2023-03-11 15.06.35 - dents of a car.png\n","DALLíñE 2023-03-11 15.07.12 - dents of a car.png\n","DALLíñE 2023-03-11 15.07.39 - dents of a car.png\n","DALLíñE 2023-03-11 15.08.00 - dents of a car.png\n","DALLíñE 2023-03-11 15.08.05 - dents of a car.png\n","DALLíñE 2023-03-11 15.08.24 - dents of a car.png\n","DALLíñE 2023-03-11 15.08.28 - dents of a car.png\n","DALLíñE 2023-03-11 15.08.48 - dents of a car.png\n","DALLíñE 2023-03-11 15.08.50 - dents of a car.png\n","DALLíñE 2023-03-11 15.08.52 - dents of a car.png\n","DALLíñE 2023-03-11 15.08.54 - dents of a car.png\n","DALLíñE 2023-03-11 15.09.38 - dents of a car.png\n","DALLíñE 2023-03-11 15.09.54 - dents of a car.png\n","DALLíñE 2023-03-11 15.09.59 - dents of a car.png\n","DALLíñE 2023-03-11 15.10.01 - dents of a car.png\n","DALLíñE 2023-03-11 15.10.43 - dents of a car.png\n","DALLíñE 2023-03-11 15.11.06 - dents of a car.png\n","DALLíñE 2023-03-11 15.11.09 - dents of a car.png\n","DALLíñE 2023-03-11 15.12.06 - dents of a car.png\n","DALLíñE 2023-03-11 15.12.25 - dents of a car.png\n","DALLíñE 2023-03-11 15.12.28 - dents of a car.png\n","DALLíñE 2023-03-11 15.12.31 - dents of a car.png\n","DALLíñE 2023-03-11 15.13.25 - dents of a car.png\n","DALLíñE 2023-03-11 15.13.45 - dents of a car.png\n","DALLíñE 2023-03-11 15.13.48 - dents of a car.png\n","DALLíñE 2023-03-11 17.10.24 - scratched car.png\n","DALLíñE 2023-03-11 17.10.30 - scratched car.png\n","DALLíñE 2023-03-11 17.14.15 - scratched car.png\n","DALLíñE 2023-03-11 17.14.17 - scratched car.png\n","DALLíñE 2023-03-11 17.14.21 - scratched car.png\n","DALLíñE 2023-03-11 17.15.16 - scratched car.png\n","DALLíñE 2023-03-11 17.15.20 - scratched car.png\n","DALLíñE 2023-03-11 17.15.58 - damaged car.png\n","DALLíñE 2023-03-11 17.16.21 - damaged car.png\n","DALLíñE 2023-03-11 17.16.24 - damaged car.png\n","DALLíñE 2023-03-11 17.16.50 - damaged car.png\n","DALLíñE 2023-03-11 17.16.53 - damaged car.png\n","DALLíñE 2023-03-11 17.17.27 - scratched car.png\n","DALLíñE 2023-03-11 17.17.32 - scratched car.png\n","DALLíñE 2023-03-11 17.17.37 - scratched car.png\n","DALLíñE 2023-03-11 17.18.02 - scratched car.png\n","DALLíñE 2023-03-11 17.18.25 - scratched car.png\n","DALLíñE 2023-03-11 17.18.29 - scratched car.png\n","DALLíñE 2023-03-11 17.18.31 - scratched car.png\n","DALLíñE 2023-03-11 17.18.46 - scratched car.png\n","DALLíñE 2023-03-11 17.18.47 - scratched car.png\n","DALLíñE 2023-03-11 17.18.49 - scratched car.png\n","DALLíñE 2023-03-11 17.18.51 - scratched car.png\n","DALLíñE 2023-03-11 17.22.16 - scratched car.png\n","DALLíñE 2023-03-11 17.23.56 - slightly dented car.png\n","DALLíñE 2023-03-11 17.23.58 - slightly dented car.png\n","DALLíñE 2023-03-11 17.24.00 - slightly dented car.png\n","DALLíñE 2023-03-11 17.25.10 - slightly dented car.png\n","DALLíñE 2023-03-11 17.25.12 - slightly dented car.png\n","DALLíñE 2023-03-11 17.25.14 - slightly dented car.png\n","DALLíñE 2023-03-11 17.26.11 - slightly dented car.png\n","DALLíñE 2023-03-11 17.26.14 - slightly dented car.png\n","DALLíñE 2023-03-11 17.26.17 - slightly dented car.png\n","DALLíñE 2023-03-11 17.27.04 - slightly dented car.png\n","DALLíñE 2023-03-11 17.27.08 - slightly dented car.png\n","DALLíñE 2023-03-11 17.27.56 - slightly dented car.png\n","DALLíñE 2023-03-11 17.27.58 - slightly dented car.png\n","DALLíñE 2023-03-11 17.28.25 - slightly dented car.png\n","DALLíñE 2023-03-11 17.28.29 - slightly dented car.png\n","DALLíñE 2023-03-11 17.28.31 - slightly dented car.png\n","DALLíñE 2023-03-11 17.28.33 - slightly dented car.png\n","DALLíñE 2023-03-11 17.29.49 - slightly dented car.png\n","DALLíñE 2023-03-11 17.29.59 - slightly dented car.png\n","DALLíñE 2023-03-11 17.30.01 - slightly dented car.png\n","DALLíñE 2023-03-11 17.30.04 - slightly dented car.png\n","DALLíñE 2023-03-11 17.31.37 - slightly dented car.png\n","DALLíñE 2023-03-11 17.31.41 - slightly dented car.png\n","DALLíñE 2023-03-11 17.31.55 - slightly dented car.png\n","DALLíñE 2023-03-11 18.41.26 - slightly dented car.png\n","DALLíñE 2023-03-11 18.41.32 - slightly dented car.png\n","DALLíñE 2023-03-11 18.41.54 - slightly dented car.png\n","DALLíñE 2023-03-11 18.41.56 - slightly dented car.png\n","DALLíñE 2023-03-11 18.42.01 - slightly dented car.png\n","DALLíñE 2023-03-11 18.42.06 - slightly dented car.png\n","DALLíñE 2023-03-11 18.42.27 - slightly dented car.png\n","DALLíñE 2023-03-11 18.42.29 - slightly dented car.png\n","DALLíñE 2023-03-11 18.42.32 - slightly dented car.png\n","DALLíñE 2023-03-11 18.42.57 - slightly dented car.png\n","DALLíñE 2023-03-11 18.42.59 - slightly dented car.png\n","DALLíñE 2023-03-11 18.43.01 - slightly dented car.png\n","DALLíñE 2023-03-11 18.43.03 - slightly dented car.png\n","DALLíñE 2023-03-11 18.43.29 - slightly dented car.png\n","DALLíñE 2023-03-11 18.43.31 - slightly dented car.png\n","DALLíñE 2023-03-11 18.43.34 - slightly dented car.png\n","DALLíñE 2023-03-11 18.44.13 - slightly dented car.png\n","DALLíñE 2023-03-11 18.44.30 - slightly dented car.png\n","DALLíñE 2023-03-11 18.44.56 - slightly dented car.png\n","DALLíñE 2023-03-11 18.45.00 - slightly dented car.png\n","DALLíñE 2023-03-11 18.45.06 - slightly dented car.png\n","DALLíñE 2023-03-11 18.45.28 - slightly dented car.png\n","DALLíñE 2023-03-11 18.45.32 - slightly dented car.png\n","DALLíñE 2023-03-11 18.45.52 - scratched car.png\n","DALLíñE 2023-03-11 18.45.56 - scratched car.png\n","DALLíñE 2023-03-11 18.46.00 - scratched car.png\n","DALLíñE 2023-03-11 18.46.24 - scratched car.png\n"]}],"source":["trainset_path = '/content/drive/MyDrive/Datasets/copy_images/trainset/'\n","validset_path = '/content/drive/MyDrive/Datasets/copy_images/validset/'\n","testset_path = '/content/drive/MyDrive/Datasets/copy_images/testset/'\n","\n","for file in os.listdir(trainset_path) :\n","    print(file)\n","    os.rename(trainset_path + file, trainset_path + 'ab_' + file)\n","\n","for file in os.listdir(validset_path) :\n","    os.rename(validset_path + file, validset_path + 'ab_' + file)\n","\n","for file in os.listdir(testset_path) :\n","    os.rename(testset_path + file, testset_path + 'ab_' + file)\n","\n"]},{"cell_type":"markdown","source":["#### 2) normal 파일 복사"],"metadata":{"id":"Nk6xITmTksyK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vw3DmdTS17RM"},"outputs":[],"source":["nomal_train_path = '/content/drive/MyDrive/Datasets/Car_Image_train/normal/'\n","nomal_val_path = '/content/drive/MyDrive/Datasets/Car_Image_val/normal/'\n","nomal_test_path = '/content/drive/MyDrive/Datasets/Car_Image_test/normal/'\n","\n","for file in os.listdir(nomal_train_path) : \n","    shutil.copyfile(nomal_train_path+file , dataset_path+'copy_images/trainset/'+file)\n","\n","for file in os.listdir(nomal_val_path) : \n","    shutil.copyfile(nomal_val_path+file , dataset_path+'copy_images/validset/'+file)\n","\n","for file in os.listdir(nomal_test_path) : \n","    shutil.copyfile(nomal_test_path+file , dataset_path+'copy_images/testset/'+file)"]},{"cell_type":"markdown","source":["* 데이터 갯수 조회"],"metadata":{"id":"xzEXHZrqkz88"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ugNprP9d-Gti","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679379974482,"user_tz":-540,"elapsed":10,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"12c9bbb1-599a-48e3-a7b0-da9f5a1a14e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["388\n","96\n","121\n"]}],"source":["print(len(os.listdir(dataset_path+'copy_images/trainset/')))\n","print(len(os.listdir(dataset_path+'copy_images/validset/')))\n","print(len(os.listdir(dataset_path+'copy_images/testset/')))"]},{"cell_type":"code","source":["print(len(os.listdir(tr_n_path)) + len(os.listdir(tr_ab_path)))\n","print(len(os.listdir(val_n_path)) + len(os.listdir(val_ab_path)))\n","print(len(os.listdir(te_n_path)) + len(os.listdir(te_ab_path)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fmo20zyJa0Wc","executionInfo":{"status":"ok","timestamp":1679379974482,"user_tz":-540,"elapsed":8,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"ea0a76b6-54d1-47c5-edc0-097d38d09f8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["388\n","96\n","121\n"]}]},{"cell_type":"markdown","metadata":{"id":"VfYDW1Pj7ZdU"},"source":["## 3.모델링 I\n","* **세부요구사항**\n","    * 모델링을 위한 데이터 구조 만들기\n","        * x : 이미지를 array로 변환합니다.\n","        * y : 이미지 갯수만큼 normal - 0, abnormal - 1 로 array를 만듭니다.\n","    * 모델을 최소 3개 이상 만들고 성능을 비교합니다.\n","        * 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n","        * 전처리 과정에서 생성한 Validation set을 적절하게 사용하세요.\n","        * Early Stopping을 반드시 사용하세요.\n","            * 최적의 가중치를 모델에 적용하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rg553KIvxE6W"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"markdown","metadata":{"id":"wIfqg6e0xE6A"},"source":["### (1) X : image to array\n","- **세부요구사항**\n","    * 모델링을 위해서는 np.array 형태로 데이터셋을 만들어야 합니다.\n","    * Training set / Validation set / Test set의 X는 이미지 형태로 되어있습니다. \n","    * 이미지 파일을 불러와 train, valid, test 각각 array 형태로 변환해 봅시다.\n","        * 각 폴더로 부터 이미지 목록을 만들고\n","        * 이미지 한장씩 적절한 크기로 로딩하여 (keras.utils.load_img)\n","            * 이미지가 너무 크면 학습시간이 많이 걸리고, 메모리 부족현상이 발생될 수 있습니다.\n","            * 이미지 크기를 280 * 280 * 3 이내의 크기를 설정하여 로딩하시오.\n","            * array로 변환 (keras.utils.img_to_array, np.expand_dims)\n","        * 데이터셋에 추가합니다.(데이터셋도 array)"]},{"cell_type":"markdown","source":["#### 1) 이미지 목록 만들기\n","* train, validation, test 폴더로 부터 이미지 목록을 생성합니다."],"metadata":{"id":"FovkIeSDT367"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"X022f0QMxE6W"},"outputs":[],"source":["# 이미지 목록 저장\n","img_train_list = os.listdir(dataset_path+'copy_images/trainset/')\n","img_valid_list = os.listdir(dataset_path+'copy_images/validset/')\n","img_test_list = os.listdir(dataset_path+'copy_images/testset/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgvW_LQfxE6X"},"outputs":[],"source":["# 메모리, 처리시간을 위해서 이미지 크기 조정\n","img_size = 227 ## 사이즈 조정 가능"]},{"cell_type":"code","source":["from keras.utils import load_img, img_to_array\n","\n","# x_train\n","x_train = []\n","train_path = dataset_path+'copy_images/trainset/'\n","for file in img_train_list :\n","    img_path = train_path + file\n","    img = load_img(img_path, target_size=(img_size, img_size))\n","    img_array = img_to_array(img)\n","    x_train.append(img_array)\n","x_train = np.array(x_train)\n","\n","# x_valid\n","x_valid = []\n","val_path = dataset_path+'copy_images/validset/'\n","for file in img_valid_list :\n","    img_path = val_path + file\n","    img = load_img(img_path, target_size=(img_size, img_size))\n","    img_array = img_to_array(img)\n","    x_valid.append(img_array)\n","x_valid = np.array(x_valid)\n","\n","# x_test\n","\n","x_test = []\n","test_path = dataset_path+'copy_images/testset/'\n","for file in img_test_list :\n","    img_path = test_path + file\n","    img = load_img(img_path, target_size=(img_size, img_size))\n","    img_array = img_to_array(img)\n","    x_test.append(img_array)\n","x_test = np.array(x_test)"],"metadata":{"id":"COSOP0mrb7lp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape, x_valid.shape, x_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxTJUv8g552u","executionInfo":{"status":"ok","timestamp":1679409292729,"user_tz":-540,"elapsed":477,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"7e38a348-1585-4af9-f293-96b31c987ad6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((388, 227, 227, 3), (96, 227, 227, 3), (121, 227, 227, 3))"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[],"metadata":{"id":"gb-xpliPm5ov"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2) 이미지들을 배열 데이터셋으로 만들기"],"metadata":{"id":"LSt88mjPV33u"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rhEdBiKfxE6Y"},"outputs":[],"source":["###############################################"]},{"cell_type":"markdown","metadata":{"id":"doUM37LxxE6Z"},"source":["### (2) y : 클래스 만들기\n","- **세부요구사항**\n","    - Training set / Validation set / Test set의 y를 생성합니다.\n","        - 각각 normal, abnormal 데이터의 갯수를 다시 확인하고\n","        - normal을 0, abnormal을 1로 지정합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nl1Uv9UxE6b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679379997907,"user_tz":-540,"elapsed":27,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"77c11597-a39a-4d0a-addb-4efa0b060619"},"outputs":[{"output_type":"stream","name":"stdout","text":["388\n","194\n","---\n","96\n","48\n","---\n","121\n","61\n"]}],"source":["# 데이터 갯수 확인\n","print( len(img_train_list) )\n","print( len([val for val in img_train_list if val.startswith('ab_')]) )\n","print('---')\n","print( len(img_valid_list) )\n","print( len([val for val in img_valid_list if val.startswith('ab_')]) )\n","print('---')\n","print( len(img_test_list) )\n","print( len([val for val in img_test_list if val.startswith('ab_')]) )"]},{"cell_type":"markdown","source":["* y_train, y_valid, y_test 만들기\n","    * normal, abnormal 데이터의 갯수를 다시 확인하고 normal을 0, abnormal을 1로 지정합니다."],"metadata":{"id":"HIfaCLlNn04C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVrPQdhTxE6b"},"outputs":[],"source":["y_train, y_valid, y_test = [0] * x_train.shape[0], [0] * x_valid.shape[0], [0] * x_test.shape[0]\n","\n","# y_train\n","for idx, file in enumerate(img_train_list):\n","    if file.startswith('ab_') : y_train[idx] = 1\n","y_train = np.array(y_train)\n","# y_valid\n","for idx, file in enumerate(img_valid_list):\n","    if file.startswith('ab_') : y_valid[idx] = 1\n","y_valid = np.array(y_valid)\n","# \n","for idx, file in enumerate(img_test_list):\n","    if file.startswith('ab_') : y_test[idx] = 1\n","y_test = np.array(y_test)"]},{"cell_type":"code","source":["x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-sk40XcG1Y_","executionInfo":{"status":"ok","timestamp":1679409307536,"user_tz":-540,"elapsed":2,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"2d1bf6b0-0885-4ad9-c535-ea170d6f4f44"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((388, 227, 227, 3),\n"," (388,),\n"," (96, 227, 227, 3),\n"," (96,),\n"," (121, 227, 227, 3),\n"," (121,))"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["print(y_valid)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7TXhRtbXNAGe","executionInfo":{"status":"ok","timestamp":1679380484218,"user_tz":-540,"elapsed":3,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"3033f580-42a8-4612-83f7-63a0e6825798"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"]}]},{"cell_type":"markdown","source":["## Min-Max Scaling"],"metadata":{"id":"SaJBCn0cKm77"}},{"cell_type":"code","source":["max_x = x_train.max() \n","min_x = x_train.min()\n","\n","x_train = (x_train - min_x)/(max_x - min_x)\n","x_valid = (x_valid - min_x)/(max_x - min_x)\n","x_test = (x_test - min_x)/(max_x - min_x)"],"metadata":{"id":"hRCw-Rf2KsYt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nK8nm95zyRKn","executionInfo":{"status":"ok","timestamp":1679384078130,"user_tz":-540,"elapsed":4,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"1d9be212-4ff8-4fcf-930d-d76a0df684e8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(388,)"]},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":[],"metadata":{"id":"8t-PzzIyuTAm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qRoacK2mcLPb"},"source":["### (3) 모델1 - AlexNet(Flatten())\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 validation_data로 validation set을 사용하시오.\n","    - 반드시 Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","\n","from keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization\n","\n","from sklearn.metrics import confusion_matrix, classification_report"],"metadata":{"id":"CF8E_nfVtueH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1) 구조 설계"],"metadata":{"id":"5WTwG8NFoLBQ"}},{"cell_type":"markdown","source":["![알뤡스](https://cdn-images-1.medium.com/max/1600/1*jqKHgwZ8alM3K_JRYO_l4w.png)"],"metadata":{"id":"cnbFEcB04KPB"}},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"DqTzgRTroLBR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lcVDXnpQoLBR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679380002147,"user_tz":-540,"elapsed":4259,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"e7d92cd3-d136-4266-a0de-579272298265"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 27, 27, 96)       384       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 27, 27, 512)       1229312   \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 13, 13, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 13, 13, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 13, 13, 768)       3539712   \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 13, 13, 768)       5309184   \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 13, 13, 512)       3539456   \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 6, 6, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," flatten (Flatten)           (None, 18432)             0         \n","                                                                 \n"," dense (Dense)               (None, 9216)              169878528 \n","                                                                 \n"," dense_1 (Dense)             (None, 4096)              37752832  \n","                                                                 \n"," dense_2 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," dropout (Dropout)           (None, 4096)              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 4097      \n","                                                                 \n","=================================================================\n","Total params: 238,073,857\n","Trainable params: 238,071,617\n","Non-trainable params: 2,240\n","_________________________________________________________________\n"]}],"source":["# 1. 세션 클리어\n","keras.backend.clear_session()\n","\n","# 2. 모델 사슬처럼 엮기\n","il = Input(shape = (227, 227, 3))\n","hl = Conv2D( filters = 96, kernel_size = (11, 11), strides = (4, 4), activation = 'relu')(il)\n","hl = MaxPool2D( pool_size = (3, 3), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 512, kernel_size = (5, 5), padding = 'same', activation = 'relu')(hl)\n","hl = MaxPool2D( pool_size = (3, 3), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 768, kernel_size = (3, 3), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 768, kernel_size = (3, 3), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), padding = 'same', activation = 'relu')(hl)\n","hl = MaxPool2D( pool_size = (3, 3), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Flatten()(hl)\n","\n","hl = Dense(9216, activation = 'relu')(hl)\n","hl = Dense(4096, activation = 'relu')(hl)\n","hl = Dense(4096, activation = 'relu')(hl)\n","\n","hl = Dropout(0.25)(hl)\n","\n","ol = Dense(1, activation = 'sigmoid')(hl)\n","\n","model_alexnet = keras.models.Model(il, ol)\n","\n","\n","#  4. 모델 컴파일\n","model_alexnet.compile(loss = 'binary_crossentropy', metrics = ['accuracy'],\n","              optimizer = 'adam')\n","# 모델 요약\n","model_alexnet.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UAhXnGmXoLBS"},"outputs":[],"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   verbose = 1,\n","                   patience = 15,\n","                   restore_best_weights = True\n","                   )\n","\n","mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Datasets/mcp_alexnet.h5',\n","                      monitor = 'val_loss',\n","                      verbose = 1,\n","                      save_best_only = True,\n","                      save_weights_only = False\n","                      )"]},{"cell_type":"code","source":["model_alexnet.fit(x_train, y_train, callbacks = [es, mcp], epochs = 1000, validation_data = (x_valid, y_valid), verbose = 1, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GE2PbYkj9FZQ","executionInfo":{"status":"ok","timestamp":1679380275860,"user_tz":-540,"elapsed":246222,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"dd5fb4a7-f211-4849-e1d6-8d4db4f57e33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","13/13 [==============================] - ETA: 0s - loss: 26.2202 - accuracy: 0.6160\n","Epoch 1: val_loss improved from inf to 108.48672, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet.h5\n","13/13 [==============================] - 58s 4s/step - loss: 26.2202 - accuracy: 0.6160 - val_loss: 108.4867 - val_accuracy: 0.5000\n","Epoch 2/1000\n","13/13 [==============================] - ETA: 0s - loss: 1.2327 - accuracy: 0.7165\n","Epoch 2: val_loss improved from 108.48672 to 13.93604, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet.h5\n","13/13 [==============================] - 15s 1s/step - loss: 1.2327 - accuracy: 0.7165 - val_loss: 13.9360 - val_accuracy: 0.5000\n","Epoch 3/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.9105 - accuracy: 0.7294\n","Epoch 3: val_loss improved from 13.93604 to 6.03990, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet.h5\n","13/13 [==============================] - 17s 1s/step - loss: 0.9105 - accuracy: 0.7294 - val_loss: 6.0399 - val_accuracy: 0.5000\n","Epoch 4/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.5679 - accuracy: 0.7912\n","Epoch 4: val_loss did not improve from 6.03990\n","13/13 [==============================] - 2s 124ms/step - loss: 0.5679 - accuracy: 0.7912 - val_loss: 7.5181 - val_accuracy: 0.5000\n","Epoch 5/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.8067\n","Epoch 5: val_loss improved from 6.03990 to 2.93917, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet.h5\n","13/13 [==============================] - 16s 1s/step - loss: 0.4638 - accuracy: 0.8067 - val_loss: 2.9392 - val_accuracy: 0.4896\n","Epoch 6/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4880 - accuracy: 0.8351\n","Epoch 6: val_loss improved from 2.93917 to 2.78631, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet.h5\n","13/13 [==============================] - 16s 1s/step - loss: 0.4880 - accuracy: 0.8351 - val_loss: 2.7863 - val_accuracy: 0.5312\n","Epoch 7/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.8170\n","Epoch 7: val_loss improved from 2.78631 to 1.35482, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet.h5\n","13/13 [==============================] - 16s 1s/step - loss: 0.4306 - accuracy: 0.8170 - val_loss: 1.3548 - val_accuracy: 0.5208\n","Epoch 8/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.8041\n","Epoch 8: val_loss improved from 1.35482 to 0.78201, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet.h5\n","13/13 [==============================] - 16s 1s/step - loss: 0.4279 - accuracy: 0.8041 - val_loss: 0.7820 - val_accuracy: 0.6667\n","Epoch 9/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.8325\n","Epoch 9: val_loss improved from 0.78201 to 0.55810, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet.h5\n","13/13 [==============================] - 16s 1s/step - loss: 0.4140 - accuracy: 0.8325 - val_loss: 0.5581 - val_accuracy: 0.7188\n","Epoch 10/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8582\n","Epoch 10: val_loss did not improve from 0.55810\n","13/13 [==============================] - 2s 126ms/step - loss: 0.3607 - accuracy: 0.8582 - val_loss: 0.8533 - val_accuracy: 0.6562\n","Epoch 11/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.8531\n","Epoch 11: val_loss did not improve from 0.55810\n","13/13 [==============================] - 2s 125ms/step - loss: 0.3344 - accuracy: 0.8531 - val_loss: 0.7987 - val_accuracy: 0.7917\n","Epoch 12/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4032 - accuracy: 0.8686\n","Epoch 12: val_loss did not improve from 0.55810\n","13/13 [==============================] - 2s 124ms/step - loss: 0.4032 - accuracy: 0.8686 - val_loss: 0.7322 - val_accuracy: 0.7604\n","Epoch 13/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.5421 - accuracy: 0.8196\n","Epoch 13: val_loss did not improve from 0.55810\n","13/13 [==============================] - 2s 124ms/step - loss: 0.5421 - accuracy: 0.8196 - val_loss: 0.8546 - val_accuracy: 0.8021\n","Epoch 14/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3988 - accuracy: 0.8531\n","Epoch 14: val_loss did not improve from 0.55810\n","13/13 [==============================] - 2s 125ms/step - loss: 0.3988 - accuracy: 0.8531 - val_loss: 0.8989 - val_accuracy: 0.6875\n","Epoch 15/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3783 - accuracy: 0.8608\n","Epoch 15: val_loss did not improve from 0.55810\n","13/13 [==============================] - 2s 125ms/step - loss: 0.3783 - accuracy: 0.8608 - val_loss: 1.3850 - val_accuracy: 0.7083\n","Epoch 16/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8763\n","Epoch 16: val_loss did not improve from 0.55810\n","13/13 [==============================] - 2s 126ms/step - loss: 0.2983 - accuracy: 0.8763 - val_loss: 1.0336 - val_accuracy: 0.6875\n","Epoch 17/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.8067\n","Epoch 17: val_loss improved from 0.55810 to 0.55534, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet.h5\n","13/13 [==============================] - 16s 1s/step - loss: 0.4471 - accuracy: 0.8067 - val_loss: 0.5553 - val_accuracy: 0.7917\n","Epoch 18/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.8479\n","Epoch 18: val_loss did not improve from 0.55534\n","13/13 [==============================] - 2s 126ms/step - loss: 0.3648 - accuracy: 0.8479 - val_loss: 1.1101 - val_accuracy: 0.6562\n","Epoch 19/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.8531\n","Epoch 19: val_loss did not improve from 0.55534\n","13/13 [==============================] - 2s 126ms/step - loss: 0.4386 - accuracy: 0.8531 - val_loss: 0.6539 - val_accuracy: 0.7083\n","Epoch 20/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.8814\n","Epoch 20: val_loss did not improve from 0.55534\n","13/13 [==============================] - 2s 126ms/step - loss: 0.2882 - accuracy: 0.8814 - val_loss: 0.6508 - val_accuracy: 0.8333\n","Epoch 21/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3431 - accuracy: 0.8686\n","Epoch 21: val_loss improved from 0.55534 to 0.49154, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet.h5\n","13/13 [==============================] - 16s 1s/step - loss: 0.3431 - accuracy: 0.8686 - val_loss: 0.4915 - val_accuracy: 0.8125\n","Epoch 22/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.8814\n","Epoch 22: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 128ms/step - loss: 0.2495 - accuracy: 0.8814 - val_loss: 0.7592 - val_accuracy: 0.7396\n","Epoch 23/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.8918\n","Epoch 23: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 126ms/step - loss: 0.2395 - accuracy: 0.8918 - val_loss: 0.8753 - val_accuracy: 0.8021\n","Epoch 24/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3164 - accuracy: 0.9021\n","Epoch 24: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 127ms/step - loss: 0.3164 - accuracy: 0.9021 - val_loss: 0.8060 - val_accuracy: 0.7708\n","Epoch 25/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.8814\n","Epoch 25: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 127ms/step - loss: 0.2421 - accuracy: 0.8814 - val_loss: 0.7478 - val_accuracy: 0.7604\n","Epoch 26/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.8840\n","Epoch 26: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 128ms/step - loss: 0.2821 - accuracy: 0.8840 - val_loss: 0.9462 - val_accuracy: 0.8125\n","Epoch 27/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9072\n","Epoch 27: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 128ms/step - loss: 0.2152 - accuracy: 0.9072 - val_loss: 1.5757 - val_accuracy: 0.7812\n","Epoch 28/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2059 - accuracy: 0.9124\n","Epoch 28: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 129ms/step - loss: 0.2059 - accuracy: 0.9124 - val_loss: 1.1719 - val_accuracy: 0.8125\n","Epoch 29/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9381\n","Epoch 29: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 129ms/step - loss: 0.1742 - accuracy: 0.9381 - val_loss: 1.3405 - val_accuracy: 0.8021\n","Epoch 30/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8454\n","Epoch 30: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 128ms/step - loss: 0.3843 - accuracy: 0.8454 - val_loss: 2.5020 - val_accuracy: 0.6771\n","Epoch 31/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.8634\n","Epoch 31: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 129ms/step - loss: 0.3712 - accuracy: 0.8634 - val_loss: 2.2527 - val_accuracy: 0.6875\n","Epoch 32/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2458 - accuracy: 0.8969\n","Epoch 32: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 132ms/step - loss: 0.2458 - accuracy: 0.8969 - val_loss: 1.3307 - val_accuracy: 0.7604\n","Epoch 33/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9175\n","Epoch 33: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 130ms/step - loss: 0.1759 - accuracy: 0.9175 - val_loss: 1.7352 - val_accuracy: 0.7812\n","Epoch 34/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.8918\n","Epoch 34: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 128ms/step - loss: 0.2548 - accuracy: 0.8918 - val_loss: 1.9554 - val_accuracy: 0.7500\n","Epoch 35/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2029 - accuracy: 0.8918\n","Epoch 35: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 130ms/step - loss: 0.2029 - accuracy: 0.8918 - val_loss: 1.2793 - val_accuracy: 0.7812\n","Epoch 36/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.8943Restoring model weights from the end of the best epoch: 21.\n","\n","Epoch 36: val_loss did not improve from 0.49154\n","13/13 [==============================] - 2s 198ms/step - loss: 0.2449 - accuracy: 0.8943 - val_loss: 1.1735 - val_accuracy: 0.7812\n","Epoch 36: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f99f461d130>"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["#### 3) test set으로 예측하고 평가하기\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"qxZ0U7K1oLBS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ShruikbsoLBS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679380294237,"user_tz":-540,"elapsed":1390,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"be9566d1-ea74-4c42-caf7-54c6c0b96ca1"},"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 276ms/step\n"]}],"source":["y_pred = model_alexnet.predict(x_test)\n","y_pred = np.where(y_pred>0.5,1,0)"]},{"cell_type":"code","source":["y_pred[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wNI3AUHE3irM","executionInfo":{"status":"ok","timestamp":1679380336759,"user_tz":-540,"elapsed":619,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"b6c0c62a-24f9-47a3-b4e1-9697bda4c138"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.5345403 ],\n","       [0.15227962],\n","       [0.9935301 ],\n","       [0.09741173],\n","       [0.31241253]], dtype=float32)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["y_test[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JddBYuvJ3nVC","executionInfo":{"status":"ok","timestamp":1679380357677,"user_tz":-540,"elapsed":559,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"4b258498-f796-4921-99d1-0375b1bc02fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, 1, 1])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["y_test.shape, y_pred.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCUJjcp15boX","executionInfo":{"status":"ok","timestamp":1679380834834,"user_tz":-540,"elapsed":4,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"38651d34-daa7-40d1-e33b-16754b5d18e2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((121,), (121, 1))"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["y_pred = np.where(y_pred>0.5,1,0)"],"metadata":{"id":"La3V9MWb7gty"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8MC8l07oLBS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679381389492,"user_tz":-540,"elapsed":19,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"31fa33af-093b-4127-97b4-a220c7ff100d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[54,  6],\n","       [21, 40]])"]},"metadata":{},"execution_count":53}],"source":["confusion_matrix(y_test, y_pred)"]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred))"],"metadata":{"id":"G7FVsFiCFSGa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679381393824,"user_tz":-540,"elapsed":6,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"32225950-84ec-4f3a-d552-e4889047f560"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.72      0.90      0.80        60\n","           1       0.87      0.66      0.75        61\n","\n","    accuracy                           0.78       121\n","   macro avg       0.79      0.78      0.77       121\n","weighted avg       0.80      0.78      0.77       121\n","\n"]}]},{"cell_type":"code","source":["x_train.shape, x_valid.shape, x_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VjCUXpLo9LZk","executionInfo":{"status":"ok","timestamp":1679381864934,"user_tz":-540,"elapsed":1395,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"f8ccc5a7-cfda-4a3b-d631-e53d7a7776b9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((388, 227, 227, 3), (96, 227, 227, 3), (121, 227, 227, 3))"]},"metadata":{},"execution_count":66}]},{"cell_type":"markdown","source":["### (4) 모델2 - AlexNet(GlobalAvgPool2D())\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 validation_data로 validation set을 사용하시오.\n","    - 반드시 Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."],"metadata":{"id":"02FHNlz1unqR"}},{"cell_type":"code","source":["# 1. 세션 클리어\n","keras.backend.clear_session()\n","\n","# 2. 모델 사슬처럼 엮기\n","il = Input(shape = (227, 227, 3))\n","hl = Conv2D( filters = 96, kernel_size = (11, 11), strides = (4, 4), activation = 'relu')(il)\n","hl = MaxPool2D( pool_size = (3, 3), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 512, kernel_size = (5, 5), padding = 'same', activation = 'relu')(hl)\n","hl = MaxPool2D( pool_size = (3, 3), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 768, kernel_size = (3, 3), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 768, kernel_size = (3, 3), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), padding = 'same', activation = 'relu')(hl)\n","hl = MaxPool2D( pool_size = (3, 3), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = keras.layers.GlobalAvgPool2D()(hl)\n","\n","hl = Dropout(0.25)(hl)\n","\n","ol = Dense(1, activation = 'sigmoid')(hl)\n","\n","model_alexnet_GlobalAvgPool = keras.models.Model(il, ol)\n","\n","\n","#  4. 모델 컴파일\n","model_alexnet_GlobalAvgPool.compile(loss = 'binary_crossentropy', metrics = ['accuracy'],\n","              optimizer = 'adam')\n","# 모델 요약\n","model_alexnet_GlobalAvgPool.summary()"],"metadata":{"id":"lV1MZbVAIox-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679381705896,"user_tz":-540,"elapsed":730,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"f205f932-3d6d-4c9d-df95-5cd3c896878a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 27, 27, 96)       384       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 27, 27, 512)       1229312   \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 13, 13, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 13, 13, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 13, 13, 768)       3539712   \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 13, 13, 768)       5309184   \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 13, 13, 512)       3539456   \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 6, 6, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 13,657,601\n","Trainable params: 13,655,361\n","Non-trainable params: 2,240\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   verbose = 1,\n","                   patience = 15,\n","                   restore_best_weights = True\n","                   )\n","\n","mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Datasets/mcp_alexnet_GlobalAvgPool.h5',\n","                      monitor = 'val_loss',\n","                      verbose = 1,\n","                      save_best_only = True,\n","                      save_weights_only = False\n","                      )"],"metadata":{"id":"VXVUK-q4venK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_alexnet_GlobalAvgPool.fit(x_train, y_train, callbacks = [es, mcp], epochs = 1000, validation_data = (x_valid, y_valid), verbose = 1, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K_AITadHvj8i","executionInfo":{"status":"ok","timestamp":1679381758024,"user_tz":-540,"elapsed":41265,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"d9fbef88-63af-4b78-a1d6-ff52e1e88d82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 1.3622 - accuracy: 0.7344\n","Epoch 1: val_loss improved from inf to 50.13318, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_GlobalAvgPool.h5\n","13/13 [==============================] - 7s 336ms/step - loss: 1.3485 - accuracy: 0.7371 - val_loss: 50.1332 - val_accuracy: 0.5000\n","Epoch 2/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.4782 - accuracy: 0.8333\n","Epoch 2: val_loss improved from 50.13318 to 12.69131, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_GlobalAvgPool.h5\n","13/13 [==============================] - 2s 126ms/step - loss: 0.4872 - accuracy: 0.8299 - val_loss: 12.6913 - val_accuracy: 0.5000\n","Epoch 3/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.3784 - accuracy: 0.8464\n","Epoch 3: val_loss improved from 12.69131 to 2.22830, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_GlobalAvgPool.h5\n","13/13 [==============================] - 2s 139ms/step - loss: 0.3791 - accuracy: 0.8454 - val_loss: 2.2283 - val_accuracy: 0.5000\n","Epoch 4/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.3371 - accuracy: 0.8594\n","Epoch 4: val_loss improved from 2.22830 to 1.18094, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_GlobalAvgPool.h5\n","13/13 [==============================] - 2s 123ms/step - loss: 0.3396 - accuracy: 0.8582 - val_loss: 1.1809 - val_accuracy: 0.5000\n","Epoch 5/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.3419 - accuracy: 0.8646\n","Epoch 5: val_loss improved from 1.18094 to 0.78309, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_GlobalAvgPool.h5\n","13/13 [==============================] - 2s 120ms/step - loss: 0.3420 - accuracy: 0.8634 - val_loss: 0.7831 - val_accuracy: 0.5208\n","Epoch 6/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.3347 - accuracy: 0.8646\n","Epoch 6: val_loss improved from 0.78309 to 0.72688, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_GlobalAvgPool.h5\n","13/13 [==============================] - 2s 175ms/step - loss: 0.3334 - accuracy: 0.8660 - val_loss: 0.7269 - val_accuracy: 0.5938\n","Epoch 7/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2928 - accuracy: 0.8932\n","Epoch 7: val_loss improved from 0.72688 to 0.54165, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_GlobalAvgPool.h5\n","13/13 [==============================] - 2s 127ms/step - loss: 0.2982 - accuracy: 0.8892 - val_loss: 0.5417 - val_accuracy: 0.6250\n","Epoch 8/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.3266 - accuracy: 0.8542\n","Epoch 8: val_loss did not improve from 0.54165\n","13/13 [==============================] - 1s 84ms/step - loss: 0.3244 - accuracy: 0.8557 - val_loss: 1.0918 - val_accuracy: 0.5208\n","Epoch 9/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2859 - accuracy: 0.8854\n","Epoch 9: val_loss improved from 0.54165 to 0.50694, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_GlobalAvgPool.h5\n","13/13 [==============================] - 2s 122ms/step - loss: 0.2917 - accuracy: 0.8840 - val_loss: 0.5069 - val_accuracy: 0.7292\n","Epoch 10/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2953 - accuracy: 0.8516\n","Epoch 10: val_loss did not improve from 0.50694\n","13/13 [==============================] - 1s 83ms/step - loss: 0.3020 - accuracy: 0.8505 - val_loss: 0.9409 - val_accuracy: 0.5625\n","Epoch 11/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.3202 - accuracy: 0.8672\n","Epoch 11: val_loss did not improve from 0.50694\n","13/13 [==============================] - 1s 83ms/step - loss: 0.3219 - accuracy: 0.8660 - val_loss: 0.8077 - val_accuracy: 0.6250\n","Epoch 12/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.3536 - accuracy: 0.8490\n","Epoch 12: val_loss improved from 0.50694 to 0.39339, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_GlobalAvgPool.h5\n","13/13 [==============================] - 2s 147ms/step - loss: 0.3508 - accuracy: 0.8505 - val_loss: 0.3934 - val_accuracy: 0.8229\n","Epoch 13/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.3215 - accuracy: 0.8490\n","Epoch 13: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 84ms/step - loss: 0.3260 - accuracy: 0.8454 - val_loss: 0.7233 - val_accuracy: 0.6458\n","Epoch 14/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.3265 - accuracy: 0.8464\n","Epoch 14: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 84ms/step - loss: 0.3236 - accuracy: 0.8479 - val_loss: 0.4903 - val_accuracy: 0.7396\n","Epoch 15/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2559 - accuracy: 0.9062\n","Epoch 15: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 83ms/step - loss: 0.2545 - accuracy: 0.9072 - val_loss: 0.4064 - val_accuracy: 0.8021\n","Epoch 16/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2592 - accuracy: 0.8932\n","Epoch 16: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 84ms/step - loss: 0.2592 - accuracy: 0.8943 - val_loss: 0.6100 - val_accuracy: 0.7188\n","Epoch 17/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2805 - accuracy: 0.8958\n","Epoch 17: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 85ms/step - loss: 0.2781 - accuracy: 0.8969 - val_loss: 0.6552 - val_accuracy: 0.7292\n","Epoch 18/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2169 - accuracy: 0.9271\n","Epoch 18: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 85ms/step - loss: 0.2338 - accuracy: 0.9227 - val_loss: 0.4833 - val_accuracy: 0.7708\n","Epoch 19/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2428 - accuracy: 0.8906\n","Epoch 19: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 84ms/step - loss: 0.2463 - accuracy: 0.8892 - val_loss: 0.6523 - val_accuracy: 0.7188\n","Epoch 20/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2803 - accuracy: 0.8880\n","Epoch 20: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 84ms/step - loss: 0.2808 - accuracy: 0.8866 - val_loss: 2.2963 - val_accuracy: 0.5000\n","Epoch 21/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2577 - accuracy: 0.8932\n","Epoch 21: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 89ms/step - loss: 0.2564 - accuracy: 0.8943 - val_loss: 1.3723 - val_accuracy: 0.6458\n","Epoch 22/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2372 - accuracy: 0.9141\n","Epoch 22: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 85ms/step - loss: 0.2382 - accuracy: 0.9124 - val_loss: 0.4705 - val_accuracy: 0.8021\n","Epoch 23/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2446 - accuracy: 0.9036\n","Epoch 23: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 84ms/step - loss: 0.2423 - accuracy: 0.9046 - val_loss: 0.5032 - val_accuracy: 0.8229\n","Epoch 24/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2021 - accuracy: 0.9297\n","Epoch 24: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 85ms/step - loss: 0.2030 - accuracy: 0.9304 - val_loss: 0.9994 - val_accuracy: 0.7396\n","Epoch 25/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.3205 - accuracy: 0.8776\n","Epoch 25: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 85ms/step - loss: 0.3207 - accuracy: 0.8763 - val_loss: 0.5781 - val_accuracy: 0.8021\n","Epoch 26/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2436 - accuracy: 0.9062\n","Epoch 26: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 84ms/step - loss: 0.2451 - accuracy: 0.9046 - val_loss: 0.4529 - val_accuracy: 0.7812\n","Epoch 27/1000\n","12/13 [==========================>...] - ETA: 0s - loss: 0.2096 - accuracy: 0.9167Restoring model weights from the end of the best epoch: 12.\n","\n","Epoch 27: val_loss did not improve from 0.39339\n","13/13 [==============================] - 1s 87ms/step - loss: 0.2175 - accuracy: 0.9098 - val_loss: 1.0829 - val_accuracy: 0.6979\n","Epoch 27: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f99bc17b160>"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["y_pred = model_alexnet_GlobalAvgPool.predict(x_test)\n","y_pred = np.where(y_pred>0.5,1,0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPWG0vo6v2CB","executionInfo":{"status":"ok","timestamp":1679381872786,"user_tz":-540,"elapsed":1098,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"79af6b77-331c-46f3-d736-4d6f04c3bae3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 38ms/step\n"]}]},{"cell_type":"code","source":["y_pred[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B85fhCZJxFAC","executionInfo":{"status":"ok","timestamp":1679381877758,"user_tz":-540,"elapsed":15,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"70120df0-cd7d-4699-805f-868760c60e82"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1],\n","       [1],\n","       [1],\n","       [0],\n","       [1]])"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["confusion_matrix(y_test, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edGtnEjYwIOE","executionInfo":{"status":"ok","timestamp":1679381882380,"user_tz":-540,"elapsed":854,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"3f06505a-53fc-4f60-8424-4895afeb9ef5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[41, 19],\n","       [ 5, 56]])"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CJTsEqCCwKc_","executionInfo":{"status":"ok","timestamp":1679381887119,"user_tz":-540,"elapsed":4,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"2b613916-5c91-4f29-d544-9ba637b3c742"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.89      0.68      0.77        60\n","           1       0.75      0.92      0.82        61\n","\n","    accuracy                           0.80       121\n","   macro avg       0.82      0.80      0.80       121\n","weighted avg       0.82      0.80      0.80       121\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"MRqzBw8eccwj"},"source":["### (5) 모델3 - VGG-16(D구조)"]},{"cell_type":"markdown","source":["![VGG-16(D구조)**굵은 텍스트**](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FK990l%2FbtqwDJ7C54R%2F664Ksm6gyTGBR1wK3YPDFk%2Fimg.png)"],"metadata":{"id":"LtNd8u5RoNJo"}},{"cell_type":"code","source":["# 1. 세션 클리어\n","keras.backend.clear_session()\n","\n","# 2. 모델 사슬처럼 엮기\n","il = Input(shape = (224, 224, 3))\n","hl = Conv2D( filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(il)\n","hl = Conv2D( filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Flatten()(hl)\n","\n","hl = Dense(4096, activation = 'relu')(hl)\n","hl = Dense(4096, activation = 'relu')(hl)\n","hl = Dense(1000, activation = 'relu')(hl)\n","\n","hl = Dropout(0.3)(hl)\n","\n","ol = Dense(1, activation = 'sigmoid')(hl)\n","\n","model_vgg_16_flatten = keras.models.Model(il, ol)\n","\n","\n","#  4. 모델 컴파일\n","model_vgg_16_flatten.compile(loss = 'binary_crossentropy', metrics = ['accuracy'],\n","              optimizer = 'adam')\n","# 모델 요약\n","model_vgg_16_flatten.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Haje0FArBQdw","executionInfo":{"status":"ok","timestamp":1679384714163,"user_tz":-540,"elapsed":835,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"b6cf9d70-066b-407f-b192-62d9d4d439fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 112, 112, 64)     256       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 56, 56, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 28, 28, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 14, 14, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 7, 7, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," dense (Dense)               (None, 4096)              102764544 \n","                                                                 \n"," dense_1 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," dense_2 (Dense)             (None, 1000)              4097000   \n","                                                                 \n"," dropout (Dropout)           (None, 1000)              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 1001      \n","                                                                 \n","=================================================================\n","Total params: 138,364,433\n","Trainable params: 138,361,489\n","Non-trainable params: 2,944\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   verbose = 1,\n","                   patience = 15,\n","                   restore_best_weights = True\n","                   )\n","\n","mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Datasets/mcp_vgg_16_flatten.h5',\n","                      monitor = 'val_loss',\n","                      verbose = 1,\n","                      save_best_only = True,\n","                      save_weights_only = False\n","                      )"],"metadata":{"id":"dWWU3rVLBuOM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_vgg_16_flatten.fit(x_train, y_train, callbacks = [es, mcp], epochs = 1000, validation_data = (x_valid, y_valid), verbose = 1, batch_size = 16)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYleamGzBytK","executionInfo":{"status":"ok","timestamp":1679385041483,"user_tz":-540,"elapsed":319550,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"79af60a4-56ea-487d-9506-bbd86dc0acb1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","25/25 [==============================] - ETA: 0s - loss: 4.2534 - accuracy: 0.6546\n","Epoch 1: val_loss improved from inf to 6.54315, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_16_flatten.h5\n","25/25 [==============================] - 28s 900ms/step - loss: 4.2534 - accuracy: 0.6546 - val_loss: 6.5431 - val_accuracy: 0.5000\n","Epoch 2/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.5587 - accuracy: 0.7577\n","Epoch 2: val_loss improved from 6.54315 to 2.96899, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_16_flatten.h5\n","25/25 [==============================] - 14s 579ms/step - loss: 0.5587 - accuracy: 0.7577 - val_loss: 2.9690 - val_accuracy: 0.5208\n","Epoch 3/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.7809\n","Epoch 3: val_loss did not improve from 2.96899\n","25/25 [==============================] - 6s 249ms/step - loss: 0.5114 - accuracy: 0.7809 - val_loss: 3.9956 - val_accuracy: 0.5000\n","Epoch 4/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.8273\n","Epoch 4: val_loss did not improve from 2.96899\n","25/25 [==============================] - 6s 252ms/step - loss: 0.4936 - accuracy: 0.8273 - val_loss: 3.5491 - val_accuracy: 0.5000\n","Epoch 5/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4253 - accuracy: 0.8557\n","Epoch 5: val_loss did not improve from 2.96899\n","25/25 [==============================] - 6s 255ms/step - loss: 0.4253 - accuracy: 0.8557 - val_loss: 3.8447 - val_accuracy: 0.5000\n","Epoch 6/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4680 - accuracy: 0.8170\n","Epoch 6: val_loss did not improve from 2.96899\n","25/25 [==============================] - 6s 257ms/step - loss: 0.4680 - accuracy: 0.8170 - val_loss: 4.4481 - val_accuracy: 0.5000\n","Epoch 7/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.8351\n","Epoch 7: val_loss did not improve from 2.96899\n","25/25 [==============================] - 6s 255ms/step - loss: 0.4071 - accuracy: 0.8351 - val_loss: 6.7445 - val_accuracy: 0.5000\n","Epoch 8/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8737\n","Epoch 8: val_loss did not improve from 2.96899\n","25/25 [==============================] - 6s 253ms/step - loss: 0.3434 - accuracy: 0.8737 - val_loss: 12.1694 - val_accuracy: 0.5000\n","Epoch 9/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.5179 - accuracy: 0.7861\n","Epoch 9: val_loss did not improve from 2.96899\n","25/25 [==============================] - 6s 251ms/step - loss: 0.5179 - accuracy: 0.7861 - val_loss: 3.4606 - val_accuracy: 0.5000\n","Epoch 10/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.8582\n","Epoch 10: val_loss did not improve from 2.96899\n","25/25 [==============================] - 6s 248ms/step - loss: 0.3891 - accuracy: 0.8582 - val_loss: 4.6210 - val_accuracy: 0.5000\n","Epoch 11/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.8119\n","Epoch 11: val_loss improved from 2.96899 to 1.82889, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_16_flatten.h5\n","25/25 [==============================] - 14s 553ms/step - loss: 0.4436 - accuracy: 0.8119 - val_loss: 1.8289 - val_accuracy: 0.5208\n","Epoch 12/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3624 - accuracy: 0.8582\n","Epoch 12: val_loss did not improve from 1.82889\n","25/25 [==============================] - 6s 243ms/step - loss: 0.3624 - accuracy: 0.8582 - val_loss: 4.7379 - val_accuracy: 0.5521\n","Epoch 13/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.8273\n","Epoch 13: val_loss improved from 1.82889 to 1.30569, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_16_flatten.h5\n","25/25 [==============================] - 14s 577ms/step - loss: 0.4053 - accuracy: 0.8273 - val_loss: 1.3057 - val_accuracy: 0.6458\n","Epoch 14/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4064 - accuracy: 0.8299\n","Epoch 14: val_loss improved from 1.30569 to 1.28015, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_16_flatten.h5\n","25/25 [==============================] - 14s 554ms/step - loss: 0.4064 - accuracy: 0.8299 - val_loss: 1.2801 - val_accuracy: 0.7708\n","Epoch 15/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.8711\n","Epoch 15: val_loss improved from 1.28015 to 0.62445, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_16_flatten.h5\n","25/25 [==============================] - 15s 606ms/step - loss: 0.3408 - accuracy: 0.8711 - val_loss: 0.6245 - val_accuracy: 0.6250\n","Epoch 16/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.8660\n","Epoch 16: val_loss did not improve from 0.62445\n","25/25 [==============================] - 6s 250ms/step - loss: 0.3331 - accuracy: 0.8660 - val_loss: 0.7017 - val_accuracy: 0.8438\n","Epoch 17/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2735 - accuracy: 0.8892\n","Epoch 17: val_loss did not improve from 0.62445\n","25/25 [==============================] - 6s 255ms/step - loss: 0.2735 - accuracy: 0.8892 - val_loss: 1.8331 - val_accuracy: 0.7188\n","Epoch 18/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2739 - accuracy: 0.8969\n","Epoch 18: val_loss did not improve from 0.62445\n","25/25 [==============================] - 6s 257ms/step - loss: 0.2739 - accuracy: 0.8969 - val_loss: 0.8583 - val_accuracy: 0.7812\n","Epoch 19/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4238 - accuracy: 0.8325\n","Epoch 19: val_loss did not improve from 0.62445\n","25/25 [==============================] - 6s 256ms/step - loss: 0.4238 - accuracy: 0.8325 - val_loss: 0.8040 - val_accuracy: 0.7396\n","Epoch 20/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3323 - accuracy: 0.8866\n","Epoch 20: val_loss did not improve from 0.62445\n","25/25 [==============================] - 6s 254ms/step - loss: 0.3323 - accuracy: 0.8866 - val_loss: 1.0812 - val_accuracy: 0.6146\n","Epoch 21/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3310 - accuracy: 0.8814\n","Epoch 21: val_loss did not improve from 0.62445\n","25/25 [==============================] - 6s 251ms/step - loss: 0.3310 - accuracy: 0.8814 - val_loss: 0.8777 - val_accuracy: 0.7812\n","Epoch 22/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.9046\n","Epoch 22: val_loss did not improve from 0.62445\n","25/25 [==============================] - 6s 248ms/step - loss: 0.2900 - accuracy: 0.9046 - val_loss: 0.9458 - val_accuracy: 0.7188\n","Epoch 23/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2535 - accuracy: 0.9046\n","Epoch 23: val_loss did not improve from 0.62445\n","25/25 [==============================] - 6s 247ms/step - loss: 0.2535 - accuracy: 0.9046 - val_loss: 0.8787 - val_accuracy: 0.7812\n","Epoch 24/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2908 - accuracy: 0.9072\n","Epoch 24: val_loss improved from 0.62445 to 0.48066, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_16_flatten.h5\n","25/25 [==============================] - 21s 870ms/step - loss: 0.2908 - accuracy: 0.9072 - val_loss: 0.4807 - val_accuracy: 0.8333\n","Epoch 25/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.1866 - accuracy: 0.9253\n","Epoch 25: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 241ms/step - loss: 0.1866 - accuracy: 0.9253 - val_loss: 1.4100 - val_accuracy: 0.8125\n","Epoch 26/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.8866\n","Epoch 26: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 244ms/step - loss: 0.3328 - accuracy: 0.8866 - val_loss: 0.8414 - val_accuracy: 0.5104\n","Epoch 27/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.9253\n","Epoch 27: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 247ms/step - loss: 0.2186 - accuracy: 0.9253 - val_loss: 1.5481 - val_accuracy: 0.6354\n","Epoch 28/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9588\n","Epoch 28: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 250ms/step - loss: 0.1772 - accuracy: 0.9588 - val_loss: 2.1025 - val_accuracy: 0.6250\n","Epoch 29/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2700 - accuracy: 0.9072\n","Epoch 29: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 253ms/step - loss: 0.2700 - accuracy: 0.9072 - val_loss: 1.7025 - val_accuracy: 0.6667\n","Epoch 30/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2491 - accuracy: 0.9046\n","Epoch 30: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 256ms/step - loss: 0.2491 - accuracy: 0.9046 - val_loss: 1.2037 - val_accuracy: 0.7292\n","Epoch 31/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9072\n","Epoch 31: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 256ms/step - loss: 0.2362 - accuracy: 0.9072 - val_loss: 9.8409 - val_accuracy: 0.5000\n","Epoch 32/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.9381\n","Epoch 32: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 255ms/step - loss: 0.1970 - accuracy: 0.9381 - val_loss: 1.7311 - val_accuracy: 0.5417\n","Epoch 33/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9536\n","Epoch 33: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 251ms/step - loss: 0.1400 - accuracy: 0.9536 - val_loss: 2.1059 - val_accuracy: 0.7812\n","Epoch 34/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9536\n","Epoch 34: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 249ms/step - loss: 0.1193 - accuracy: 0.9536 - val_loss: 1.0572 - val_accuracy: 0.7500\n","Epoch 35/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.9381\n","Epoch 35: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 248ms/step - loss: 0.2662 - accuracy: 0.9381 - val_loss: 3.7524 - val_accuracy: 0.6042\n","Epoch 36/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.1635 - accuracy: 0.9433\n","Epoch 36: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 247ms/step - loss: 0.1635 - accuracy: 0.9433 - val_loss: 5.4224 - val_accuracy: 0.5521\n","Epoch 37/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.9304\n","Epoch 37: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 246ms/step - loss: 0.3941 - accuracy: 0.9304 - val_loss: 11.7719 - val_accuracy: 0.5417\n","Epoch 38/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.9433\n","Epoch 38: val_loss did not improve from 0.48066\n","25/25 [==============================] - 6s 246ms/step - loss: 0.1863 - accuracy: 0.9433 - val_loss: 19.6931 - val_accuracy: 0.5521\n","Epoch 39/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.8763Restoring model weights from the end of the best epoch: 24.\n","\n","Epoch 39: val_loss did not improve from 0.48066\n","25/25 [==============================] - 7s 267ms/step - loss: 0.3334 - accuracy: 0.8763 - val_loss: 9.2188 - val_accuracy: 0.5312\n","Epoch 39: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f99e067ef70>"]},"metadata":{},"execution_count":130}]},{"cell_type":"code","source":["y_pred = model_vgg_16.predict(x_test)\n","y_pred = np.where(y_pred>0.5,1,0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vF6qAXeZB4v-","executionInfo":{"status":"ok","timestamp":1679385054175,"user_tz":-540,"elapsed":1045,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"09a35b4b-630a-4e00-d4e1-8bedc3666771"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 144ms/step\n"]}]},{"cell_type":"code","source":["confusion_matrix(y_test, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKrPLAFrB74k","executionInfo":{"status":"ok","timestamp":1679385058275,"user_tz":-540,"elapsed":4,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"85e331f6-effb-461c-db60-732764547f32"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[48, 12],\n","       [ 8, 53]])"]},"metadata":{},"execution_count":132}]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNoFC6YKB-B-","executionInfo":{"status":"ok","timestamp":1679385060201,"user_tz":-540,"elapsed":5,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"925a9a4d-6e5a-4151-df19-2f642b1e622c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.86      0.80      0.83        60\n","           1       0.82      0.87      0.84        61\n","\n","    accuracy                           0.83       121\n","   macro avg       0.84      0.83      0.83       121\n","weighted avg       0.84      0.83      0.83       121\n","\n"]}]},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"4zgVkXLHoNJo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTlUNbkhoNJo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679384296238,"user_tz":-540,"elapsed":1853,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"ffcba738-3179-41e5-8e69-bfdb30b7eddf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 112, 112, 64)     256       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 56, 56, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 28, 28, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 14, 14, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 7, 7, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 14,721,089\n","Trainable params: 14,718,145\n","Non-trainable params: 2,944\n","_________________________________________________________________\n"]}],"source":["# 1. 세션 클리어\n","keras.backend.clear_session()\n","\n","# 2. 모델 사슬처럼 엮기\n","il = Input(shape = (224, 224, 3))\n","hl = Conv2D( filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(il)\n","hl = Conv2D( filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = keras.layers.GlobalAvgPool2D()(hl)\n","\n","hl = Dropout(0.3)(hl)\n","\n","ol = Dense(1, activation = 'sigmoid')(hl)\n","\n","model_vgg_16 = keras.models.Model(il, ol)\n","\n","\n","#  4. 모델 컴파일\n","model_vgg_16.compile(loss = 'binary_crossentropy', metrics = ['accuracy'],\n","              optimizer = 'adam')\n","# 모델 요약\n","model_vgg_16.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4GYo0dboNJo"},"outputs":[],"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   verbose = 1,\n","                   patience = 15,\n","                   restore_best_weights = True\n","                   )\n","\n","mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Datasets/mcp_vgg_16.h5',\n","                      monitor = 'val_loss',\n","                      verbose = 1,\n","                      save_best_only = True,\n","                      save_weights_only = False\n","                      )"]},{"cell_type":"code","source":["model_vgg_16.fit(x_train, y_train, callbacks = [es, mcp], epochs = 1000, validation_data = (x_valid, y_valid), verbose = 1, batch_size = 16)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J1vjmSiTdmmG","executionInfo":{"status":"ok","timestamp":1679384563069,"user_tz":-540,"elapsed":259999,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"b518c9cd-1c17-4961-8fb4-8f293c55a3a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.6705 - accuracy: 0.7629\n","Epoch 1: val_loss did not improve from 0.56092\n","25/25 [==============================] - 15s 242ms/step - loss: 0.6705 - accuracy: 0.7629 - val_loss: 3.1715 - val_accuracy: 0.4792\n","Epoch 2/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4631 - accuracy: 0.7912\n","Epoch 2: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 228ms/step - loss: 0.4631 - accuracy: 0.7912 - val_loss: 2.0001 - val_accuracy: 0.5104\n","Epoch 3/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4462 - accuracy: 0.7887\n","Epoch 3: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 229ms/step - loss: 0.4462 - accuracy: 0.7887 - val_loss: 1.6753 - val_accuracy: 0.5000\n","Epoch 4/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.8247\n","Epoch 4: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 231ms/step - loss: 0.4170 - accuracy: 0.8247 - val_loss: 2.4634 - val_accuracy: 0.5000\n","Epoch 5/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4102 - accuracy: 0.8454\n","Epoch 5: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 234ms/step - loss: 0.4102 - accuracy: 0.8454 - val_loss: 2.5659 - val_accuracy: 0.5000\n","Epoch 6/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.8402\n","Epoch 6: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 234ms/step - loss: 0.4020 - accuracy: 0.8402 - val_loss: 1.4642 - val_accuracy: 0.5000\n","Epoch 7/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4193 - accuracy: 0.8170\n","Epoch 7: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 230ms/step - loss: 0.4193 - accuracy: 0.8170 - val_loss: 2.5261 - val_accuracy: 0.5000\n","Epoch 8/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8325\n","Epoch 8: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 230ms/step - loss: 0.3952 - accuracy: 0.8325 - val_loss: 1.3282 - val_accuracy: 0.5000\n","Epoch 9/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.8402\n","Epoch 9: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 226ms/step - loss: 0.3211 - accuracy: 0.8402 - val_loss: 2.1023 - val_accuracy: 0.5000\n","Epoch 10/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.4312 - accuracy: 0.8299\n","Epoch 10: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 227ms/step - loss: 0.4312 - accuracy: 0.8299 - val_loss: 0.7330 - val_accuracy: 0.6562\n","Epoch 11/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8402\n","Epoch 11: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 225ms/step - loss: 0.3821 - accuracy: 0.8402 - val_loss: 0.9907 - val_accuracy: 0.7083\n","Epoch 12/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.8557\n","Epoch 12: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 224ms/step - loss: 0.3566 - accuracy: 0.8557 - val_loss: 1.2104 - val_accuracy: 0.5938\n","Epoch 13/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.8093\n","Epoch 13: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 224ms/step - loss: 0.3655 - accuracy: 0.8093 - val_loss: 0.8688 - val_accuracy: 0.6458\n","Epoch 14/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.8557\n","Epoch 14: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 224ms/step - loss: 0.3482 - accuracy: 0.8557 - val_loss: 1.0262 - val_accuracy: 0.5104\n","Epoch 15/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3542 - accuracy: 0.8531\n","Epoch 15: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 225ms/step - loss: 0.3542 - accuracy: 0.8531 - val_loss: 0.6663 - val_accuracy: 0.6875\n","Epoch 16/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3280 - accuracy: 0.8531\n","Epoch 16: val_loss did not improve from 0.56092\n","25/25 [==============================] - 6s 224ms/step - loss: 0.3280 - accuracy: 0.8531 - val_loss: 0.7319 - val_accuracy: 0.6875\n","Epoch 17/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.8582\n","Epoch 17: val_loss improved from 0.56092 to 0.41356, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_16.h5\n","25/25 [==============================] - 8s 315ms/step - loss: 0.3006 - accuracy: 0.8582 - val_loss: 0.4136 - val_accuracy: 0.7917\n","Epoch 18/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.8866\n","Epoch 18: val_loss did not improve from 0.41356\n","25/25 [==============================] - 6s 226ms/step - loss: 0.3032 - accuracy: 0.8866 - val_loss: 0.5331 - val_accuracy: 0.8125\n","Epoch 19/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.8531\n","Epoch 19: val_loss did not improve from 0.41356\n","25/25 [==============================] - 6s 227ms/step - loss: 0.3077 - accuracy: 0.8531 - val_loss: 2.1123 - val_accuracy: 0.5000\n","Epoch 20/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3041 - accuracy: 0.8737\n","Epoch 20: val_loss did not improve from 0.41356\n","25/25 [==============================] - 6s 228ms/step - loss: 0.3041 - accuracy: 0.8737 - val_loss: 0.6842 - val_accuracy: 0.8333\n","Epoch 21/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2967 - accuracy: 0.8763\n","Epoch 21: val_loss did not improve from 0.41356\n","25/25 [==============================] - 6s 228ms/step - loss: 0.2967 - accuracy: 0.8763 - val_loss: 0.5139 - val_accuracy: 0.7708\n","Epoch 22/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.8840\n","Epoch 22: val_loss did not improve from 0.41356\n","25/25 [==============================] - 6s 229ms/step - loss: 0.2640 - accuracy: 0.8840 - val_loss: 1.2505 - val_accuracy: 0.7188\n","Epoch 23/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.9175\n","Epoch 23: val_loss improved from 0.41356 to 0.38846, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_16.h5\n","25/25 [==============================] - 8s 310ms/step - loss: 0.2142 - accuracy: 0.9175 - val_loss: 0.3885 - val_accuracy: 0.8333\n","Epoch 24/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.8892\n","Epoch 24: val_loss did not improve from 0.38846\n","25/25 [==============================] - 6s 226ms/step - loss: 0.2334 - accuracy: 0.8892 - val_loss: 1.9036 - val_accuracy: 0.5521\n","Epoch 25/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.8789\n","Epoch 25: val_loss did not improve from 0.38846\n","25/25 [==============================] - 6s 225ms/step - loss: 0.2783 - accuracy: 0.8789 - val_loss: 0.5799 - val_accuracy: 0.7604\n","Epoch 26/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2672 - accuracy: 0.8763\n","Epoch 26: val_loss did not improve from 0.38846\n","25/25 [==============================] - 6s 225ms/step - loss: 0.2672 - accuracy: 0.8763 - val_loss: 2.7286 - val_accuracy: 0.5312\n","Epoch 27/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.9046\n","Epoch 27: val_loss did not improve from 0.38846\n","25/25 [==============================] - 6s 225ms/step - loss: 0.2465 - accuracy: 0.9046 - val_loss: 0.4295 - val_accuracy: 0.8542\n","Epoch 28/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.9021\n","Epoch 28: val_loss improved from 0.38846 to 0.30311, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_16.h5\n","25/25 [==============================] - 8s 314ms/step - loss: 0.2054 - accuracy: 0.9021 - val_loss: 0.3031 - val_accuracy: 0.8750\n","Epoch 29/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.8840\n","Epoch 29: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 224ms/step - loss: 0.2395 - accuracy: 0.8840 - val_loss: 1.4634 - val_accuracy: 0.7604\n","Epoch 30/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.8660\n","Epoch 30: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 225ms/step - loss: 0.3311 - accuracy: 0.8660 - val_loss: 0.8343 - val_accuracy: 0.7604\n","Epoch 31/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.9227\n","Epoch 31: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 227ms/step - loss: 0.2244 - accuracy: 0.9227 - val_loss: 0.6569 - val_accuracy: 0.7083\n","Epoch 32/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2004 - accuracy: 0.9098\n","Epoch 32: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 227ms/step - loss: 0.2004 - accuracy: 0.9098 - val_loss: 0.8844 - val_accuracy: 0.7917\n","Epoch 33/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.9021\n","Epoch 33: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 227ms/step - loss: 0.2609 - accuracy: 0.9021 - val_loss: 6.1546 - val_accuracy: 0.5000\n","Epoch 34/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2735 - accuracy: 0.8840\n","Epoch 34: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 227ms/step - loss: 0.2735 - accuracy: 0.8840 - val_loss: 1.5826 - val_accuracy: 0.5729\n","Epoch 35/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9046\n","Epoch 35: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 227ms/step - loss: 0.1999 - accuracy: 0.9046 - val_loss: 1.2212 - val_accuracy: 0.6354\n","Epoch 36/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.8892\n","Epoch 36: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 227ms/step - loss: 0.2602 - accuracy: 0.8892 - val_loss: 2.2185 - val_accuracy: 0.5208\n","Epoch 37/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.1918 - accuracy: 0.9330\n","Epoch 37: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 227ms/step - loss: 0.1918 - accuracy: 0.9330 - val_loss: 0.8430 - val_accuracy: 0.7604\n","Epoch 38/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.9253\n","Epoch 38: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 226ms/step - loss: 0.1771 - accuracy: 0.9253 - val_loss: 0.6835 - val_accuracy: 0.7812\n","Epoch 39/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2042 - accuracy: 0.9098\n","Epoch 39: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 226ms/step - loss: 0.2042 - accuracy: 0.9098 - val_loss: 1.3136 - val_accuracy: 0.6875\n","Epoch 40/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2251 - accuracy: 0.9072\n","Epoch 40: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 226ms/step - loss: 0.2251 - accuracy: 0.9072 - val_loss: 0.9659 - val_accuracy: 0.7812\n","Epoch 41/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.8866\n","Epoch 41: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 226ms/step - loss: 0.2740 - accuracy: 0.8866 - val_loss: 0.8776 - val_accuracy: 0.7812\n","Epoch 42/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 0.9433\n","Epoch 42: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 226ms/step - loss: 0.1474 - accuracy: 0.9433 - val_loss: 0.6107 - val_accuracy: 0.8333\n","Epoch 43/1000\n","25/25 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9639Restoring model weights from the end of the best epoch: 28.\n","\n","Epoch 43: val_loss did not improve from 0.30311\n","25/25 [==============================] - 6s 227ms/step - loss: 0.1037 - accuracy: 0.9639 - val_loss: 0.3375 - val_accuracy: 0.8750\n","Epoch 43: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f99e0fdb430>"]},"metadata":{},"execution_count":123}]},{"cell_type":"markdown","source":["#### 3) test set으로 예측하고 평가하기\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"uZV9zbsroNJo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sc9UmjZ0oNJo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679384577224,"user_tz":-540,"elapsed":1248,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"ee27d7c1-c92b-416a-d03f-0d392eff0d5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 133ms/step\n"]}],"source":["y_pred = model_vgg_16.predict(x_test)\n","y_pred = np.where(y_pred>0.5,1,0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aP-p0_y9oNJo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679384578543,"user_tz":-540,"elapsed":3,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"4441e70b-78c4-4156-a691-562c1d3d6420"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[48, 12],\n","       [ 8, 53]])"]},"metadata":{},"execution_count":125}],"source":["confusion_matrix(y_test, y_pred)"]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Si6XbIxfNXn","executionInfo":{"status":"ok","timestamp":1679384581940,"user_tz":-540,"elapsed":3,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"8c170822-21d8-4619-f424-112c4e66f95b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.86      0.80      0.83        60\n","           1       0.82      0.87      0.84        61\n","\n","    accuracy                           0.83       121\n","   macro avg       0.84      0.83      0.83       121\n","weighted avg       0.84      0.83      0.83       121\n","\n"]}]},{"cell_type":"markdown","source":["### (6) 모델4 - VGG-19(E구조)\n","![VGG-19](https://wikidocs.net/images/page/164796/vgg_Fig_07.jpeg)"],"metadata":{"id":"Yx4sNJxwiRWk"}},{"cell_type":"code","source":[],"metadata":{"id":"IyN5oIEmitZ2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"g5RfrkXuiths"}},{"cell_type":"code","source":["# 1. 세션 클리어\n","keras.backend.clear_session()\n","\n","# 2. 모델 사슬처럼 엮기\n","il = Input(shape = (224, 224, 3))\n","hl = Conv2D( filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(il)\n","hl = Conv2D( filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D( filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","\n","hl = MaxPool2D( pool_size = (2, 2), strides = (2, 2))(hl)\n","hl = BatchNormalization()(hl)\n","\n","hl = keras.layers.GlobalAvgPool2D()(hl)\n","\n","hl = Dropout(0.25)(hl)\n","\n","ol = Dense(1, activation = 'sigmoid')(hl)\n","\n","model_vgg_19 = keras.models.Model(il, ol)\n","\n","\n","#  4. 모델 컴파일\n","model_vgg_19.compile(loss = 'binary_crossentropy', metrics = ['accuracy'],\n","              optimizer = 'adam')\n","# 모델 요약\n","model_vgg_19.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3uGeOK1GiucG","executionInfo":{"status":"ok","timestamp":1679382327201,"user_tz":-540,"elapsed":608,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"1d0a2bc3-a3ae-47e6-aa37-73935a97e9be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 112, 112, 64)     256       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 56, 56, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 56, 56, 256)       590080    \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 28, 28, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 28, 28, 512)       1180160   \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 28, 28, 512)       2359808   \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 28, 28, 512)       2359808   \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 14, 14, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," conv2d_13 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," conv2d_14 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," conv2d_15 (Conv2D)          (None, 14, 14, 512)       2359808   \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 7, 7, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 20,030,785\n","Trainable params: 20,027,841\n","Non-trainable params: 2,944\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   verbose = 1,\n","                   patience = 15,\n","                   restore_best_weights = True\n","                   )\n","\n","mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Datasets/mcp_vgg_19.h5',\n","                      monitor = 'val_loss',\n","                      verbose = 1,\n","                      save_best_only = True,\n","                      save_weights_only = False\n","                      )"],"metadata":{"id":"xmkzCRFWkG9S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_vgg_19.fit(x_train, y_train, callbacks = [es, mcp], epochs = 1000, validation_data = (x_valid, y_valid), verbose = 1, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T81okNkckNN6","executionInfo":{"status":"ok","timestamp":1679382690226,"user_tz":-540,"elapsed":343192,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"ebcbfb87-7e03-4678-9c3f-1a2362841632"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.5759 - accuracy: 0.7397\n","Epoch 1: val_loss improved from inf to 17.42811, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_19.h5\n","13/13 [==============================] - 31s 2s/step - loss: 0.5759 - accuracy: 0.7397 - val_loss: 17.4281 - val_accuracy: 0.4896\n","Epoch 2/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4726 - accuracy: 0.7732\n","Epoch 2: val_loss improved from 17.42811 to 14.76010, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_19.h5\n","13/13 [==============================] - 7s 566ms/step - loss: 0.4726 - accuracy: 0.7732 - val_loss: 14.7601 - val_accuracy: 0.5000\n","Epoch 3/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.8299\n","Epoch 3: val_loss improved from 14.76010 to 13.60373, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_19.h5\n","13/13 [==============================] - 7s 575ms/step - loss: 0.4279 - accuracy: 0.8299 - val_loss: 13.6037 - val_accuracy: 0.5000\n","Epoch 4/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8299\n","Epoch 4: val_loss improved from 13.60373 to 1.51806, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_19.h5\n","13/13 [==============================] - 8s 584ms/step - loss: 0.3869 - accuracy: 0.8299 - val_loss: 1.5181 - val_accuracy: 0.4583\n","Epoch 5/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8428\n","Epoch 5: val_loss did not improve from 1.51806\n","13/13 [==============================] - 7s 534ms/step - loss: 0.3792 - accuracy: 0.8428 - val_loss: 3.7506 - val_accuracy: 0.5000\n","Epoch 6/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8376\n","Epoch 6: val_loss did not improve from 1.51806\n","13/13 [==============================] - 7s 532ms/step - loss: 0.3832 - accuracy: 0.8376 - val_loss: 5.1747 - val_accuracy: 0.5000\n","Epoch 7/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8454\n","Epoch 7: val_loss did not improve from 1.51806\n","13/13 [==============================] - 7s 520ms/step - loss: 0.3942 - accuracy: 0.8454 - val_loss: 2.9418 - val_accuracy: 0.5000\n","Epoch 8/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.8144\n","Epoch 8: val_loss did not improve from 1.51806\n","13/13 [==============================] - 7s 517ms/step - loss: 0.3894 - accuracy: 0.8144 - val_loss: 2.2054 - val_accuracy: 0.5000\n","Epoch 9/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.8763\n","Epoch 9: val_loss did not improve from 1.51806\n","13/13 [==============================] - 7s 512ms/step - loss: 0.3437 - accuracy: 0.8763 - val_loss: 1.8348 - val_accuracy: 0.5000\n","Epoch 10/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3157 - accuracy: 0.8686\n","Epoch 10: val_loss did not improve from 1.51806\n","13/13 [==============================] - 7s 507ms/step - loss: 0.3157 - accuracy: 0.8686 - val_loss: 1.5623 - val_accuracy: 0.5000\n","Epoch 11/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2889 - accuracy: 0.8918\n","Epoch 11: val_loss did not improve from 1.51806\n","13/13 [==============================] - 7s 504ms/step - loss: 0.2889 - accuracy: 0.8918 - val_loss: 2.6232 - val_accuracy: 0.5104\n","Epoch 12/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.8737\n","Epoch 12: val_loss did not improve from 1.51806\n","13/13 [==============================] - 7s 504ms/step - loss: 0.3123 - accuracy: 0.8737 - val_loss: 3.3185 - val_accuracy: 0.5000\n","Epoch 13/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.8531\n","Epoch 13: val_loss did not improve from 1.51806\n","13/13 [==============================] - 7s 504ms/step - loss: 0.2948 - accuracy: 0.8531 - val_loss: 8.5476 - val_accuracy: 0.5000\n","Epoch 14/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3101 - accuracy: 0.8814\n","Epoch 14: val_loss did not improve from 1.51806\n","13/13 [==============================] - 7s 504ms/step - loss: 0.3101 - accuracy: 0.8814 - val_loss: 3.0193 - val_accuracy: 0.5000\n","Epoch 15/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2860 - accuracy: 0.8866\n","Epoch 15: val_loss improved from 1.51806 to 1.28914, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_19.h5\n","13/13 [==============================] - 9s 728ms/step - loss: 0.2860 - accuracy: 0.8866 - val_loss: 1.2891 - val_accuracy: 0.5000\n","Epoch 16/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3065 - accuracy: 0.8814\n","Epoch 16: val_loss did not improve from 1.28914\n","13/13 [==============================] - 7s 510ms/step - loss: 0.3065 - accuracy: 0.8814 - val_loss: 3.9035 - val_accuracy: 0.5000\n","Epoch 17/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3104 - accuracy: 0.8582\n","Epoch 17: val_loss did not improve from 1.28914\n","13/13 [==============================] - 7s 513ms/step - loss: 0.3104 - accuracy: 0.8582 - val_loss: 10.4994 - val_accuracy: 0.5000\n","Epoch 18/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.8634\n","Epoch 18: val_loss did not improve from 1.28914\n","13/13 [==============================] - 7s 517ms/step - loss: 0.2993 - accuracy: 0.8634 - val_loss: 5.0429 - val_accuracy: 0.5000\n","Epoch 19/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2693 - accuracy: 0.8918\n","Epoch 19: val_loss did not improve from 1.28914\n","13/13 [==============================] - 7s 518ms/step - loss: 0.2693 - accuracy: 0.8918 - val_loss: 3.1812 - val_accuracy: 0.5104\n","Epoch 20/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.8918\n","Epoch 20: val_loss did not improve from 1.28914\n","13/13 [==============================] - 7s 516ms/step - loss: 0.2721 - accuracy: 0.8918 - val_loss: 3.9892 - val_accuracy: 0.5208\n","Epoch 21/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.8814\n","Epoch 21: val_loss did not improve from 1.28914\n","13/13 [==============================] - 7s 512ms/step - loss: 0.2855 - accuracy: 0.8814 - val_loss: 2.0282 - val_accuracy: 0.5521\n","Epoch 22/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.8840\n","Epoch 22: val_loss improved from 1.28914 to 1.04103, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_19.h5\n","13/13 [==============================] - 9s 733ms/step - loss: 0.2465 - accuracy: 0.8840 - val_loss: 1.0410 - val_accuracy: 0.5729\n","Epoch 23/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.8969\n","Epoch 23: val_loss did not improve from 1.04103\n","13/13 [==============================] - 7s 505ms/step - loss: 0.2136 - accuracy: 0.8969 - val_loss: 2.6336 - val_accuracy: 0.5208\n","Epoch 24/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1834 - accuracy: 0.9253\n","Epoch 24: val_loss improved from 1.04103 to 0.74747, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_19.h5\n","13/13 [==============================] - 7s 568ms/step - loss: 0.1834 - accuracy: 0.9253 - val_loss: 0.7475 - val_accuracy: 0.7500\n","Epoch 25/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1998 - accuracy: 0.9227\n","Epoch 25: val_loss did not improve from 0.74747\n","13/13 [==============================] - 7s 506ms/step - loss: 0.1998 - accuracy: 0.9227 - val_loss: 1.7027 - val_accuracy: 0.6458\n","Epoch 26/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2397 - accuracy: 0.9046\n","Epoch 26: val_loss did not improve from 0.74747\n","13/13 [==============================] - 7s 506ms/step - loss: 0.2397 - accuracy: 0.9046 - val_loss: 2.3115 - val_accuracy: 0.5938\n","Epoch 27/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.8892\n","Epoch 27: val_loss did not improve from 0.74747\n","13/13 [==============================] - 7s 509ms/step - loss: 0.2586 - accuracy: 0.8892 - val_loss: 5.8784 - val_accuracy: 0.5000\n","Epoch 28/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.9072\n","Epoch 28: val_loss did not improve from 0.74747\n","13/13 [==============================] - 7s 512ms/step - loss: 0.2438 - accuracy: 0.9072 - val_loss: 7.7436 - val_accuracy: 0.5104\n","Epoch 29/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.9072\n","Epoch 29: val_loss did not improve from 0.74747\n","13/13 [==============================] - 7s 513ms/step - loss: 0.2401 - accuracy: 0.9072 - val_loss: 4.4711 - val_accuracy: 0.5729\n","Epoch 30/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2553 - accuracy: 0.9021\n","Epoch 30: val_loss did not improve from 0.74747\n","13/13 [==============================] - 7s 513ms/step - loss: 0.2553 - accuracy: 0.9021 - val_loss: 1.6108 - val_accuracy: 0.6875\n","Epoch 31/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1869 - accuracy: 0.9253\n","Epoch 31: val_loss improved from 0.74747 to 0.48791, saving model to /content/drive/MyDrive/Datasets/mcp_vgg_19.h5\n","13/13 [==============================] - 9s 743ms/step - loss: 0.1869 - accuracy: 0.9253 - val_loss: 0.4879 - val_accuracy: 0.8125\n","Epoch 32/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.9098\n","Epoch 32: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 510ms/step - loss: 0.1976 - accuracy: 0.9098 - val_loss: 0.5975 - val_accuracy: 0.7708\n","Epoch 33/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1906 - accuracy: 0.9227\n","Epoch 33: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 510ms/step - loss: 0.1906 - accuracy: 0.9227 - val_loss: 0.5579 - val_accuracy: 0.7917\n","Epoch 34/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2290 - accuracy: 0.9046\n","Epoch 34: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 513ms/step - loss: 0.2290 - accuracy: 0.9046 - val_loss: 3.2645 - val_accuracy: 0.5938\n","Epoch 35/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.9124\n","Epoch 35: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 512ms/step - loss: 0.2147 - accuracy: 0.9124 - val_loss: 0.8622 - val_accuracy: 0.7292\n","Epoch 36/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.9175\n","Epoch 36: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 513ms/step - loss: 0.1929 - accuracy: 0.9175 - val_loss: 0.7522 - val_accuracy: 0.7396\n","Epoch 37/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.9072\n","Epoch 37: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 512ms/step - loss: 0.2112 - accuracy: 0.9072 - val_loss: 0.6537 - val_accuracy: 0.7396\n","Epoch 38/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.9072\n","Epoch 38: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 512ms/step - loss: 0.2086 - accuracy: 0.9072 - val_loss: 1.8553 - val_accuracy: 0.5729\n","Epoch 39/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9149\n","Epoch 39: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 513ms/step - loss: 0.1886 - accuracy: 0.9149 - val_loss: 1.5560 - val_accuracy: 0.5833\n","Epoch 40/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9330\n","Epoch 40: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 513ms/step - loss: 0.1647 - accuracy: 0.9330 - val_loss: 1.5162 - val_accuracy: 0.6562\n","Epoch 41/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1323 - accuracy: 0.9536\n","Epoch 41: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 512ms/step - loss: 0.1323 - accuracy: 0.9536 - val_loss: 0.9238 - val_accuracy: 0.8333\n","Epoch 42/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.9330\n","Epoch 42: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 512ms/step - loss: 0.1653 - accuracy: 0.9330 - val_loss: 2.0585 - val_accuracy: 0.5625\n","Epoch 43/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1416 - accuracy: 0.9356\n","Epoch 43: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 513ms/step - loss: 0.1416 - accuracy: 0.9356 - val_loss: 2.3118 - val_accuracy: 0.5104\n","Epoch 44/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9588\n","Epoch 44: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 514ms/step - loss: 0.1194 - accuracy: 0.9588 - val_loss: 0.5729 - val_accuracy: 0.8125\n","Epoch 45/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9588\n","Epoch 45: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 511ms/step - loss: 0.1026 - accuracy: 0.9588 - val_loss: 1.9427 - val_accuracy: 0.6979\n","Epoch 46/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9407Restoring model weights from the end of the best epoch: 31.\n","\n","Epoch 46: val_loss did not improve from 0.48791\n","13/13 [==============================] - 7s 516ms/step - loss: 0.1359 - accuracy: 0.9407 - val_loss: 1.2391 - val_accuracy: 0.7083\n","Epoch 46: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f99b1570640>"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["y_pred = model_vgg_19.predict(x_test)\n","y_pred = np.where(y_pred>0.5,1,0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QvoUo93zApCy","executionInfo":{"status":"ok","timestamp":1679382807190,"user_tz":-540,"elapsed":640,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"cb6da44f-3067-495b-b744-8764068bcf29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 155ms/step\n"]}]},{"cell_type":"code","source":["confusion_matrix(y_test, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5LAtGuSJAxVH","executionInfo":{"status":"ok","timestamp":1679382810916,"user_tz":-540,"elapsed":3,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"45eae6b4-e24f-4113-e6ce-4ce052007494"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[47, 13],\n","       [11, 50]])"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V-xC4lvqA1Kr","executionInfo":{"status":"ok","timestamp":1679382814498,"user_tz":-540,"elapsed":4,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"bbf08799-2068-483e-c4b6-4b7467e79dc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.81      0.78      0.80        60\n","           1       0.79      0.82      0.81        61\n","\n","    accuracy                           0.80       121\n","   macro avg       0.80      0.80      0.80       121\n","weighted avg       0.80      0.80      0.80       121\n","\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import layers\n","keras.backend.clear_session()\n","model_resnet = keras.Sequential()\n","\n","model_resnet.add(ResNet50(include_top=True, weights='imagenet' ,input_shape=(224, 224, 3), classes=1))\n","model_resnet.compile(loss = 'binary_crossentropy', metrics = ['accuracy'],\n","              optimizer = 'adam')\n","model_resnet.summary()\n","\n","# 모델 요약\n","model_resnet.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":479},"id":"rerHkydyJqQp","executionInfo":{"status":"error","timestamp":1679454322581,"user_tz":-540,"elapsed":492,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"4a67743d-5f99-41f4-b714-56bb74819249"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-108-3da4ebaeb6d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_resnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel_resnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m model_resnet.compile(loss = 'binary_crossentropy', metrics = ['accuracy'],\n\u001b[1;32m      9\u001b[0m               optimizer = 'adam')\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m     return ResNet(\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0mstack_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"imagenet\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minclude_top\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m'If using `weights` as `\"imagenet\"` with `include_top`'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;34m\" as true, `classes` should be 1000\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000"]}]},{"cell_type":"code","source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   verbose = 1,\n","                   patience = 15,\n","                   restore_best_weights = True\n","                   )\n","\n","mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Datasets/mcp_resnet.h5',\n","                      monitor = 'val_loss',\n","                      verbose = 1,\n","                      save_best_only = True,\n","                      save_weights_only = False\n","                      )"],"metadata":{"id":"co--kHDWKjUk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_resnet.fit(x_train, y_train, callbacks = [es, mcp], epochs = 1000, validation_data = (x_valid, y_valid), verbose = 1, batch_size = 32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7nDquWC9KpOP","executionInfo":{"status":"error","timestamp":1679387154776,"user_tz":-540,"elapsed":201889,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"fb3b1893-65da-4136-b993-090b1442da1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","13/13 [==============================] - ETA: 0s - loss: 1.1047 - accuracy: 0.5000\n","Epoch 1: val_loss improved from inf to 1.54759, saving model to /content/drive/MyDrive/Datasets/mcp_resnet.h5\n","13/13 [==============================] - 40s 775ms/step - loss: 1.1047 - accuracy: 0.5000 - val_loss: 1.5476 - val_accuracy: 0.5000\n","Epoch 2/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.5000\n","Epoch 2: val_loss did not improve from 1.54759\n","13/13 [==============================] - 4s 315ms/step - loss: 0.4709 - accuracy: 0.5000 - val_loss: 5.3505 - val_accuracy: 0.5000\n","Epoch 3/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.5000\n","Epoch 3: val_loss did not improve from 1.54759\n","13/13 [==============================] - 4s 317ms/step - loss: 0.4397 - accuracy: 0.5000 - val_loss: 4.5695 - val_accuracy: 0.5000\n","Epoch 4/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4713 - accuracy: 0.5000\n","Epoch 4: val_loss did not improve from 1.54759\n","13/13 [==============================] - 4s 319ms/step - loss: 0.4713 - accuracy: 0.5000 - val_loss: 1.8165 - val_accuracy: 0.5000\n","Epoch 5/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.5000\n","Epoch 5: val_loss did not improve from 1.54759\n","13/13 [==============================] - 4s 322ms/step - loss: 0.4447 - accuracy: 0.5000 - val_loss: 2.9229 - val_accuracy: 0.5000\n","Epoch 6/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.5000\n","Epoch 6: val_loss did not improve from 1.54759\n","13/13 [==============================] - 4s 324ms/step - loss: 0.3325 - accuracy: 0.5000 - val_loss: 3.0216 - val_accuracy: 0.5000\n","Epoch 7/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2657 - accuracy: 0.5000\n","Epoch 7: val_loss did not improve from 1.54759\n","13/13 [==============================] - 4s 328ms/step - loss: 0.2657 - accuracy: 0.5000 - val_loss: 4.0643 - val_accuracy: 0.5000\n","Epoch 8/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 0.5000\n","Epoch 8: val_loss did not improve from 1.54759\n","13/13 [==============================] - 4s 332ms/step - loss: 0.3122 - accuracy: 0.5000 - val_loss: 4.4373 - val_accuracy: 0.5000\n","Epoch 9/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.5000\n","Epoch 9: val_loss improved from 1.54759 to 1.22580, saving model to /content/drive/MyDrive/Datasets/mcp_resnet.h5\n","13/13 [==============================] - 8s 651ms/step - loss: 0.2943 - accuracy: 0.5000 - val_loss: 1.2258 - val_accuracy: 0.5000\n","Epoch 10/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.5000\n","Epoch 10: val_loss did not improve from 1.22580\n","13/13 [==============================] - 4s 326ms/step - loss: 0.1488 - accuracy: 0.5000 - val_loss: 6.5649 - val_accuracy: 0.5000\n","Epoch 11/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.5000\n","Epoch 11: val_loss did not improve from 1.22580\n","13/13 [==============================] - 4s 327ms/step - loss: 0.2225 - accuracy: 0.5000 - val_loss: 4.8780 - val_accuracy: 0.5000\n","Epoch 12/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.5000\n","Epoch 12: val_loss did not improve from 1.22580\n","13/13 [==============================] - 4s 327ms/step - loss: 0.2851 - accuracy: 0.5000 - val_loss: 5.2077 - val_accuracy: 0.5000\n","Epoch 13/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3598 - accuracy: 0.5000\n","Epoch 13: val_loss improved from 1.22580 to 1.18014, saving model to /content/drive/MyDrive/Datasets/mcp_resnet.h5\n","13/13 [==============================] - 6s 447ms/step - loss: 0.3598 - accuracy: 0.5000 - val_loss: 1.1801 - val_accuracy: 0.5000\n","Epoch 14/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.5000\n","Epoch 14: val_loss did not improve from 1.18014\n","13/13 [==============================] - 4s 323ms/step - loss: 0.2148 - accuracy: 0.5000 - val_loss: 2.4673 - val_accuracy: 0.5000\n","Epoch 15/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.5000\n","Epoch 15: val_loss did not improve from 1.18014\n","13/13 [==============================] - 4s 321ms/step - loss: 0.1479 - accuracy: 0.5000 - val_loss: 5.7829 - val_accuracy: 0.5000\n","Epoch 16/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.5000\n","Epoch 16: val_loss did not improve from 1.18014\n","13/13 [==============================] - 4s 321ms/step - loss: 0.3452 - accuracy: 0.5000 - val_loss: 4.0462 - val_accuracy: 0.5000\n","Epoch 17/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2424 - accuracy: 0.5000\n","Epoch 17: val_loss did not improve from 1.18014\n","13/13 [==============================] - 4s 321ms/step - loss: 0.2424 - accuracy: 0.5000 - val_loss: 4.2473 - val_accuracy: 0.5000\n","Epoch 18/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2415 - accuracy: 0.5000\n","Epoch 18: val_loss did not improve from 1.18014\n","13/13 [==============================] - 4s 320ms/step - loss: 0.2415 - accuracy: 0.5000 - val_loss: 3.3177 - val_accuracy: 0.5000\n","Epoch 19/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.5000\n","Epoch 19: val_loss did not improve from 1.18014\n","13/13 [==============================] - 4s 320ms/step - loss: 0.2303 - accuracy: 0.5000 - val_loss: 1.5287 - val_accuracy: 0.5000\n","Epoch 20/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.5000\n","Epoch 20: val_loss did not improve from 1.18014\n","13/13 [==============================] - 4s 319ms/step - loss: 0.0987 - accuracy: 0.5000 - val_loss: 1.9376 - val_accuracy: 0.5000\n","Epoch 21/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.5000\n","Epoch 21: val_loss improved from 1.18014 to 1.16202, saving model to /content/drive/MyDrive/Datasets/mcp_resnet.h5\n","13/13 [==============================] - 8s 648ms/step - loss: 0.0805 - accuracy: 0.5000 - val_loss: 1.1620 - val_accuracy: 0.5000\n","Epoch 22/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.5000\n","Epoch 22: val_loss did not improve from 1.16202\n","13/13 [==============================] - 4s 319ms/step - loss: 0.0454 - accuracy: 0.5000 - val_loss: 1.5322 - val_accuracy: 0.5000\n","Epoch 23/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.5000\n","Epoch 23: val_loss did not improve from 1.16202\n","13/13 [==============================] - 4s 319ms/step - loss: 0.0501 - accuracy: 0.5000 - val_loss: 2.9611 - val_accuracy: 0.5000\n","Epoch 24/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.5000\n","Epoch 24: val_loss did not improve from 1.16202\n","13/13 [==============================] - 4s 321ms/step - loss: 0.1107 - accuracy: 0.5000 - val_loss: 4.9285 - val_accuracy: 0.5000\n","Epoch 25/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.3615 - accuracy: 0.5000\n","Epoch 25: val_loss did not improve from 1.16202\n","13/13 [==============================] - 4s 324ms/step - loss: 0.3615 - accuracy: 0.5000 - val_loss: 1.9248 - val_accuracy: 0.5000\n","Epoch 26/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2551 - accuracy: 0.5000\n","Epoch 26: val_loss did not improve from 1.16202\n","13/13 [==============================] - 4s 325ms/step - loss: 0.2551 - accuracy: 0.5000 - val_loss: 1.2013 - val_accuracy: 0.5000\n","Epoch 27/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.5000\n","Epoch 27: val_loss improved from 1.16202 to 0.63922, saving model to /content/drive/MyDrive/Datasets/mcp_resnet.h5\n","13/13 [==============================] - 8s 655ms/step - loss: 0.1054 - accuracy: 0.5000 - val_loss: 0.6392 - val_accuracy: 0.5000\n","Epoch 28/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.5000\n","Epoch 28: val_loss did not improve from 0.63922\n","13/13 [==============================] - 4s 324ms/step - loss: 0.2159 - accuracy: 0.5000 - val_loss: 0.8645 - val_accuracy: 0.5000\n","Epoch 29/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.5000\n","Epoch 29: val_loss did not improve from 0.63922\n","13/13 [==============================] - 4s 324ms/step - loss: 0.1769 - accuracy: 0.5000 - val_loss: 2.9534 - val_accuracy: 0.5000\n","Epoch 30/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2502 - accuracy: 0.5000\n","Epoch 30: val_loss did not improve from 0.63922\n","13/13 [==============================] - 4s 324ms/step - loss: 0.2502 - accuracy: 0.5000 - val_loss: 14.3802 - val_accuracy: 0.5000\n","Epoch 31/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.5000\n","Epoch 31: val_loss did not improve from 0.63922\n","13/13 [==============================] - 4s 325ms/step - loss: 0.2080 - accuracy: 0.5000 - val_loss: 4.5004 - val_accuracy: 0.5000\n","Epoch 32/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.5000\n","Epoch 32: val_loss did not improve from 0.63922\n","13/13 [==============================] - 4s 324ms/step - loss: 0.0927 - accuracy: 0.5000 - val_loss: 4.8302 - val_accuracy: 0.5000\n","Epoch 33/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.5000\n","Epoch 33: val_loss did not improve from 0.63922\n","13/13 [==============================] - 4s 323ms/step - loss: 0.0981 - accuracy: 0.5000 - val_loss: 6.6243 - val_accuracy: 0.5000\n","Epoch 34/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.5000\n","Epoch 34: val_loss did not improve from 0.63922\n","13/13 [==============================] - 4s 323ms/step - loss: 0.0470 - accuracy: 0.5000 - val_loss: 1.0437 - val_accuracy: 0.5000\n","Epoch 35/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.5000\n","Epoch 35: val_loss did not improve from 0.63922\n","13/13 [==============================] - 4s 322ms/step - loss: 0.0342 - accuracy: 0.5000 - val_loss: 0.9377 - val_accuracy: 0.5000\n","Epoch 36/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.5000\n","Epoch 36: val_loss did not improve from 0.63922\n","13/13 [==============================] - 4s 322ms/step - loss: 0.0694 - accuracy: 0.5000 - val_loss: 0.9198 - val_accuracy: 0.5000\n","Epoch 37/1000\n"," 4/13 [========>.....................] - ETA: 2s - loss: 0.0584 - accuracy: 0.5469"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-158-f37b67dcd5c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_resnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["y_pred = model_resnet.predict(x_test)\n","y_pred = np.where(y_pred>0.5,1,0)\n","confusion_matrix(y_test, y_pred)\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3T-bXr3wL1ha","executionInfo":{"status":"ok","timestamp":1679385660581,"user_tz":-540,"elapsed":2366,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"78ae3494-2200-41d1-cc65-d917c1f802f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 2s 339ms/step\n"]}]},{"cell_type":"code","source":["confusion_matrix(y_test, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NFZqEvS1L7yu","executionInfo":{"status":"ok","timestamp":1679385677096,"user_tz":-540,"elapsed":567,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"dc5372b0-b2d9-466b-dc41-b2ba1a446142"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0, 60],\n","       [ 0, 61]])"]},"metadata":{},"execution_count":142}]},{"cell_type":"code","source":["print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZrjihNBVL-9O","executionInfo":{"status":"ok","timestamp":1679385688742,"user_tz":-540,"elapsed":445,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"9bffc313-beca-4f31-d3bb-4e0a24aeb253"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        60\n","           1       0.50      1.00      0.67        61\n","\n","    accuracy                           0.50       121\n","   macro avg       0.25      0.50      0.34       121\n","weighted avg       0.25      0.50      0.34       121\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","metadata":{"id":"AxUpfhJ1xXle"},"source":["## 4.모델링 II\n","* **세부요구사항**\n","    - 성능을 높이기 위해서 다음의 두가지를 시도해 봅시다.\n","        - Data Augmentation을 통해 데이터를 증가 시킵니다.\n","            - ImageDataGenerator를 사용합니다.\n","        - 사전 학습된 모델(Transfer Learning)을 가져다 사용해 봅시다.\n","            - VGG16(이미지넷)을 사용해 봅시다."]},{"cell_type":"markdown","metadata":{"id":"ouCRBdKPxCut"},"source":["### (1) Data Augmentation\n","- **세부요구사항**\n","    * 모델 학습에 이용할 이미지 데이터를 증강시키세요.\n","    * Keras의 ImageDataGenerator를 이용\n","        - [ImageDataGenerator document](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n","\n","    * image generator를 이용하여 학습\n","        * 모델 구조는 이미 생성한 1,2,3 중 하나를 선택하여 학습\n"]},{"cell_type":"code","source":["!mkdir /content/drive/MyDrive/Datasets/Data_Augmentation"],"metadata":{"id":"d7t-ZEMwmote"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Data_Augmentation_path = '/content/drive/MyDrive/Datasets/Data_Augmentation/'"],"metadata":{"id":"ENkaCVjsm1Ap"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qe6yjs8F7Zox"},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYae9YFt8Q03"},"outputs":[],"source":["img_size = 224 ## 사이즈 조정 가능\n","dataset_path = '/content/drive/MyDrive/Datasets/'\n","train_path = dataset_path+'Car_Image_train/'\n","valid_path = dataset_path+'Car_Image_val/'\n","test_path = dataset_path+'Car_Image_test/'"]},{"cell_type":"markdown","source":["#### 1) ImageGenerator 생성\n","* ImageDataGenerator 함수 사용\n","    * 주요 옵션\n","        * rotation_range: 무작위 회전을 적용할 각도 범위\n","        * zoom_range: 무작위 줌을 적용할 범위 [1-zoom_range, 1+zoom_range]\n","        * horizontal_flip: 무작위 좌우반전을 적용할지 여부\n","        * vertical_flip: 무작위 상하반전을 적용할지 여부\n","        * rescale: 텐서의 모든 값을 rescale 값으로 나누어줌 (이 경우에는 255로 나누어서 0~1사이의 값으로 변경)"],"metadata":{"id":"IP4jIyTGfXD_"}},{"cell_type":"code","source":["datagen = ImageDataGenerator(rescale = 1./255,\n","                             rotation_range=30,       # 이미지 회전\n","                             width_shift_range=0.05,  # 이미지 좌우 이동\n","                             height_shift_range=0.05, # 이미지 상하 이동\n","                             zoom_range=0.2,          # 확대/축소 범위\n","                             shear_range=0.15,        # 비스듬히 늘림\n","                             horizontal_flip=True,    # 가로 전환\n","                             vertical_flip=True)      # 세로 전환\n","\n","testgen = ImageDataGenerator(rescale = 1./255)\n","\n"],"metadata":{"id":"2iZ3C2hAkig_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[":#### 2) 경로로 부터 이미지 불러 올 준비\n","* .flow_from_directory 이용\n","    * 디렉토리에서 이미지를 가져와서 데이터 증강을 적용하고 batch 단위로 제공하는 generator를 생성합니다.\n","    * 이미지를 불러올 때 target_size로 크기를 맞추고, \n","    * class_mode로 이진 분류(binary)를 수행하도록 지정합니다.\n"],"metadata":{"id":"dKwSYYkufanb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bwvQ4hHSCwY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679453817265,"user_tz":-540,"elapsed":5,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"e0ceed13-9e39-4a84-b587-337a04eba721"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 388 images belonging to 2 classes.\n","Found 96 images belonging to 2 classes.\n","Found 121 images belonging to 2 classes.\n"]}],"source":["train_generator = datagen.flow_from_directory(\n","    train_path,\n","    batch_size = 32,\n","    target_size = (img_size, img_size),\n","    class_mode = 'binary'\n",")\n","\n","valid_generator = testgen.flow_from_directory(\n","    valid_path,\n","    batch_size = 32,\n","    target_size = (img_size, img_size),\n","    class_mode = 'binary'\n",")\n","\n","test_generator = testgen.flow_from_directory(\n","    test_path,\n","    batch_size = 32,\n","    target_size = (img_size, img_size),\n","    class_mode = 'binary'\n",")"]},{"cell_type":"markdown","metadata":{"id":"g4RPCjU5f662"},"source":["#### 3) 학습\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 train_generator 이용. \n","    - validation_data = valid_generator 지정\n","    - Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"markdown","source":["![알뤡스](https://cdn-images-1.medium.com/max/1600/1*jqKHgwZ8alM3K_JRYO_l4w.png)"],"metadata":{"id":"olxfj_2mrctA"}},{"cell_type":"markdown","source":["* 구조 설계"],"metadata":{"id":"wVMLsXw6f663"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","\n","from keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization\n","\n","from sklearn.metrics import confusion_matrix, classification_report"],"metadata":{"id":"2VlYPnKqrnr1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   verbose = 1,\n","                   patience = 7,\n","                   restore_best_weights = True\n","                   )\n","\n","mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5',\n","                      monitor = 'val_loss',\n","                      verbose = 1,\n","                      save_best_only = True,\n","                      save_weights_only = False\n","                      )\n","\n","loss_array = [0] * 5\n","accuracy_array = [0] * 5"],"metadata":{"id":"xkfvVUUO6UGF","executionInfo":{"status":"ok","timestamp":1679464946177,"user_tz":-540,"elapsed":466,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":126,"outputs":[]},{"cell_type":"code","execution_count":127,"metadata":{"id":"_W7rqgH1f663","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679467604889,"user_tz":-540,"elapsed":2637650,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"a8eb8429-5d73-4b90-db15-37bf1e6ac11e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 27, 27, 96)       384       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 27, 27, 512)       1229312   \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 13, 13, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 13, 13, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 13, 13, 768)       3539712   \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 13, 13, 768)       5309184   \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 13, 13, 512)       3539456   \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 6, 6, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 13,657,601\n","Trainable params: 13,655,361\n","Non-trainable params: 2,240\n","_________________________________________________________________\n","Epoch 1/10000\n","13/13 [==============================] - ETA: 0s - loss: 1.6011 - accuracy: 0.7036\n","Epoch 1: val_loss improved from inf to 44.67444, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5\n","13/13 [==============================] - 23s 2s/step - loss: 1.6011 - accuracy: 0.7036 - val_loss: 44.6744 - val_accuracy: 0.5000\n","Epoch 2/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5686 - accuracy: 0.7268\n","Epoch 2: val_loss improved from 44.67444 to 16.39246, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5\n","13/13 [==============================] - 21s 2s/step - loss: 0.5686 - accuracy: 0.7268 - val_loss: 16.3925 - val_accuracy: 0.5000\n","Epoch 3/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4537 - accuracy: 0.7912\n","Epoch 3: val_loss improved from 16.39246 to 7.97794, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5\n","13/13 [==============================] - 20s 2s/step - loss: 0.4537 - accuracy: 0.7912 - val_loss: 7.9779 - val_accuracy: 0.5000\n","Epoch 4/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.8041\n","Epoch 4: val_loss improved from 7.97794 to 4.12865, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5\n","13/13 [==============================] - 21s 2s/step - loss: 0.4264 - accuracy: 0.8041 - val_loss: 4.1286 - val_accuracy: 0.4896\n","Epoch 5/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.8196\n","Epoch 5: val_loss did not improve from 4.12865\n","13/13 [==============================] - 19s 1s/step - loss: 0.4221 - accuracy: 0.8196 - val_loss: 4.3862 - val_accuracy: 0.5104\n","Epoch 6/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.8093\n","Epoch 6: val_loss improved from 4.12865 to 3.37434, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5\n","13/13 [==============================] - 20s 2s/step - loss: 0.4150 - accuracy: 0.8093 - val_loss: 3.3743 - val_accuracy: 0.5312\n","Epoch 7/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.8119\n","Epoch 7: val_loss improved from 3.37434 to 1.12330, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5\n","13/13 [==============================] - 21s 2s/step - loss: 0.4148 - accuracy: 0.8119 - val_loss: 1.1233 - val_accuracy: 0.5833\n","Epoch 8/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.8170\n","Epoch 8: val_loss improved from 1.12330 to 0.57054, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5\n","13/13 [==============================] - 21s 2s/step - loss: 0.4083 - accuracy: 0.8170 - val_loss: 0.5705 - val_accuracy: 0.6979\n","Epoch 9/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4259 - accuracy: 0.8144\n","Epoch 9: val_loss did not improve from 0.57054\n","13/13 [==============================] - 19s 2s/step - loss: 0.4259 - accuracy: 0.8144 - val_loss: 0.7075 - val_accuracy: 0.6250\n","Epoch 10/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3847 - accuracy: 0.8402\n","Epoch 10: val_loss did not improve from 0.57054\n","13/13 [==============================] - 19s 1s/step - loss: 0.3847 - accuracy: 0.8402 - val_loss: 0.5726 - val_accuracy: 0.7396\n","Epoch 11/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3541 - accuracy: 0.8711\n","Epoch 11: val_loss improved from 0.57054 to 0.40390, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5\n","13/13 [==============================] - 21s 2s/step - loss: 0.3541 - accuracy: 0.8711 - val_loss: 0.4039 - val_accuracy: 0.8542\n","Epoch 12/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3776 - accuracy: 0.8402\n","Epoch 12: val_loss did not improve from 0.40390\n","13/13 [==============================] - 19s 1s/step - loss: 0.3776 - accuracy: 0.8402 - val_loss: 0.4311 - val_accuracy: 0.8125\n","Epoch 13/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.8351\n","Epoch 13: val_loss did not improve from 0.40390\n","13/13 [==============================] - 19s 1s/step - loss: 0.3848 - accuracy: 0.8351 - val_loss: 0.5557 - val_accuracy: 0.6979\n","Epoch 14/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4119 - accuracy: 0.8299\n","Epoch 14: val_loss improved from 0.40390 to 0.38176, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5\n","13/13 [==============================] - 21s 2s/step - loss: 0.4119 - accuracy: 0.8299 - val_loss: 0.3818 - val_accuracy: 0.8229\n","Epoch 15/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4035 - accuracy: 0.8402\n","Epoch 15: val_loss did not improve from 0.38176\n","13/13 [==============================] - 19s 1s/step - loss: 0.4035 - accuracy: 0.8402 - val_loss: 0.8038 - val_accuracy: 0.6979\n","Epoch 16/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3473 - accuracy: 0.8608\n","Epoch 16: val_loss improved from 0.38176 to 0.34133, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5\n","13/13 [==============================] - 21s 2s/step - loss: 0.3473 - accuracy: 0.8608 - val_loss: 0.3413 - val_accuracy: 0.8542\n","Epoch 17/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3725 - accuracy: 0.8660\n","Epoch 17: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3725 - accuracy: 0.8660 - val_loss: 0.3714 - val_accuracy: 0.8229\n","Epoch 18/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8428\n","Epoch 18: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3876 - accuracy: 0.8428 - val_loss: 0.4471 - val_accuracy: 0.8021\n","Epoch 19/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.8531\n","Epoch 19: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3677 - accuracy: 0.8531 - val_loss: 0.6036 - val_accuracy: 0.7396\n","Epoch 20/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8531\n","Epoch 20: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3798 - accuracy: 0.8531 - val_loss: 0.3833 - val_accuracy: 0.8021\n","Epoch 21/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.8505\n","Epoch 21: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3675 - accuracy: 0.8505 - val_loss: 0.4143 - val_accuracy: 0.8438\n","Epoch 22/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3397 - accuracy: 0.8608\n","Epoch 22: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3397 - accuracy: 0.8608 - val_loss: 0.3736 - val_accuracy: 0.8229\n","Epoch 23/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8325Restoring model weights from the end of the best epoch: 16.\n","\n","Epoch 23: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3869 - accuracy: 0.8325 - val_loss: 1.0515 - val_accuracy: 0.5938\n","Epoch 23: early stopping\n","4/4 [==============================] - 4s 918ms/step - loss: 0.4552 - accuracy: 0.8347\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 27, 27, 96)       384       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 27, 27, 512)       1229312   \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 13, 13, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 13, 13, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 13, 13, 768)       3539712   \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 13, 13, 768)       5309184   \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 13, 13, 512)       3539456   \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 6, 6, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 13,657,601\n","Trainable params: 13,655,361\n","Non-trainable params: 2,240\n","_________________________________________________________________\n","Epoch 1/10000\n","13/13 [==============================] - ETA: 0s - loss: 1.7189 - accuracy: 0.6624\n","Epoch 1: val_loss did not improve from 0.34133\n","13/13 [==============================] - 21s 1s/step - loss: 1.7189 - accuracy: 0.6624 - val_loss: 35.2784 - val_accuracy: 0.5000\n","Epoch 2/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.7258 - accuracy: 0.7552\n","Epoch 2: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.7258 - accuracy: 0.7552 - val_loss: 14.8279 - val_accuracy: 0.5000\n","Epoch 3/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.7809\n","Epoch 3: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.5178 - accuracy: 0.7809 - val_loss: 8.3819 - val_accuracy: 0.5000\n","Epoch 4/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.8247\n","Epoch 4: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4403 - accuracy: 0.8247 - val_loss: 2.7141 - val_accuracy: 0.4896\n","Epoch 5/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.8428\n","Epoch 5: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4270 - accuracy: 0.8428 - val_loss: 1.0767 - val_accuracy: 0.5104\n","Epoch 6/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.8299\n","Epoch 6: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4333 - accuracy: 0.8299 - val_loss: 0.7464 - val_accuracy: 0.5521\n","Epoch 7/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4141 - accuracy: 0.8273\n","Epoch 7: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4141 - accuracy: 0.8273 - val_loss: 0.6749 - val_accuracy: 0.6042\n","Epoch 8/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8428\n","Epoch 8: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3816 - accuracy: 0.8428 - val_loss: 0.6379 - val_accuracy: 0.6458\n","Epoch 9/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.8428\n","Epoch 9: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3794 - accuracy: 0.8428 - val_loss: 0.5641 - val_accuracy: 0.7188\n","Epoch 10/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3884 - accuracy: 0.8376\n","Epoch 10: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3884 - accuracy: 0.8376 - val_loss: 0.5180 - val_accuracy: 0.7396\n","Epoch 11/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8428\n","Epoch 11: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3882 - accuracy: 0.8428 - val_loss: 0.6446 - val_accuracy: 0.6354\n","Epoch 12/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.8608\n","Epoch 12: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3673 - accuracy: 0.8608 - val_loss: 0.5069 - val_accuracy: 0.7396\n","Epoch 13/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.8505\n","Epoch 13: val_loss did not improve from 0.34133\n","13/13 [==============================] - 18s 1s/step - loss: 0.3658 - accuracy: 0.8505 - val_loss: 0.7651 - val_accuracy: 0.5521\n","Epoch 14/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8531\n","Epoch 14: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3852 - accuracy: 0.8531 - val_loss: 0.6834 - val_accuracy: 0.6042\n","Epoch 15/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.7990\n","Epoch 15: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4264 - accuracy: 0.7990 - val_loss: 0.6098 - val_accuracy: 0.5729\n","Epoch 16/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.8454\n","Epoch 16: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3762 - accuracy: 0.8454 - val_loss: 0.5898 - val_accuracy: 0.6771\n","Epoch 17/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.8376\n","Epoch 17: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3806 - accuracy: 0.8376 - val_loss: 0.4650 - val_accuracy: 0.7917\n","Epoch 18/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.8170\n","Epoch 18: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3992 - accuracy: 0.8170 - val_loss: 0.5336 - val_accuracy: 0.7396\n","Epoch 19/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8454\n","Epoch 19: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3837 - accuracy: 0.8454 - val_loss: 0.4185 - val_accuracy: 0.8229\n","Epoch 20/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.8454\n","Epoch 20: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 2s/step - loss: 0.3655 - accuracy: 0.8454 - val_loss: 0.6075 - val_accuracy: 0.7083\n","Epoch 21/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.8634\n","Epoch 21: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3464 - accuracy: 0.8634 - val_loss: 0.4369 - val_accuracy: 0.8333\n","Epoch 22/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3729 - accuracy: 0.8454\n","Epoch 22: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 2s/step - loss: 0.3729 - accuracy: 0.8454 - val_loss: 0.5427 - val_accuracy: 0.7500\n","Epoch 23/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8454\n","Epoch 23: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3631 - accuracy: 0.8454 - val_loss: 0.3807 - val_accuracy: 0.7917\n","Epoch 24/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3525 - accuracy: 0.8608\n","Epoch 24: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3525 - accuracy: 0.8608 - val_loss: 0.4878 - val_accuracy: 0.7917\n","Epoch 25/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3555 - accuracy: 0.8557\n","Epoch 25: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3555 - accuracy: 0.8557 - val_loss: 0.3924 - val_accuracy: 0.8021\n","Epoch 26/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.8479\n","Epoch 26: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3699 - accuracy: 0.8479 - val_loss: 0.4311 - val_accuracy: 0.7604\n","Epoch 27/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.8557\n","Epoch 27: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3524 - accuracy: 0.8557 - val_loss: 0.4688 - val_accuracy: 0.7500\n","Epoch 28/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.8299\n","Epoch 28: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3575 - accuracy: 0.8299 - val_loss: 0.6551 - val_accuracy: 0.6875\n","Epoch 29/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.8479\n","Epoch 29: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 2s/step - loss: 0.3675 - accuracy: 0.8479 - val_loss: 0.5540 - val_accuracy: 0.7396\n","Epoch 30/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.8608Restoring model weights from the end of the best epoch: 23.\n","\n","Epoch 30: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3281 - accuracy: 0.8608 - val_loss: 0.4584 - val_accuracy: 0.8333\n","Epoch 30: early stopping\n","4/4 [==============================] - 4s 938ms/step - loss: 0.3838 - accuracy: 0.8678\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 27, 27, 96)       384       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 27, 27, 512)       1229312   \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 13, 13, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 13, 13, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 13, 13, 768)       3539712   \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 13, 13, 768)       5309184   \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 13, 13, 512)       3539456   \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 6, 6, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 13,657,601\n","Trainable params: 13,655,361\n","Non-trainable params: 2,240\n","_________________________________________________________________\n","Epoch 1/10000\n","13/13 [==============================] - ETA: 0s - loss: 1.1978 - accuracy: 0.7706\n","Epoch 1: val_loss did not improve from 0.34133\n","13/13 [==============================] - 21s 1s/step - loss: 1.1978 - accuracy: 0.7706 - val_loss: 41.7314 - val_accuracy: 0.5000\n","Epoch 2/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.7668 - accuracy: 0.7706\n","Epoch 2: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.7668 - accuracy: 0.7706 - val_loss: 14.1984 - val_accuracy: 0.5000\n","Epoch 3/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5391 - accuracy: 0.7784\n","Epoch 3: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 2s/step - loss: 0.5391 - accuracy: 0.7784 - val_loss: 4.9197 - val_accuracy: 0.5000\n","Epoch 4/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4926 - accuracy: 0.7732\n","Epoch 4: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4926 - accuracy: 0.7732 - val_loss: 1.8864 - val_accuracy: 0.5000\n","Epoch 5/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.7912\n","Epoch 5: val_loss did not improve from 0.34133\n","13/13 [==============================] - 18s 1s/step - loss: 0.4397 - accuracy: 0.7912 - val_loss: 1.8789 - val_accuracy: 0.5208\n","Epoch 6/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.8015\n","Epoch 6: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3987 - accuracy: 0.8015 - val_loss: 1.2807 - val_accuracy: 0.5312\n","Epoch 7/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.8093\n","Epoch 7: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 2s/step - loss: 0.4221 - accuracy: 0.8093 - val_loss: 0.8753 - val_accuracy: 0.5625\n","Epoch 8/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.8222\n","Epoch 8: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 2s/step - loss: 0.3893 - accuracy: 0.8222 - val_loss: 0.6472 - val_accuracy: 0.6042\n","Epoch 9/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.8170\n","Epoch 9: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4059 - accuracy: 0.8170 - val_loss: 0.5585 - val_accuracy: 0.6667\n","Epoch 10/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3994 - accuracy: 0.8196\n","Epoch 10: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3994 - accuracy: 0.8196 - val_loss: 0.5243 - val_accuracy: 0.7188\n","Epoch 11/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.8428\n","Epoch 11: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 2s/step - loss: 0.3734 - accuracy: 0.8428 - val_loss: 0.5647 - val_accuracy: 0.7812\n","Epoch 12/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.8505\n","Epoch 12: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3923 - accuracy: 0.8505 - val_loss: 0.5107 - val_accuracy: 0.7604\n","Epoch 13/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.8093\n","Epoch 13: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3911 - accuracy: 0.8093 - val_loss: 0.5369 - val_accuracy: 0.7083\n","Epoch 14/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.8376\n","Epoch 14: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3782 - accuracy: 0.8376 - val_loss: 0.5214 - val_accuracy: 0.7083\n","Epoch 15/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4119 - accuracy: 0.8351\n","Epoch 15: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4119 - accuracy: 0.8351 - val_loss: 0.5395 - val_accuracy: 0.7292\n","Epoch 16/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8170\n","Epoch 16: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3982 - accuracy: 0.8170 - val_loss: 0.4171 - val_accuracy: 0.8021\n","Epoch 17/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3668 - accuracy: 0.8531\n","Epoch 17: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3668 - accuracy: 0.8531 - val_loss: 0.4617 - val_accuracy: 0.7604\n","Epoch 18/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.8505\n","Epoch 18: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3574 - accuracy: 0.8505 - val_loss: 0.9369 - val_accuracy: 0.6875\n","Epoch 19/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.8273\n","Epoch 19: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 2s/step - loss: 0.3782 - accuracy: 0.8273 - val_loss: 0.4379 - val_accuracy: 0.7917\n","Epoch 20/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.8454\n","Epoch 20: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 2s/step - loss: 0.3724 - accuracy: 0.8454 - val_loss: 0.3895 - val_accuracy: 0.8125\n","Epoch 21/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3486 - accuracy: 0.8479\n","Epoch 21: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3486 - accuracy: 0.8479 - val_loss: 0.3803 - val_accuracy: 0.8125\n","Epoch 22/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3630 - accuracy: 0.8428\n","Epoch 22: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3630 - accuracy: 0.8428 - val_loss: 0.4540 - val_accuracy: 0.7917\n","Epoch 23/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8582\n","Epoch 23: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 2s/step - loss: 0.3736 - accuracy: 0.8582 - val_loss: 0.4123 - val_accuracy: 0.7917\n","Epoch 24/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.8479\n","Epoch 24: val_loss did not improve from 0.34133\n","13/13 [==============================] - 18s 1s/step - loss: 0.3619 - accuracy: 0.8479 - val_loss: 0.5224 - val_accuracy: 0.7604\n","Epoch 25/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8531\n","Epoch 25: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3805 - accuracy: 0.8531 - val_loss: 0.3841 - val_accuracy: 0.8125\n","Epoch 26/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.8711\n","Epoch 26: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3304 - accuracy: 0.8711 - val_loss: 0.4837 - val_accuracy: 0.7604\n","Epoch 27/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.8660\n","Epoch 27: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3460 - accuracy: 0.8660 - val_loss: 0.4383 - val_accuracy: 0.7708\n","Epoch 28/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.8608Restoring model weights from the end of the best epoch: 21.\n","\n","Epoch 28: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3676 - accuracy: 0.8608 - val_loss: 0.3845 - val_accuracy: 0.8229\n","Epoch 28: early stopping\n","4/4 [==============================] - 4s 932ms/step - loss: 0.4341 - accuracy: 0.8347\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 27, 27, 96)       384       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 27, 27, 512)       1229312   \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 13, 13, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 13, 13, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 13, 13, 768)       3539712   \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 13, 13, 768)       5309184   \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 13, 13, 512)       3539456   \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 6, 6, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 13,657,601\n","Trainable params: 13,655,361\n","Non-trainable params: 2,240\n","_________________________________________________________________\n","Epoch 1/10000\n","13/13 [==============================] - ETA: 0s - loss: 1.3382 - accuracy: 0.7062\n","Epoch 1: val_loss did not improve from 0.34133\n","13/13 [==============================] - 21s 1s/step - loss: 1.3382 - accuracy: 0.7062 - val_loss: 36.9819 - val_accuracy: 0.5000\n","Epoch 2/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5693 - accuracy: 0.7242\n","Epoch 2: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.5693 - accuracy: 0.7242 - val_loss: 12.0505 - val_accuracy: 0.5000\n","Epoch 3/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5072 - accuracy: 0.7552\n","Epoch 3: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.5072 - accuracy: 0.7552 - val_loss: 6.9350 - val_accuracy: 0.5000\n","Epoch 4/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.7629\n","Epoch 4: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4742 - accuracy: 0.7629 - val_loss: 3.8346 - val_accuracy: 0.4896\n","Epoch 5/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4463 - accuracy: 0.8119\n","Epoch 5: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4463 - accuracy: 0.8119 - val_loss: 1.5270 - val_accuracy: 0.5208\n","Epoch 6/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.8093\n","Epoch 6: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 2s/step - loss: 0.4319 - accuracy: 0.8093 - val_loss: 0.6650 - val_accuracy: 0.5625\n","Epoch 7/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4095 - accuracy: 0.8247\n","Epoch 7: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4095 - accuracy: 0.8247 - val_loss: 0.6969 - val_accuracy: 0.6146\n","Epoch 8/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3740 - accuracy: 0.8222\n","Epoch 8: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3740 - accuracy: 0.8222 - val_loss: 0.6043 - val_accuracy: 0.6562\n","Epoch 9/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.8351\n","Epoch 9: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3756 - accuracy: 0.8351 - val_loss: 0.6932 - val_accuracy: 0.5833\n","Epoch 10/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8428\n","Epoch 10: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3903 - accuracy: 0.8428 - val_loss: 1.1286 - val_accuracy: 0.5104\n","Epoch 11/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3954 - accuracy: 0.8402\n","Epoch 11: val_loss did not improve from 0.34133\n","13/13 [==============================] - 18s 1s/step - loss: 0.3954 - accuracy: 0.8402 - val_loss: 1.2714 - val_accuracy: 0.5000\n","Epoch 12/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.8479\n","Epoch 12: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3677 - accuracy: 0.8479 - val_loss: 0.6153 - val_accuracy: 0.6146\n","Epoch 13/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3722 - accuracy: 0.8299\n","Epoch 13: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3722 - accuracy: 0.8299 - val_loss: 0.4563 - val_accuracy: 0.7812\n","Epoch 14/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3825 - accuracy: 0.8428\n","Epoch 14: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3825 - accuracy: 0.8428 - val_loss: 0.5082 - val_accuracy: 0.7604\n","Epoch 15/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.8325\n","Epoch 15: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3808 - accuracy: 0.8325 - val_loss: 0.4900 - val_accuracy: 0.7812\n","Epoch 16/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.8557\n","Epoch 16: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3712 - accuracy: 0.8557 - val_loss: 0.4618 - val_accuracy: 0.7604\n","Epoch 17/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8531\n","Epoch 17: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3811 - accuracy: 0.8531 - val_loss: 0.3938 - val_accuracy: 0.8438\n","Epoch 18/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.8144\n","Epoch 18: val_loss did not improve from 0.34133\n","13/13 [==============================] - 18s 1s/step - loss: 0.3890 - accuracy: 0.8144 - val_loss: 0.3451 - val_accuracy: 0.8438\n","Epoch 19/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3649 - accuracy: 0.8505\n","Epoch 19: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3649 - accuracy: 0.8505 - val_loss: 1.1886 - val_accuracy: 0.5417\n","Epoch 20/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8428\n","Epoch 20: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3828 - accuracy: 0.8428 - val_loss: 0.4237 - val_accuracy: 0.8021\n","Epoch 21/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3770 - accuracy: 0.8428\n","Epoch 21: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3770 - accuracy: 0.8428 - val_loss: 0.4349 - val_accuracy: 0.8125\n","Epoch 22/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.8660\n","Epoch 22: val_loss did not improve from 0.34133\n","13/13 [==============================] - 18s 1s/step - loss: 0.3643 - accuracy: 0.8660 - val_loss: 0.3809 - val_accuracy: 0.7812\n","Epoch 23/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3432 - accuracy: 0.8789\n","Epoch 23: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3432 - accuracy: 0.8789 - val_loss: 0.6146 - val_accuracy: 0.6875\n","Epoch 24/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.8428\n","Epoch 24: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3699 - accuracy: 0.8428 - val_loss: 1.2037 - val_accuracy: 0.6354\n","Epoch 25/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8376Restoring model weights from the end of the best epoch: 18.\n","\n","Epoch 25: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3952 - accuracy: 0.8376 - val_loss: 0.3996 - val_accuracy: 0.7708\n","Epoch 25: early stopping\n","4/4 [==============================] - 4s 912ms/step - loss: 0.3979 - accuracy: 0.8430\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 27, 27, 96)       384       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 27, 27, 512)       1229312   \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 13, 13, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 13, 13, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 13, 13, 768)       3539712   \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 13, 13, 768)       5309184   \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 13, 13, 512)       3539456   \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 6, 6, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 13,657,601\n","Trainable params: 13,655,361\n","Non-trainable params: 2,240\n","_________________________________________________________________\n","Epoch 1/10000\n","13/13 [==============================] - ETA: 0s - loss: 1.0995 - accuracy: 0.7423\n","Epoch 1: val_loss did not improve from 0.34133\n","13/13 [==============================] - 22s 1s/step - loss: 1.0995 - accuracy: 0.7423 - val_loss: 44.3395 - val_accuracy: 0.5000\n","Epoch 2/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.7784\n","Epoch 2: val_loss did not improve from 0.34133\n","13/13 [==============================] - 18s 1s/step - loss: 0.5250 - accuracy: 0.7784 - val_loss: 11.2539 - val_accuracy: 0.5000\n","Epoch 3/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4773 - accuracy: 0.7912\n","Epoch 3: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4773 - accuracy: 0.7912 - val_loss: 4.8497 - val_accuracy: 0.5000\n","Epoch 4/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.8144\n","Epoch 4: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4476 - accuracy: 0.8144 - val_loss: 4.1304 - val_accuracy: 0.5000\n","Epoch 5/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4015 - accuracy: 0.8119\n","Epoch 5: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4015 - accuracy: 0.8119 - val_loss: 2.0872 - val_accuracy: 0.5000\n","Epoch 6/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4156 - accuracy: 0.8067\n","Epoch 6: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4156 - accuracy: 0.8067 - val_loss: 0.9496 - val_accuracy: 0.5729\n","Epoch 7/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8170\n","Epoch 7: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4030 - accuracy: 0.8170 - val_loss: 0.5654 - val_accuracy: 0.6875\n","Epoch 8/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.8093\n","Epoch 8: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4049 - accuracy: 0.8093 - val_loss: 0.5755 - val_accuracy: 0.6458\n","Epoch 9/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8531\n","Epoch 9: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3843 - accuracy: 0.8531 - val_loss: 0.6404 - val_accuracy: 0.5938\n","Epoch 10/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3955 - accuracy: 0.8402\n","Epoch 10: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3955 - accuracy: 0.8402 - val_loss: 0.7336 - val_accuracy: 0.5729\n","Epoch 11/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3879 - accuracy: 0.8428\n","Epoch 11: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3879 - accuracy: 0.8428 - val_loss: 0.4663 - val_accuracy: 0.7708\n","Epoch 12/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.8531\n","Epoch 12: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3539 - accuracy: 0.8531 - val_loss: 0.4231 - val_accuracy: 0.7917\n","Epoch 13/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.8299\n","Epoch 13: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3923 - accuracy: 0.8299 - val_loss: 0.4403 - val_accuracy: 0.7812\n","Epoch 14/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.8608\n","Epoch 14: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3887 - accuracy: 0.8608 - val_loss: 0.4181 - val_accuracy: 0.7917\n","Epoch 15/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8428\n","Epoch 15: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3843 - accuracy: 0.8428 - val_loss: 0.3726 - val_accuracy: 0.8229\n","Epoch 16/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.8557\n","Epoch 16: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3651 - accuracy: 0.8557 - val_loss: 0.5373 - val_accuracy: 0.7188\n","Epoch 17/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4012 - accuracy: 0.8299\n","Epoch 17: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4012 - accuracy: 0.8299 - val_loss: 0.3727 - val_accuracy: 0.8333\n","Epoch 18/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.8454\n","Epoch 18: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3468 - accuracy: 0.8454 - val_loss: 0.3978 - val_accuracy: 0.7917\n","Epoch 19/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.8351\n","Epoch 19: val_loss did not improve from 0.34133\n","13/13 [==============================] - 18s 1s/step - loss: 0.3864 - accuracy: 0.8351 - val_loss: 0.4754 - val_accuracy: 0.7917\n","Epoch 20/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3616 - accuracy: 0.8686\n","Epoch 20: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3616 - accuracy: 0.8686 - val_loss: 0.3697 - val_accuracy: 0.8438\n","Epoch 21/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3748 - accuracy: 0.8428\n","Epoch 21: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3748 - accuracy: 0.8428 - val_loss: 0.5395 - val_accuracy: 0.7708\n","Epoch 22/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4280 - accuracy: 0.8222\n","Epoch 22: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.4280 - accuracy: 0.8222 - val_loss: 0.3813 - val_accuracy: 0.8229\n","Epoch 23/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.8660\n","Epoch 23: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3655 - accuracy: 0.8660 - val_loss: 0.4088 - val_accuracy: 0.8438\n","Epoch 24/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.8608\n","Epoch 24: val_loss did not improve from 0.34133\n","13/13 [==============================] - 18s 1s/step - loss: 0.3339 - accuracy: 0.8608 - val_loss: 0.3436 - val_accuracy: 0.8333\n","Epoch 25/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.8557\n","Epoch 25: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3588 - accuracy: 0.8557 - val_loss: 0.3860 - val_accuracy: 0.8125\n","Epoch 26/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.8711\n","Epoch 26: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3403 - accuracy: 0.8711 - val_loss: 0.3888 - val_accuracy: 0.8125\n","Epoch 27/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3711 - accuracy: 0.8711\n","Epoch 27: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3711 - accuracy: 0.8711 - val_loss: 0.3956 - val_accuracy: 0.8021\n","Epoch 28/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.8428\n","Epoch 28: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3731 - accuracy: 0.8428 - val_loss: 0.4533 - val_accuracy: 0.7812\n","Epoch 29/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.8299\n","Epoch 29: val_loss did not improve from 0.34133\n","13/13 [==============================] - 18s 1s/step - loss: 0.3734 - accuracy: 0.8299 - val_loss: 0.4157 - val_accuracy: 0.8229\n","Epoch 30/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.8634\n","Epoch 30: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3550 - accuracy: 0.8634 - val_loss: 0.4498 - val_accuracy: 0.7917\n","Epoch 31/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3693 - accuracy: 0.8428Restoring model weights from the end of the best epoch: 24.\n","\n","Epoch 31: val_loss did not improve from 0.34133\n","13/13 [==============================] - 19s 1s/step - loss: 0.3693 - accuracy: 0.8428 - val_loss: 0.4737 - val_accuracy: 0.7917\n","Epoch 31: early stopping\n","4/4 [==============================] - 4s 925ms/step - loss: 0.4925 - accuracy: 0.8099\n"]}],"source":["for i in range(5) :\n","    # 1. 세션 클리어\n","    keras.backend.clear_session()\n","\n","    # 2. 모델 사슬처럼 엮기\n","    il = Input(shape = (227, 227, 3))\n","    hl = Conv2D( filters = 96, kernel_size = (11, 11), strides = (4, 4), activation = 'relu')(il)\n","    hl = MaxPool2D( pool_size = (3, 3), strides = (2, 2))(hl)\n","    hl = BatchNormalization()(hl)\n","\n","    hl = Conv2D( filters = 512, kernel_size = (5, 5), padding = 'same', activation = 'relu')(hl)\n","    hl = MaxPool2D( pool_size = (3, 3), strides = (2, 2))(hl)\n","    hl = BatchNormalization()(hl)\n","\n","    hl = Conv2D( filters = 768, kernel_size = (3, 3), padding = 'same', activation = 'relu')(hl)\n","    hl = Conv2D( filters = 768, kernel_size = (3, 3), padding = 'same', activation = 'relu')(hl)\n","    hl = Conv2D( filters = 512, kernel_size = (3, 3), padding = 'same', activation = 'relu')(hl)\n","    hl = MaxPool2D( pool_size = (3, 3), strides = (2, 2))(hl)\n","    hl = BatchNormalization()(hl)\n","\n","    hl = keras.layers.GlobalAvgPool2D()(hl)\n","\n","    hl = Dropout(0.3)(hl)\n","\n","    ol = Dense(1, activation = 'sigmoid')(hl)\n","\n","    model_alexnet_GlobalAvgPool = keras.models.Model(il, ol)\n","\n","\n","    #  4. 모델 컴파일\n","    model_alexnet_GlobalAvgPool.compile(loss = 'binary_crossentropy', metrics = ['accuracy'],\n","                optimizer = 'adam')\n","    # 모델 요약\n","    model_alexnet_GlobalAvgPool.summary()\n","\n","    hist = model_alexnet_GlobalAvgPool.fit(train_generator, epochs=10000, validation_data=valid_generator, verbose = 1, callbacks=[es, mcp], batch_size=32)\n","\n","    evaluate_result = model_alexnet_GlobalAvgPool.evaluate(test_generator)\n","    loss_array[i] = evaluate_result[0] # loss\n","    accuracy_array[i] = evaluate_result[1] # loss"]},{"cell_type":"code","source":["print(loss_array)\n","print('---------------------------')\n","print(accuracy_array)\n","print('---------------------------')\n","print('loss mean :', np.array(loss_array).mean())\n","print('accuracy mean :',np.array(accuracy_array).mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pcd4cc-HEqhI","executionInfo":{"status":"ok","timestamp":1679467824767,"user_tz":-540,"elapsed":532,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"26ce924f-30a5-4d40-c3d3-98e62d130690"},"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.45521268248558044, 0.3837905526161194, 0.4340907335281372, 0.39785516262054443, 0.4924594461917877]\n","---------------------------\n","[0.8347107172012329, 0.8677685856819153, 0.8347107172012329, 0.8429751992225647, 0.8099173307418823]\n","---------------------------\n","loss mean : 0.4326817154884338\n","accuracy mean : 0.8380165100097656\n"]}]},{"cell_type":"markdown","source":["* 학습\n","    * EarlyStopping 설정하기\n","    * 학습 데이터에 train_generator, validation_data=valid_generator 사용"],"metadata":{"id":"nw2_G7zdf663"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6m5mRE9Nf663"},"outputs":[],"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   verbose = 1,\n","                   patience = 7,\n","                   restore_best_weights = True\n","                   )\n","\n","mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5',\n","                      monitor = 'val_loss',\n","                      verbose = 1,\n","                      save_best_only = True,\n","                      save_weights_only = False\n","                      )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCWzBSYqf663","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679452525099,"user_tz":-540,"elapsed":156298,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"aa330c18-406f-4464-91d1-091c728201ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8402\n","Epoch 1: val_loss improved from inf to 0.35804, saving model to /content/drive/MyDrive/Datasets/mcp_alexnet_data_augmentation.h5\n","13/13 [==============================] - 22s 2s/step - loss: 0.3434 - accuracy: 0.8402 - val_loss: 0.3580 - val_accuracy: 0.8125\n","Epoch 2/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3422 - accuracy: 0.8686\n","Epoch 2: val_loss did not improve from 0.35804\n","13/13 [==============================] - 19s 1s/step - loss: 0.3422 - accuracy: 0.8686 - val_loss: 0.3626 - val_accuracy: 0.8229\n","Epoch 3/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.8351\n","Epoch 3: val_loss did not improve from 0.35804\n","13/13 [==============================] - 19s 1s/step - loss: 0.3369 - accuracy: 0.8351 - val_loss: 0.3659 - val_accuracy: 0.8125\n","Epoch 4/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.8505\n","Epoch 4: val_loss did not improve from 0.35804\n","13/13 [==============================] - 19s 1s/step - loss: 0.3435 - accuracy: 0.8505 - val_loss: 0.3880 - val_accuracy: 0.8229\n","Epoch 5/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.8608\n","Epoch 5: val_loss did not improve from 0.35804\n","13/13 [==============================] - 19s 1s/step - loss: 0.3298 - accuracy: 0.8608 - val_loss: 0.3731 - val_accuracy: 0.8333\n","Epoch 6/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.8892\n","Epoch 6: val_loss did not improve from 0.35804\n","13/13 [==============================] - 19s 1s/step - loss: 0.3387 - accuracy: 0.8892 - val_loss: 0.3674 - val_accuracy: 0.8646\n","Epoch 7/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.8711\n","Epoch 7: val_loss did not improve from 0.35804\n","13/13 [==============================] - 19s 1s/step - loss: 0.3189 - accuracy: 0.8711 - val_loss: 0.3752 - val_accuracy: 0.8646\n","Epoch 8/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.3128 - accuracy: 0.8943Restoring model weights from the end of the best epoch: 1.\n","\n","Epoch 8: val_loss did not improve from 0.35804\n","13/13 [==============================] - 19s 1s/step - loss: 0.3128 - accuracy: 0.8943 - val_loss: 0.3760 - val_accuracy: 0.8438\n","Epoch 8: early stopping\n"]}],"source":["hist = model_alexnet_GlobalAvgPool.fit(train_generator, epochs=10000, validation_data=valid_generator, verbose = 1, callbacks=[es, mcp], batch_size=32)"]},{"cell_type":"code","source":["y_pred = model_alexnet_GlobalAvgPool.predict(x_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PqbkB8XAFxxt","executionInfo":{"status":"ok","timestamp":1679467985465,"user_tz":-540,"elapsed":841,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"f59da602-583a-47d3-e6c8-f1748ab1bb86"},"execution_count":132,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 38ms/step\n"]}]},{"cell_type":"code","source":["y_pred = np.where(y_pred>0.5,0,1)\n","confusion_matrix(y_test, y_pred)\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-H_83VXGHWV","executionInfo":{"status":"ok","timestamp":1679468043745,"user_tz":-540,"elapsed":393,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"126a35de-5785-48e2-c14c-736ce5d7c3cd"},"execution_count":133,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.84      0.77      0.80        60\n","           1       0.79      0.85      0.82        61\n","\n","    accuracy                           0.81       121\n","   macro avg       0.81      0.81      0.81       121\n","weighted avg       0.81      0.81      0.81       121\n","\n"]}]},{"cell_type":"markdown","source":["#### 4) 성능 평가\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"BdKiY1uIf663"}},{"cell_type":"code","source":["result = model_alexnet_GlobalAvgPool.evaluate(test_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G72rnt9vEXVC","executionInfo":{"status":"ok","timestamp":1679464176417,"user_tz":-540,"elapsed":5463,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"bc2a7846-4be8-4428-c534-49a80c2c18e1"},"execution_count":123,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 5s 908ms/step - loss: 0.9332 - accuracy: 0.8430\n"]}]},{"cell_type":"code","source":["result[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pnO7K16x3YQa","executionInfo":{"status":"ok","timestamp":1679464180066,"user_tz":-540,"elapsed":4,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"cd53acc0-7f43-417c-af89-32c9aadbf191"},"execution_count":124,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9332460761070251"]},"metadata":{},"execution_count":124}]},{"cell_type":"code","source":["from tensorflow.keras.applications import Xception\n","from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","def create_model(verbose = False) :\n","    input_tensor = Input(shape = (224, 224, 3))\n","    pretrained_model = Xception(input)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"ybwKb2AwQM-w","executionInfo":{"status":"error","timestamp":1679459924181,"user_tz":-540,"elapsed":542,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"263d3af6-7a34-44d0-f20b-cca306122115"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-122-8794b570c8ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorlow'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   verbose = 1,\n","                   patience = 15,\n","                   restore_best_weights = True\n","                   )\n","\n","mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Datasets/mcp_resnet50.h5',\n","                      monitor = 'val_loss',\n","                      verbose = 1,\n","                      save_best_only = True,\n","                      save_weights_only = False\n","                      )"],"metadata":{"id":"zdMCe2QeNe5s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hist = model_resnet50.fit(train_generator, epochs=10000, validation_data=valid_generator, verbose = 1, callbacks=[es, mcp], batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"WVlmFwnKMbkK","executionInfo":{"status":"error","timestamp":1679455679760,"user_tz":-540,"elapsed":237700,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"14e317c0-1dc1-42c0-8ab7-9d8953c68584"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10000\n","13/13 [==============================] - ETA: 0s - loss: 1.4187 - accuracy: 0.5000\n","Epoch 1: val_loss improved from inf to 0.69437, saving model to /content/drive/MyDrive/Datasets/mcp_resnet50.h5\n","13/13 [==============================] - 54s 2s/step - loss: 1.4187 - accuracy: 0.5000 - val_loss: 0.6944 - val_accuracy: 0.5000\n","Epoch 2/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5793 - accuracy: 0.5000\n","Epoch 2: val_loss did not improve from 0.69437\n","13/13 [==============================] - 20s 2s/step - loss: 0.5793 - accuracy: 0.5000 - val_loss: 3.1621 - val_accuracy: 0.5000\n","Epoch 3/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5702 - accuracy: 0.5000\n","Epoch 3: val_loss did not improve from 0.69437\n","13/13 [==============================] - 19s 1s/step - loss: 0.5702 - accuracy: 0.5000 - val_loss: 0.7458 - val_accuracy: 0.5000\n","Epoch 4/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.5000\n","Epoch 4: val_loss did not improve from 0.69437\n","13/13 [==============================] - 19s 1s/step - loss: 0.5088 - accuracy: 0.5000 - val_loss: 1.9193 - val_accuracy: 0.5000\n","Epoch 5/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.6682 - accuracy: 0.5000\n","Epoch 5: val_loss did not improve from 0.69437\n","13/13 [==============================] - 20s 1s/step - loss: 0.6682 - accuracy: 0.5000 - val_loss: 4.4340 - val_accuracy: 0.5000\n","Epoch 6/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.5000\n","Epoch 6: val_loss did not improve from 0.69437\n","13/13 [==============================] - 20s 1s/step - loss: 0.4403 - accuracy: 0.5000 - val_loss: 3.2628 - val_accuracy: 0.5000\n","Epoch 7/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4530 - accuracy: 0.5000\n","Epoch 7: val_loss did not improve from 0.69437\n","13/13 [==============================] - 19s 1s/step - loss: 0.4530 - accuracy: 0.5000 - val_loss: 2.0971 - val_accuracy: 0.5000\n","Epoch 8/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.5000\n","Epoch 8: val_loss did not improve from 0.69437\n","13/13 [==============================] - 20s 2s/step - loss: 0.4274 - accuracy: 0.5000 - val_loss: 5.2963 - val_accuracy: 0.5000\n","Epoch 9/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.5000\n","Epoch 9: val_loss did not improve from 0.69437\n","13/13 [==============================] - 20s 1s/step - loss: 0.4256 - accuracy: 0.5000 - val_loss: 4.3960 - val_accuracy: 0.5000\n","Epoch 10/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.5000\n","Epoch 10: val_loss did not improve from 0.69437\n","13/13 [==============================] - 19s 1s/step - loss: 0.4453 - accuracy: 0.5000 - val_loss: 6.7994 - val_accuracy: 0.5000\n","Epoch 11/10000\n"," 4/13 [========>.....................] - ETA: 11s - loss: 0.5485 - accuracy: 0.5312"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-120-e10d8f622308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_resnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"G1Njn8ogMbiQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2n4Re4AUMbf8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S1iv22vSxXle"},"source":["### (2) Transfer Learning\n","- **세부요구사항**\n","    * VGG16 모델은 1000개의 클래스를 분류하는 데 사용된 ImageNet 데이터셋을 기반으로 사전 학습된 가중치를 가지고 있습니다. \n","        * 따라서 이 모델은 이미지 분류 문제에 대한 높은 성능을 보입니다.\n","        * 이 모델은 보통 전이학습(transfer learning)에서 기본적으로 사용되며, 특히 대규모 데이터셋이 없을 때는 기본 모델로 사용되어 fine-tuning을 수행합니다.\n","    * VGG16 함수로 부터 base_model 저장\n"]},{"cell_type":"code","source":["# The identity block\n","def identity_block(X, f, filters, stage, block):\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","    \n","    F1, F2, F3 = filters\n","    \n","    X_shortcut = X\n","    \n","    # first step of main path\n","    X = tf.keras.layers.Conv2D(filters=F1, kernel_size=1, strides=1, padding='valid', name=conv_name_base + '2a',\n","                              kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n","    X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2a')(X)\n","    X = tf.keras.layers.Activation('relu')(X)\n","    \n","    # second step of main path\n","    X = tf.keras.layers.Conv2D(filters=F2, kernel_size=f, strides=1, padding='same', name=conv_name_base + '2b',\n","                              kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n","    X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2b')(X)\n","    X = tf.keras.layers.Activation('relu')(X) \n","    \n","    # third step of main path\n","    X = tf.keras.layers.Conv2D(filters=F3, kernel_size=1, strides=1, padding='valid', name=conv_name_base + '2c',\n","                              kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n","    X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2c')(X)\n","    \n","    # add shortcut value and pass it through a ReLU activation\n","    X = tf.keras.layers.Add()([X, X_shortcut])\n","    X = tf.keras.layers.Activation('relu')(X)\n","    \n","    return X"],"metadata":{"id":"ZkLNPZDDOcsz","executionInfo":{"status":"ok","timestamp":1679470221073,"user_tz":-540,"elapsed":694,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":135,"outputs":[]},{"cell_type":"code","source":["# Convolutional Block\n","def convolutional_block(X, f, filters, stage, block, s=2):\n","    conv_name_base = 'res'+str(stage)+block+'_branch'\n","    bn_name_base = 'bn'+str(stage)+block+'_branch'\n","    \n","    F1, F2, F3 = filters\n","    \n","    X_shortcut = X\n","    \n","    # first step of main path\n","    X = tf.keras.layers.Conv2D(filters=F1, kernel_size=1, strides=s, padding='valid', name=conv_name_base+'2a',\n","                              kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n","    X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2a')(X)\n","    X = tf.keras.layers.Activation('relu')(X)\n","    \n","    # second step of main path\n","    X = tf.keras.layers.Conv2D(filters=F2, kernel_size=f, strides=1, padding='same', name=conv_name_base+'2b',\n","                              kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n","    X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2b')(X)\n","    X = tf.keras.layers.Activation('relu')(X)\n","    \n","    # third step of main path\n","    X = tf.keras.layers.Conv2D(filters=F3, kernel_size=1, strides=1, padding='valid', name=conv_name_base+'2c',\n","                              kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n","    X = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'2c')(X)\n","    \n","    # shortcut path\n","    X_shortcut = tf.keras.layers.Conv2D(filters=F3, kernel_size=1, strides=s, padding='valid', name=conv_name_base+'1',\n","                                       kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X_shortcut)\n","    X_shortcut = tf.keras.layers.BatchNormalization(axis=3, name=bn_name_base+'1')(X_shortcut)\n","    \n","    # Add and pass it through a ReLU activation\n","    X = tf.keras.layers.Add()([X, X_shortcut])\n","    X = tf.keras.layers.Activation('relu')(X)\n","    \n","    return X"],"metadata":{"id":"cKElpMs2OYu0","executionInfo":{"status":"ok","timestamp":1679470204661,"user_tz":-540,"elapsed":496,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":134,"outputs":[]},{"cell_type":"code","source":["# ResNet50\n","def ResNet50(input_shape=(224,224,3), classes=1):\n","    X_input = tf.keras.layers.Input(input_shape)\n","    \n","    # zero padding\n","    X = tf.keras.layers.ZeroPadding2D((3,3))(X_input)\n","    \n","    # stage 1\n","    X = tf.keras.layers.Conv2D(filters=64, kernel_size=7, strides=2, name='conv1',\n","                              kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n","    X = tf.keras.layers.BatchNormalization(axis=3, name='bn_conv1')(X)\n","    X = tf.keras.layers.Activation('relu')(X)\n","    X = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2))(X)\n","    \n","    # stage 2\n","    X = convolutional_block(X, f=3, filters=[64,64,256], stage=2, block='a', s=1)\n","    X = identity_block(X, 3, [64,64,256], stage=2, block='b')\n","    X = identity_block(X, 3, [64,64,256], stage=2, block='c')\n","    \n","    # stage 3\n","    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n","    X = identity_block(X, 3, [128, 128, 512], stage = 3, block='b')\n","    X = identity_block(X, 3, [128, 128, 512], stage = 3, block='c')\n","    X = identity_block(X, 3, [128, 128, 512], stage = 3, block='d')\n","    \n","    # Stage 4\n","    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n","    X = identity_block(X, 3, [256, 256, 1024], stage = 4, block='b')\n","    X = identity_block(X, 3, [256, 256, 1024], stage = 4, block='c')\n","    X = identity_block(X, 3, [256, 256, 1024], stage = 4, block='d')\n","    X = identity_block(X, 3, [256, 256, 1024], stage = 4, block='e')\n","    X = identity_block(X, 3, [256, 256, 1024], stage = 4, block='f')\n"," \n","    # Stage 5\n","    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n","    X = identity_block(X, 3, [512, 512, 2048], stage = 5, block='b')\n","    X = identity_block(X, 3, [512, 512, 2048], stage = 5, block='c')\n","    \n","    # AVGPOOL\n","    X = tf.keras.layers.AveragePooling2D()(X)\n","    \n","    # output layer\n","    X = tf.keras.layers.Flatten()(X)\n","    X = tf.keras.layers.Dense(classes, activation='sigmoid', name='fc'+str(classes),\n","                             kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0))(X)\n","    \n","    # Create Model\n","    model = tf.keras.models.Model(inputs=X_input, outputs=X, name='ResNet50')\n","    \n","    return model"],"metadata":{"id":"w2AvoaNOMbB9","executionInfo":{"status":"ok","timestamp":1679470488612,"user_tz":-540,"elapsed":445,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":142,"outputs":[]},{"cell_type":"code","source":["model = ResNet50(input_shape = (224, 224, 3), classes = 1)\n","model.summary()\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"],"metadata":{"id":"Fg4axitUMbAD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679470493681,"user_tz":-540,"elapsed":2015,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"113c74f8-58d4-42f1-80be-46bc5e0afc3c"},"execution_count":143,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"ResNet50\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_5 (InputLayer)           [(None, 224, 224, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," zero_padding2d_3 (ZeroPadding2  (None, 230, 230, 3)  0          ['input_5[0][0]']                \n"," D)                                                                                               \n","                                                                                                  \n"," conv1 (Conv2D)                 (None, 112, 112, 64  9472        ['zero_padding2d_3[0][0]']       \n","                                )                                                                 \n","                                                                                                  \n"," bn_conv1 (BatchNormalization)  (None, 112, 112, 64  256         ['conv1[0][0]']                  \n","                                )                                                                 \n","                                                                                                  \n"," activation_147 (Activation)    (None, 112, 112, 64  0           ['bn_conv1[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_6 (MaxPooling2D)  (None, 55, 55, 64)  0           ['activation_147[0][0]']         \n","                                                                                                  \n"," res2a_branch2a (Conv2D)        (None, 55, 55, 64)   4160        ['max_pooling2d_6[0][0]']        \n","                                                                                                  \n"," bn2a_branch2a (BatchNormalizat  (None, 55, 55, 64)  256         ['res2a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_148 (Activation)    (None, 55, 55, 64)   0           ['bn2a_branch2a[0][0]']          \n","                                                                                                  \n"," res2a_branch2b (Conv2D)        (None, 55, 55, 64)   36928       ['activation_148[0][0]']         \n","                                                                                                  \n"," bn2a_branch2b (BatchNormalizat  (None, 55, 55, 64)  256         ['res2a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_149 (Activation)    (None, 55, 55, 64)   0           ['bn2a_branch2b[0][0]']          \n","                                                                                                  \n"," res2a_branch2c (Conv2D)        (None, 55, 55, 256)  16640       ['activation_149[0][0]']         \n","                                                                                                  \n"," res2a_branch1 (Conv2D)         (None, 55, 55, 256)  16640       ['max_pooling2d_6[0][0]']        \n","                                                                                                  \n"," bn2a_branch2c (BatchNormalizat  (None, 55, 55, 256)  1024       ['res2a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," bn2a_branch1 (BatchNormalizati  (None, 55, 55, 256)  1024       ['res2a_branch1[0][0]']          \n"," on)                                                                                              \n","                                                                                                  \n"," add_48 (Add)                   (None, 55, 55, 256)  0           ['bn2a_branch2c[0][0]',          \n","                                                                  'bn2a_branch1[0][0]']           \n","                                                                                                  \n"," activation_150 (Activation)    (None, 55, 55, 256)  0           ['add_48[0][0]']                 \n","                                                                                                  \n"," res2b_branch2a (Conv2D)        (None, 55, 55, 64)   16448       ['activation_150[0][0]']         \n","                                                                                                  \n"," bn2b_branch2a (BatchNormalizat  (None, 55, 55, 64)  256         ['res2b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_151 (Activation)    (None, 55, 55, 64)   0           ['bn2b_branch2a[0][0]']          \n","                                                                                                  \n"," res2b_branch2b (Conv2D)        (None, 55, 55, 64)   36928       ['activation_151[0][0]']         \n","                                                                                                  \n"," bn2b_branch2b (BatchNormalizat  (None, 55, 55, 64)  256         ['res2b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_152 (Activation)    (None, 55, 55, 64)   0           ['bn2b_branch2b[0][0]']          \n","                                                                                                  \n"," res2b_branch2c (Conv2D)        (None, 55, 55, 256)  16640       ['activation_152[0][0]']         \n","                                                                                                  \n"," bn2b_branch2c (BatchNormalizat  (None, 55, 55, 256)  1024       ['res2b_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_49 (Add)                   (None, 55, 55, 256)  0           ['bn2b_branch2c[0][0]',          \n","                                                                  'activation_150[0][0]']         \n","                                                                                                  \n"," activation_153 (Activation)    (None, 55, 55, 256)  0           ['add_49[0][0]']                 \n","                                                                                                  \n"," res2c_branch2a (Conv2D)        (None, 55, 55, 64)   16448       ['activation_153[0][0]']         \n","                                                                                                  \n"," bn2c_branch2a (BatchNormalizat  (None, 55, 55, 64)  256         ['res2c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_154 (Activation)    (None, 55, 55, 64)   0           ['bn2c_branch2a[0][0]']          \n","                                                                                                  \n"," res2c_branch2b (Conv2D)        (None, 55, 55, 64)   36928       ['activation_154[0][0]']         \n","                                                                                                  \n"," bn2c_branch2b (BatchNormalizat  (None, 55, 55, 64)  256         ['res2c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_155 (Activation)    (None, 55, 55, 64)   0           ['bn2c_branch2b[0][0]']          \n","                                                                                                  \n"," res2c_branch2c (Conv2D)        (None, 55, 55, 256)  16640       ['activation_155[0][0]']         \n","                                                                                                  \n"," bn2c_branch2c (BatchNormalizat  (None, 55, 55, 256)  1024       ['res2c_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_50 (Add)                   (None, 55, 55, 256)  0           ['bn2c_branch2c[0][0]',          \n","                                                                  'activation_153[0][0]']         \n","                                                                                                  \n"," activation_156 (Activation)    (None, 55, 55, 256)  0           ['add_50[0][0]']                 \n","                                                                                                  \n"," res3a_branch2a (Conv2D)        (None, 28, 28, 128)  32896       ['activation_156[0][0]']         \n","                                                                                                  \n"," bn3a_branch2a (BatchNormalizat  (None, 28, 28, 128)  512        ['res3a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_157 (Activation)    (None, 28, 28, 128)  0           ['bn3a_branch2a[0][0]']          \n","                                                                                                  \n"," res3a_branch2b (Conv2D)        (None, 28, 28, 128)  147584      ['activation_157[0][0]']         \n","                                                                                                  \n"," bn3a_branch2b (BatchNormalizat  (None, 28, 28, 128)  512        ['res3a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_158 (Activation)    (None, 28, 28, 128)  0           ['bn3a_branch2b[0][0]']          \n","                                                                                                  \n"," res3a_branch2c (Conv2D)        (None, 28, 28, 512)  66048       ['activation_158[0][0]']         \n","                                                                                                  \n"," res3a_branch1 (Conv2D)         (None, 28, 28, 512)  131584      ['activation_156[0][0]']         \n","                                                                                                  \n"," bn3a_branch2c (BatchNormalizat  (None, 28, 28, 512)  2048       ['res3a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," bn3a_branch1 (BatchNormalizati  (None, 28, 28, 512)  2048       ['res3a_branch1[0][0]']          \n"," on)                                                                                              \n","                                                                                                  \n"," add_51 (Add)                   (None, 28, 28, 512)  0           ['bn3a_branch2c[0][0]',          \n","                                                                  'bn3a_branch1[0][0]']           \n","                                                                                                  \n"," activation_159 (Activation)    (None, 28, 28, 512)  0           ['add_51[0][0]']                 \n","                                                                                                  \n"," res3b_branch2a (Conv2D)        (None, 28, 28, 128)  65664       ['activation_159[0][0]']         \n","                                                                                                  \n"," bn3b_branch2a (BatchNormalizat  (None, 28, 28, 128)  512        ['res3b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_160 (Activation)    (None, 28, 28, 128)  0           ['bn3b_branch2a[0][0]']          \n","                                                                                                  \n"," res3b_branch2b (Conv2D)        (None, 28, 28, 128)  147584      ['activation_160[0][0]']         \n","                                                                                                  \n"," bn3b_branch2b (BatchNormalizat  (None, 28, 28, 128)  512        ['res3b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_161 (Activation)    (None, 28, 28, 128)  0           ['bn3b_branch2b[0][0]']          \n","                                                                                                  \n"," res3b_branch2c (Conv2D)        (None, 28, 28, 512)  66048       ['activation_161[0][0]']         \n","                                                                                                  \n"," bn3b_branch2c (BatchNormalizat  (None, 28, 28, 512)  2048       ['res3b_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_52 (Add)                   (None, 28, 28, 512)  0           ['bn3b_branch2c[0][0]',          \n","                                                                  'activation_159[0][0]']         \n","                                                                                                  \n"," activation_162 (Activation)    (None, 28, 28, 512)  0           ['add_52[0][0]']                 \n","                                                                                                  \n"," res3c_branch2a (Conv2D)        (None, 28, 28, 128)  65664       ['activation_162[0][0]']         \n","                                                                                                  \n"," bn3c_branch2a (BatchNormalizat  (None, 28, 28, 128)  512        ['res3c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_163 (Activation)    (None, 28, 28, 128)  0           ['bn3c_branch2a[0][0]']          \n","                                                                                                  \n"," res3c_branch2b (Conv2D)        (None, 28, 28, 128)  147584      ['activation_163[0][0]']         \n","                                                                                                  \n"," bn3c_branch2b (BatchNormalizat  (None, 28, 28, 128)  512        ['res3c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_164 (Activation)    (None, 28, 28, 128)  0           ['bn3c_branch2b[0][0]']          \n","                                                                                                  \n"," res3c_branch2c (Conv2D)        (None, 28, 28, 512)  66048       ['activation_164[0][0]']         \n","                                                                                                  \n"," bn3c_branch2c (BatchNormalizat  (None, 28, 28, 512)  2048       ['res3c_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_53 (Add)                   (None, 28, 28, 512)  0           ['bn3c_branch2c[0][0]',          \n","                                                                  'activation_162[0][0]']         \n","                                                                                                  \n"," activation_165 (Activation)    (None, 28, 28, 512)  0           ['add_53[0][0]']                 \n","                                                                                                  \n"," res3d_branch2a (Conv2D)        (None, 28, 28, 128)  65664       ['activation_165[0][0]']         \n","                                                                                                  \n"," bn3d_branch2a (BatchNormalizat  (None, 28, 28, 128)  512        ['res3d_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_166 (Activation)    (None, 28, 28, 128)  0           ['bn3d_branch2a[0][0]']          \n","                                                                                                  \n"," res3d_branch2b (Conv2D)        (None, 28, 28, 128)  147584      ['activation_166[0][0]']         \n","                                                                                                  \n"," bn3d_branch2b (BatchNormalizat  (None, 28, 28, 128)  512        ['res3d_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_167 (Activation)    (None, 28, 28, 128)  0           ['bn3d_branch2b[0][0]']          \n","                                                                                                  \n"," res3d_branch2c (Conv2D)        (None, 28, 28, 512)  66048       ['activation_167[0][0]']         \n","                                                                                                  \n"," bn3d_branch2c (BatchNormalizat  (None, 28, 28, 512)  2048       ['res3d_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_54 (Add)                   (None, 28, 28, 512)  0           ['bn3d_branch2c[0][0]',          \n","                                                                  'activation_165[0][0]']         \n","                                                                                                  \n"," activation_168 (Activation)    (None, 28, 28, 512)  0           ['add_54[0][0]']                 \n","                                                                                                  \n"," res4a_branch2a (Conv2D)        (None, 14, 14, 256)  131328      ['activation_168[0][0]']         \n","                                                                                                  \n"," bn4a_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_169 (Activation)    (None, 14, 14, 256)  0           ['bn4a_branch2a[0][0]']          \n","                                                                                                  \n"," res4a_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_169[0][0]']         \n","                                                                                                  \n"," bn4a_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_170 (Activation)    (None, 14, 14, 256)  0           ['bn4a_branch2b[0][0]']          \n","                                                                                                  \n"," res4a_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_170[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," res4a_branch1 (Conv2D)         (None, 14, 14, 1024  525312      ['activation_168[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," bn4a_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4a_branch2c[0][0]']         \n"," ion)                           )                                                                 \n","                                                                                                  \n"," bn4a_branch1 (BatchNormalizati  (None, 14, 14, 1024  4096       ['res4a_branch1[0][0]']          \n"," on)                            )                                                                 \n","                                                                                                  \n"," add_55 (Add)                   (None, 14, 14, 1024  0           ['bn4a_branch2c[0][0]',          \n","                                )                                 'bn4a_branch1[0][0]']           \n","                                                                                                  \n"," activation_171 (Activation)    (None, 14, 14, 1024  0           ['add_55[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," res4b_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_171[0][0]']         \n","                                                                                                  \n"," bn4b_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_172 (Activation)    (None, 14, 14, 256)  0           ['bn4b_branch2a[0][0]']          \n","                                                                                                  \n"," res4b_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_172[0][0]']         \n","                                                                                                  \n"," bn4b_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_173 (Activation)    (None, 14, 14, 256)  0           ['bn4b_branch2b[0][0]']          \n","                                                                                                  \n"," res4b_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_173[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," bn4b_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4b_branch2c[0][0]']         \n"," ion)                           )                                                                 \n","                                                                                                  \n"," add_56 (Add)                   (None, 14, 14, 1024  0           ['bn4b_branch2c[0][0]',          \n","                                )                                 'activation_171[0][0]']         \n","                                                                                                  \n"," activation_174 (Activation)    (None, 14, 14, 1024  0           ['add_56[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," res4c_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_174[0][0]']         \n","                                                                                                  \n"," bn4c_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_175 (Activation)    (None, 14, 14, 256)  0           ['bn4c_branch2a[0][0]']          \n","                                                                                                  \n"," res4c_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_175[0][0]']         \n","                                                                                                  \n"," bn4c_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_176 (Activation)    (None, 14, 14, 256)  0           ['bn4c_branch2b[0][0]']          \n","                                                                                                  \n"," res4c_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_176[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," bn4c_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4c_branch2c[0][0]']         \n"," ion)                           )                                                                 \n","                                                                                                  \n"," add_57 (Add)                   (None, 14, 14, 1024  0           ['bn4c_branch2c[0][0]',          \n","                                )                                 'activation_174[0][0]']         \n","                                                                                                  \n"," activation_177 (Activation)    (None, 14, 14, 1024  0           ['add_57[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," res4d_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_177[0][0]']         \n","                                                                                                  \n"," bn4d_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4d_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_178 (Activation)    (None, 14, 14, 256)  0           ['bn4d_branch2a[0][0]']          \n","                                                                                                  \n"," res4d_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_178[0][0]']         \n","                                                                                                  \n"," bn4d_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4d_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_179 (Activation)    (None, 14, 14, 256)  0           ['bn4d_branch2b[0][0]']          \n","                                                                                                  \n"," res4d_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_179[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," bn4d_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4d_branch2c[0][0]']         \n"," ion)                           )                                                                 \n","                                                                                                  \n"," add_58 (Add)                   (None, 14, 14, 1024  0           ['bn4d_branch2c[0][0]',          \n","                                )                                 'activation_177[0][0]']         \n","                                                                                                  \n"," activation_180 (Activation)    (None, 14, 14, 1024  0           ['add_58[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," res4e_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_180[0][0]']         \n","                                                                                                  \n"," bn4e_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4e_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_181 (Activation)    (None, 14, 14, 256)  0           ['bn4e_branch2a[0][0]']          \n","                                                                                                  \n"," res4e_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_181[0][0]']         \n","                                                                                                  \n"," bn4e_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4e_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_182 (Activation)    (None, 14, 14, 256)  0           ['bn4e_branch2b[0][0]']          \n","                                                                                                  \n"," res4e_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_182[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," bn4e_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4e_branch2c[0][0]']         \n"," ion)                           )                                                                 \n","                                                                                                  \n"," add_59 (Add)                   (None, 14, 14, 1024  0           ['bn4e_branch2c[0][0]',          \n","                                )                                 'activation_180[0][0]']         \n","                                                                                                  \n"," activation_183 (Activation)    (None, 14, 14, 1024  0           ['add_59[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," res4f_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_183[0][0]']         \n","                                                                                                  \n"," bn4f_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4f_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_184 (Activation)    (None, 14, 14, 256)  0           ['bn4f_branch2a[0][0]']          \n","                                                                                                  \n"," res4f_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_184[0][0]']         \n","                                                                                                  \n"," bn4f_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4f_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_185 (Activation)    (None, 14, 14, 256)  0           ['bn4f_branch2b[0][0]']          \n","                                                                                                  \n"," res4f_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_185[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," bn4f_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4f_branch2c[0][0]']         \n"," ion)                           )                                                                 \n","                                                                                                  \n"," add_60 (Add)                   (None, 14, 14, 1024  0           ['bn4f_branch2c[0][0]',          \n","                                )                                 'activation_183[0][0]']         \n","                                                                                                  \n"," activation_186 (Activation)    (None, 14, 14, 1024  0           ['add_60[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," res5a_branch2a (Conv2D)        (None, 7, 7, 512)    524800      ['activation_186[0][0]']         \n","                                                                                                  \n"," bn5a_branch2a (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_187 (Activation)    (None, 7, 7, 512)    0           ['bn5a_branch2a[0][0]']          \n","                                                                                                  \n"," res5a_branch2b (Conv2D)        (None, 7, 7, 512)    2359808     ['activation_187[0][0]']         \n","                                                                                                  \n"," bn5a_branch2b (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_188 (Activation)    (None, 7, 7, 512)    0           ['bn5a_branch2b[0][0]']          \n","                                                                                                  \n"," res5a_branch2c (Conv2D)        (None, 7, 7, 2048)   1050624     ['activation_188[0][0]']         \n","                                                                                                  \n"," res5a_branch1 (Conv2D)         (None, 7, 7, 2048)   2099200     ['activation_186[0][0]']         \n","                                                                                                  \n"," bn5a_branch2c (BatchNormalizat  (None, 7, 7, 2048)  8192        ['res5a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," bn5a_branch1 (BatchNormalizati  (None, 7, 7, 2048)  8192        ['res5a_branch1[0][0]']          \n"," on)                                                                                              \n","                                                                                                  \n"," add_61 (Add)                   (None, 7, 7, 2048)   0           ['bn5a_branch2c[0][0]',          \n","                                                                  'bn5a_branch1[0][0]']           \n","                                                                                                  \n"," activation_189 (Activation)    (None, 7, 7, 2048)   0           ['add_61[0][0]']                 \n","                                                                                                  \n"," res5b_branch2a (Conv2D)        (None, 7, 7, 512)    1049088     ['activation_189[0][0]']         \n","                                                                                                  \n"," bn5b_branch2a (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_190 (Activation)    (None, 7, 7, 512)    0           ['bn5b_branch2a[0][0]']          \n","                                                                                                  \n"," res5b_branch2b (Conv2D)        (None, 7, 7, 512)    2359808     ['activation_190[0][0]']         \n","                                                                                                  \n"," bn5b_branch2b (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_191 (Activation)    (None, 7, 7, 512)    0           ['bn5b_branch2b[0][0]']          \n","                                                                                                  \n"," res5b_branch2c (Conv2D)        (None, 7, 7, 2048)   1050624     ['activation_191[0][0]']         \n","                                                                                                  \n"," bn5b_branch2c (BatchNormalizat  (None, 7, 7, 2048)  8192        ['res5b_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_62 (Add)                   (None, 7, 7, 2048)   0           ['bn5b_branch2c[0][0]',          \n","                                                                  'activation_189[0][0]']         \n","                                                                                                  \n"," activation_192 (Activation)    (None, 7, 7, 2048)   0           ['add_62[0][0]']                 \n","                                                                                                  \n"," res5c_branch2a (Conv2D)        (None, 7, 7, 512)    1049088     ['activation_192[0][0]']         \n","                                                                                                  \n"," bn5c_branch2a (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_193 (Activation)    (None, 7, 7, 512)    0           ['bn5c_branch2a[0][0]']          \n","                                                                                                  \n"," res5c_branch2b (Conv2D)        (None, 7, 7, 512)    2359808     ['activation_193[0][0]']         \n","                                                                                                  \n"," bn5c_branch2b (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_194 (Activation)    (None, 7, 7, 512)    0           ['bn5c_branch2b[0][0]']          \n","                                                                                                  \n"," res5c_branch2c (Conv2D)        (None, 7, 7, 2048)   1050624     ['activation_194[0][0]']         \n","                                                                                                  \n"," bn5c_branch2c (BatchNormalizat  (None, 7, 7, 2048)  8192        ['res5c_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_63 (Add)                   (None, 7, 7, 2048)   0           ['bn5c_branch2c[0][0]',          \n","                                                                  'activation_192[0][0]']         \n","                                                                                                  \n"," activation_195 (Activation)    (None, 7, 7, 2048)   0           ['add_63[0][0]']                 \n","                                                                                                  \n"," average_pooling2d_3 (AveragePo  (None, 3, 3, 2048)  0           ['activation_195[0][0]']         \n"," oling2D)                                                                                         \n","                                                                                                  \n"," flatten_3 (Flatten)            (None, 18432)        0           ['average_pooling2d_3[0][0]']    \n","                                                                                                  \n"," fc1 (Dense)                    (None, 1)            18433       ['flatten_3[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 23,606,145\n","Trainable params: 23,553,025\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   verbose = 1,\n","                   patience = 5,\n","                   restore_best_weights = True\n","                   )\n","\n","mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Datasets/mcp_resnet50.h5',\n","                      monitor = 'val_loss',\n","                      verbose = 1,\n","                      save_best_only = True,\n","                      save_weights_only = False\n","                      )"],"metadata":{"id":"ndQLi7ANMa9g","executionInfo":{"status":"ok","timestamp":1679470499466,"user_tz":-540,"elapsed":423,"user":{"displayName":"현태","userId":"11869159444039358312"}}},"execution_count":144,"outputs":[]},{"cell_type":"code","source":["hist = model.fit(train_generator, epochs=10000, validation_data=valid_generator, verbose = 1, callbacks=[es, mcp], batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kX7y8no-O8Nv","executionInfo":{"status":"ok","timestamp":1679471138233,"user_tz":-540,"elapsed":631193,"user":{"displayName":"현태","userId":"11869159444039358312"}},"outputId":"ad6e8989-4d89-4a61-dc03-68a3c8e6526a"},"execution_count":145,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10000\n","13/13 [==============================] - ETA: 0s - loss: 2.0325 - acc: 0.7062\n","Epoch 1: val_loss improved from inf to 13.85926, saving model to /content/drive/MyDrive/Datasets/mcp_resnet50.h5\n","13/13 [==============================] - 53s 2s/step - loss: 2.0325 - acc: 0.7062 - val_loss: 13.8593 - val_acc: 0.5000\n","Epoch 2/10000\n","13/13 [==============================] - ETA: 0s - loss: 2.0864 - acc: 0.6933\n","Epoch 2: val_loss did not improve from 13.85926\n","13/13 [==============================] - 20s 2s/step - loss: 2.0864 - acc: 0.6933 - val_loss: 79.6319 - val_acc: 0.5000\n","Epoch 3/10000\n","13/13 [==============================] - ETA: 0s - loss: 1.7859 - acc: 0.6856\n","Epoch 3: val_loss did not improve from 13.85926\n","13/13 [==============================] - 19s 1s/step - loss: 1.7859 - acc: 0.6856 - val_loss: 155.4107 - val_acc: 0.5000\n","Epoch 4/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.7966 - acc: 0.7758\n","Epoch 4: val_loss did not improve from 13.85926\n","13/13 [==============================] - 19s 1s/step - loss: 0.7966 - acc: 0.7758 - val_loss: 139.7836 - val_acc: 0.5000\n","Epoch 5/10000\n","13/13 [==============================] - ETA: 0s - loss: 2.6112 - acc: 0.7500\n","Epoch 5: val_loss did not improve from 13.85926\n","13/13 [==============================] - 20s 1s/step - loss: 2.6112 - acc: 0.7500 - val_loss: 15.3357 - val_acc: 0.4688\n","Epoch 6/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.8582 - acc: 0.7861\n","Epoch 6: val_loss improved from 13.85926 to 2.36187, saving model to /content/drive/MyDrive/Datasets/mcp_resnet50.h5\n","13/13 [==============================] - 24s 2s/step - loss: 0.8582 - acc: 0.7861 - val_loss: 2.3619 - val_acc: 0.5625\n","Epoch 7/10000\n","13/13 [==============================] - ETA: 0s - loss: 1.2448 - acc: 0.7242\n","Epoch 7: val_loss did not improve from 2.36187\n","13/13 [==============================] - 20s 2s/step - loss: 1.2448 - acc: 0.7242 - val_loss: 3.1119 - val_acc: 0.4896\n","Epoch 8/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.6852 - acc: 0.7320\n","Epoch 8: val_loss did not improve from 2.36187\n","13/13 [==============================] - 20s 2s/step - loss: 0.6852 - acc: 0.7320 - val_loss: 2.5302 - val_acc: 0.5312\n","Epoch 9/10000\n","13/13 [==============================] - ETA: 0s - loss: 1.1551 - acc: 0.8093\n","Epoch 9: val_loss did not improve from 2.36187\n","13/13 [==============================] - 20s 2s/step - loss: 1.1551 - acc: 0.8093 - val_loss: 3.2654 - val_acc: 0.5000\n","Epoch 10/10000\n","13/13 [==============================] - ETA: 0s - loss: 1.2173 - acc: 0.7629\n","Epoch 10: val_loss did not improve from 2.36187\n","13/13 [==============================] - 20s 2s/step - loss: 1.2173 - acc: 0.7629 - val_loss: 2.9211 - val_acc: 0.5104\n","Epoch 11/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.7568 - acc: 0.8093\n","Epoch 11: val_loss improved from 2.36187 to 1.66960, saving model to /content/drive/MyDrive/Datasets/mcp_resnet50.h5\n","13/13 [==============================] - 25s 2s/step - loss: 0.7568 - acc: 0.8093 - val_loss: 1.6696 - val_acc: 0.5312\n","Epoch 12/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5105 - acc: 0.8067\n","Epoch 12: val_loss improved from 1.66960 to 1.05259, saving model to /content/drive/MyDrive/Datasets/mcp_resnet50.h5\n","13/13 [==============================] - 24s 2s/step - loss: 0.5105 - acc: 0.8067 - val_loss: 1.0526 - val_acc: 0.5000\n","Epoch 13/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.9005 - acc: 0.7242\n","Epoch 13: val_loss did not improve from 1.05259\n","13/13 [==============================] - 20s 2s/step - loss: 0.9005 - acc: 0.7242 - val_loss: 65.3859 - val_acc: 0.5000\n","Epoch 14/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.7341 - acc: 0.7680\n","Epoch 14: val_loss did not improve from 1.05259\n","13/13 [==============================] - 20s 1s/step - loss: 0.7341 - acc: 0.7680 - val_loss: 82.7062 - val_acc: 0.5000\n","Epoch 15/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5785 - acc: 0.8325\n","Epoch 15: val_loss did not improve from 1.05259\n","13/13 [==============================] - 20s 1s/step - loss: 0.5785 - acc: 0.8325 - val_loss: 20.9282 - val_acc: 0.4896\n","Epoch 16/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4607 - acc: 0.8067\n","Epoch 16: val_loss did not improve from 1.05259\n","13/13 [==============================] - 20s 2s/step - loss: 0.4607 - acc: 0.8067 - val_loss: 1.4863 - val_acc: 0.4896\n","Epoch 17/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4296 - acc: 0.8505\n","Epoch 17: val_loss improved from 1.05259 to 0.81817, saving model to /content/drive/MyDrive/Datasets/mcp_resnet50.h5\n","13/13 [==============================] - 23s 2s/step - loss: 0.4296 - acc: 0.8505 - val_loss: 0.8182 - val_acc: 0.5938\n","Epoch 18/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4643 - acc: 0.8222\n","Epoch 18: val_loss did not improve from 0.81817\n","13/13 [==============================] - 20s 2s/step - loss: 0.4643 - acc: 0.8222 - val_loss: 1.8033 - val_acc: 0.5521\n","Epoch 19/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4612 - acc: 0.8222\n","Epoch 19: val_loss did not improve from 0.81817\n","13/13 [==============================] - 20s 2s/step - loss: 0.4612 - acc: 0.8222 - val_loss: 3.1048 - val_acc: 0.5417\n","Epoch 20/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5820 - acc: 0.8015\n","Epoch 20: val_loss improved from 0.81817 to 0.73334, saving model to /content/drive/MyDrive/Datasets/mcp_resnet50.h5\n","13/13 [==============================] - 23s 2s/step - loss: 0.5820 - acc: 0.8015 - val_loss: 0.7333 - val_acc: 0.7188\n","Epoch 21/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.8921 - acc: 0.8093\n","Epoch 21: val_loss did not improve from 0.73334\n","13/13 [==============================] - 20s 2s/step - loss: 0.8921 - acc: 0.8093 - val_loss: 0.9170 - val_acc: 0.4792\n","Epoch 22/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4570 - acc: 0.8144\n","Epoch 22: val_loss did not improve from 0.73334\n","13/13 [==============================] - 20s 2s/step - loss: 0.4570 - acc: 0.8144 - val_loss: 0.7625 - val_acc: 0.6667\n","Epoch 23/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.6507 - acc: 0.8170\n","Epoch 23: val_loss did not improve from 0.73334\n","13/13 [==============================] - 19s 1s/step - loss: 0.6507 - acc: 0.8170 - val_loss: 0.7805 - val_acc: 0.7083\n","Epoch 24/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.4287 - acc: 0.8479\n","Epoch 24: val_loss improved from 0.73334 to 0.61026, saving model to /content/drive/MyDrive/Datasets/mcp_resnet50.h5\n","13/13 [==============================] - 23s 2s/step - loss: 0.4287 - acc: 0.8479 - val_loss: 0.6103 - val_acc: 0.7812\n","Epoch 25/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.7000 - acc: 0.8351\n","Epoch 25: val_loss did not improve from 0.61026\n","13/13 [==============================] - 20s 2s/step - loss: 0.7000 - acc: 0.8351 - val_loss: 1.3551 - val_acc: 0.6146\n","Epoch 26/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.9310 - acc: 0.8170\n","Epoch 26: val_loss did not improve from 0.61026\n","13/13 [==============================] - 19s 1s/step - loss: 0.9310 - acc: 0.8170 - val_loss: 1.9523 - val_acc: 0.6250\n","Epoch 27/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5321 - acc: 0.7835\n","Epoch 27: val_loss did not improve from 0.61026\n","13/13 [==============================] - 19s 1s/step - loss: 0.5321 - acc: 0.7835 - val_loss: 0.7538 - val_acc: 0.7292\n","Epoch 28/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.5655 - acc: 0.8222\n","Epoch 28: val_loss did not improve from 0.61026\n","13/13 [==============================] - 20s 2s/step - loss: 0.5655 - acc: 0.8222 - val_loss: 1.1368 - val_acc: 0.7708\n","Epoch 29/10000\n","13/13 [==============================] - ETA: 0s - loss: 0.7607 - acc: 0.7809Restoring model weights from the end of the best epoch: 24.\n","\n","Epoch 29: val_loss did not improve from 0.61026\n","13/13 [==============================] - 19s 1s/step - loss: 0.7607 - acc: 0.7809 - val_loss: 1.8694 - val_acc: 0.8125\n","Epoch 29: early stopping\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RnS12YhDxXle"},"outputs":[],"source":["from tensorflow.keras.applications import VGG16"]},{"cell_type":"code","source":[],"metadata":{"id":"z9Rz1mupMakZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1) VGG16 불러와서 저장하기\n","* include_top=False로 설정하여 분류기를 제외하고 미리 학습된 가중치 imagenet을 로드합니다.\n","* .trainable을 True로 설정하여 모델의 모든 레이어들이 fine-tuning에 대해 업데이트되도록 합니다.\n"],"metadata":{"id":"d3kyvCwIiAfi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFf3IxbBGe9B"},"outputs":[],"source":["base_model = VGG16(                 )\n","\n","\n"]},{"cell_type":"markdown","source":["#### 2) VGG16과 연결한 구조 설계\n","* VGG16을 불러와서 Flatten, Dense 등으로 레이어 연결하기"],"metadata":{"id":"D-JjBLZZiIxA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yg4KhHQ8xXlf"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5V5heiDxxXlf"},"source":["#### 3) 학습\n","- **세부요구사항**\n","    - 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n","    - 데이터\n","        * Image Generator를 연결하거나\n","        * 기존 train, validation 셋을 이용해도 됩니다.\n","        - Early Stopping을 반드시 사용하세요.\n","        - 최적의 가중치를 모델에 적용하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CtqQIS-HxXlg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zg0L88Gwf4l"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#### 4) 성능 평가"],"metadata":{"id":"BbhiWcS5i735"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ik4AFzCQi735"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zkkSsyMoi735"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGuQMUJNxXSy"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}